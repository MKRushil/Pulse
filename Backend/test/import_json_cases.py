#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
JSON ç—…ä¾‹æ‰¹æ¬¡åŒ¯å…¥ç¨‹å¼ (æ‰¹æ¬¡ç›®éŒ„ç‰ˆæœ¬)
å¾æŒ‡å®šç›®éŒ„è®€å–æ‰€æœ‰ JSON æª”æ¡ˆä¸¦æ‰¹æ¬¡ä¸Šå‚³åˆ° Weaviate TCMCase Collection

ä½¿ç”¨æ–¹æ³•:
    python import_batch_json_cases.py
    python import_batch_json_cases.py --dry-run
    python import_batch_json_cases.py --files 01 02 03
"""

import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

from anc.schema import TCMCaseInput
from anc.case_processor import get_case_processor


# æ‰¹æ¬¡ç›®éŒ„è·¯å¾‘
BATCH_DIR = Path(r"C:\work\ç³»çµ±-ä¸­é†«\Pulse-project\Backend\tcm_cases_batch")


def get_batch_files(file_numbers: List[str] = None) -> List[Path]:
    """
    å–å¾—æ‰¹æ¬¡ JSON æª”æ¡ˆåˆ—è¡¨
    
    Args:
        file_numbers: æŒ‡å®šè¦åŒ¯å…¥çš„æª”æ¡ˆç·¨è™Ÿåˆ—è¡¨ (å¦‚ ['01', '02'])
    
    Returns:
        JSON æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
    """
    if not BATCH_DIR.exists():
        raise FileNotFoundError(f"æ‰¹æ¬¡ç›®éŒ„ä¸å­˜åœ¨: {BATCH_DIR}")
    
    files = []
    
    if file_numbers:
        # åŒ¯å…¥æŒ‡å®šæª”æ¡ˆ
        for num in file_numbers:
            file_path = BATCH_DIR / f"tcm_cases_batch_{num}.json"
            if file_path.exists():
                files.append(file_path)
            else:
                print(f"âš ï¸  æª”æ¡ˆä¸å­˜åœ¨: {file_path.name}")
    else:
        # åŒ¯å…¥æ‰€æœ‰ tcm_cases_batch_*.json æª”æ¡ˆ
        files = sorted(BATCH_DIR.glob("tcm_cases_batch_*.json"))
    
    return files


def import_single_file(
    json_path: Path,
    processor,
    dry_run: bool = False
) -> Dict[str, Any]:
    """
    åŒ¯å…¥å–®å€‹ JSON æª”æ¡ˆ
    
    Args:
        json_path: JSON æª”æ¡ˆè·¯å¾‘
        processor: CaseProcessor å¯¦ä¾‹
        dry_run: æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼
    
    Returns:
        åŒ¯å…¥çµæœ
    """
    print(f"\n{'â”€'*70}")
    print(f"ğŸ“„ è™•ç†æª”æ¡ˆ: {json_path.name}")
    print(f"{'â”€'*70}")
    
    # è®€å– JSON
    with open(json_path, 'r', encoding='utf-8') as f:
        cases = json.load(f)
    
    if not isinstance(cases, list):
        raise ValueError(f"JSON æ ¼å¼éŒ¯èª¤: {json_path.name} æ‡‰ç‚ºç—…ä¾‹åˆ—è¡¨")
    
    print(f"   ç—…ä¾‹æ•¸é‡: {len(cases)} ç­†\n")
    
    results = {
        "file": json_path.name,
        "total": len(cases),
        "success": 0,
        "failed": 0,
        "errors": []
    }
    
    if dry_run:
        # æ¸¬è©¦æ¨¡å¼ï¼šåªé©—è­‰å‰ 3 ç­†
        print("   [æ¸¬è©¦æ¨¡å¼] é©—è­‰å‰ 3 ç­†è³‡æ–™æ ¼å¼:")
        for i, case_data in enumerate(cases[:3], 1):
            try:
                case_input = TCMCaseInput(**case_data)
                print(f"      âœ“ ç—…ä¾‹ {i}: {case_input.basic.name} ({case_input.basic.gender}, {case_input.basic.age}æ­²)")
            except Exception as e:
                print(f"      âœ— ç—…ä¾‹ {i}: æ ¼å¼éŒ¯èª¤ - {str(e)[:50]}...")
                results["errors"].append(f"ç—…ä¾‹ {i}: {e}")
        
        results["validated"] = min(3, len(cases))
        return results
    
    # å¯¦éš›åŒ¯å…¥
    for i, case_data in enumerate(cases, 1):
        try:
            # è½‰æ›ç‚º TCMCaseInput
            case_input = TCMCaseInput(**case_data)
            
            # è™•ç†ç—…ä¾‹
            result = processor.process_case(case_input)
            
            if result["success"]:
                results["success"] += 1
                case_id = result['case_id']
                status = "âœ“"
                if result.get("errors"):
                    status += f" (è­¦å‘Š: {len(result['errors'])})"
                print(f"   [{i:02d}/{len(cases):02d}] {status} {case_input.basic.name} - {case_id}")
            else:
                results["failed"] += 1
                error_msg = f"{json_path.name} ç—…ä¾‹ {i} ({case_input.basic.name}): {', '.join(result['errors'])}"
                results["errors"].append(error_msg)
                print(f"   [{i:02d}/{len(cases):02d}] âœ— {case_input.basic.name} - å¤±æ•—")
                print(f"      éŒ¯èª¤: {', '.join(result['errors'][:2])}")
        
        except Exception as e:
            results["failed"] += 1
            error_msg = f"{json_path.name} ç—…ä¾‹ {i}: {str(e)}"
            results["errors"].append(error_msg)
            print(f"   [{i:02d}/{len(cases):02d}] âœ— è™•ç†å¤±æ•—: {str(e)[:60]}...")
    
    return results


def import_batch_files(
    file_numbers: List[str] = None,
    dry_run: bool = False
) -> Dict[str, Any]:
    """
    æ‰¹æ¬¡åŒ¯å…¥å¤šå€‹ JSON æª”æ¡ˆ
    
    Args:
        file_numbers: æŒ‡å®šæª”æ¡ˆç·¨è™Ÿåˆ—è¡¨
        dry_run: æ¸¬è©¦æ¨¡å¼
    
    Returns:
        ç¸½åŒ¯å…¥çµæœçµ±è¨ˆ
    """
    print(f"\n{'='*70}")
    print(f"  ğŸ¥ ä¸­é†«ç—…ä¾‹æ‰¹æ¬¡åŒ¯å…¥ç³»çµ±")
    print(f"{'='*70}\n")
    print(f"æ‰¹æ¬¡ç›®éŒ„: {BATCH_DIR}")
    print(f"æ¸¬è©¦æ¨¡å¼: {'æ˜¯' if dry_run else 'å¦'}")
    print(f"æŒ‡å®šæª”æ¡ˆ: {', '.join(file_numbers) if file_numbers else 'å…¨éƒ¨'}")
    
    # å–å¾—æª”æ¡ˆåˆ—è¡¨
    files = get_batch_files(file_numbers)
    
    if not files:
        raise FileNotFoundError("æœªæ‰¾åˆ°ä»»ä½• JSON æª”æ¡ˆ")
    
    print(f"æ‰¾åˆ°æª”æ¡ˆ: {len(files)} å€‹\n")
    for f in files:
        print(f"   â€¢ {f.name}")
    
    # åˆå§‹åŒ–è™•ç†å™¨
    processor = None if dry_run else get_case_processor()
    
    # æ‰¹æ¬¡åŒ¯å…¥
    all_results = {
        "files": len(files),
        "total_cases": 0,
        "total_success": 0,
        "total_failed": 0,
        "file_results": [],
        "all_errors": []
    }
    
    for json_file in files:
        try:
            result = import_single_file(json_file, processor, dry_run)
            
            all_results["file_results"].append(result)
            all_results["total_cases"] += result["total"]
            all_results["total_success"] += result["success"]
            all_results["total_failed"] += result["failed"]
            all_results["all_errors"].extend(result["errors"])
            
        except Exception as e:
            print(f"\n   âœ— æª”æ¡ˆè™•ç†å¤±æ•—: {json_file.name}")
            print(f"      éŒ¯èª¤: {e}")
            all_results["all_errors"].append(f"{json_file.name}: {e}")
    
    # åŒ¯å…¥å®Œæˆçµ±è¨ˆ
    print(f"\n{'='*70}")
    print(f"  ğŸ“Š æ‰¹æ¬¡åŒ¯å…¥å®Œæˆçµ±è¨ˆ")
    print(f"{'='*70}\n")
    
    if dry_run:
        print(f"æ¸¬è©¦æ¨¡å¼å®Œæˆ")
        print(f"   æª”æ¡ˆæ•¸é‡: {all_results['files']} å€‹")
        print(f"   ç—…ä¾‹ç¸½æ•¸: {all_results['total_cases']} ç­†")
        print(f"   æ ¼å¼é©—è­‰: é€šé\n")
        print("âœ“ ç§»é™¤ --dry-run åƒæ•¸é–‹å§‹å¯¦éš›åŒ¯å…¥")
    else:
        print(f"è™•ç†æª”æ¡ˆ: {all_results['files']} å€‹")
        print(f"ç—…ä¾‹ç¸½æ•¸: {all_results['total_cases']} ç­†")
        print(f"æˆåŠŸåŒ¯å…¥: {all_results['total_success']} ç­†")
        print(f"åŒ¯å…¥å¤±æ•—: {all_results['total_failed']} ç­†")
        
        if all_results['total_cases'] > 0:
            success_rate = all_results['total_success'] / all_results['total_cases'] * 100
            print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        
        # å„æª”æ¡ˆçµ±è¨ˆ
        print(f"\nå„æª”æ¡ˆçµ±è¨ˆ:")
        for result in all_results["file_results"]:
            status = "âœ“" if result["failed"] == 0 else "âœ—"
            print(f"   {status} {result['file']}: {result['success']}/{result['total']}")
        
        # éŒ¯èª¤åˆ—è¡¨
        if all_results['all_errors']:
            print(f"\néŒ¯èª¤åˆ—è¡¨ (å‰ 10 æ¢):")
            for error in all_results['all_errors'][:10]:
                print(f"   â€¢ {error}")
            
            if len(all_results['all_errors']) > 10:
                print(f"   ... é‚„æœ‰ {len(all_results['all_errors']) - 10} æ¢éŒ¯èª¤")
            
            # ä¿å­˜éŒ¯èª¤æ—¥èªŒ
            log_file = Path(f"batch_import_errors_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(all_results['all_errors']))
            print(f"\n   éŒ¯èª¤æ—¥èªŒå·²ä¿å­˜: {log_file}")
    
    return all_results


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description="æ‰¹æ¬¡åŒ¯å…¥ç›®éŒ„ä¸­çš„æ‰€æœ‰ä¸­é†«ç—…ä¾‹ JSON æª”æ¡ˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # åŒ¯å…¥æ‰€æœ‰æª”æ¡ˆ
  python import_batch_json_cases.py
  
  # æ¸¬è©¦æ¨¡å¼ï¼ˆä¸å¯¦éš›åŒ¯å…¥ï¼‰
  python import_batch_json_cases.py --dry-run
  
  # åªåŒ¯å…¥æŒ‡å®šæª”æ¡ˆ
  python import_batch_json_cases.py --files 01 02 03
  
  # æ¸¬è©¦æŒ‡å®šæª”æ¡ˆ
  python import_batch_json_cases.py --files 01 --dry-run
        """
    )
    
    parser.add_argument(
        "--files",
        nargs="+",
        help="æŒ‡å®šè¦åŒ¯å…¥çš„æª”æ¡ˆç·¨è™Ÿ (å¦‚: 01 02 03)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="æ¸¬è©¦æ¨¡å¼ï¼ˆé©—è­‰æ ¼å¼ä½†ä¸å¯¦éš›åŒ¯å…¥ï¼‰"
    )
    
    args = parser.parse_args()
    
    try:
        results = import_batch_files(
            file_numbers=args.files,
            dry_run=args.dry_run
        )
        
        # æ ¹æ“šçµæœè¨­å®šé€€å‡ºç¢¼
        if args.dry_run:
            sys.exit(0)
        
        if results['total_failed'] == 0:
            print("\nâœ“ æ‰€æœ‰ç—…ä¾‹åŒ¯å…¥æˆåŠŸ")
            sys.exit(0)
        elif results['total_success'] > 0:
            print(f"\nâš  éƒ¨åˆ†ç—…ä¾‹åŒ¯å…¥æˆåŠŸ ({results['total_success']}/{results['total_cases']})")
            sys.exit(1)
        else:
            print("\nâœ— æ‰€æœ‰ç—…ä¾‹åŒ¯å…¥å¤±æ•—")
            sys.exit(2)
    
    except Exception as e:
        print(f"\nâœ— åŸ·è¡ŒéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(3)


if __name__ == "__main__":
    main()