# s_cbr/utils/terminology_manager.py

'''
å–®ä¾‹æ¨¡å¼ (Singleton) çš„ç®¡ç†å™¨ï¼Œè² è²¬ç¶­è­·ç†±æ›´æ–°çš„è©žå½™è¡¨ã€‚
'''

import os
import json
from typing import Set
from threading import Lock

class TerminologyManager:
    _instance = None
    _lock = Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super(TerminologyManager, cls).__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
            
        # è¨­å®šè©žåº«æª”æ¡ˆè·¯å¾‘
        base_dir = os.path.dirname(os.path.abspath(__file__))
        self.db_path = os.path.join(os.path.dirname(__file__), "C:\work\ç³»çµ±-ä¸­é†«\Pulse-project\Backend\s_cbr\data\dynamic_tcm_terms.json")
        self.terms: Set[str] = set()
        self._load_terms()
        self._initialized = True
    
    def _load_terms(self):
            """è¼‰å…¥è©žåº« (åˆä½µæ¨¡å¼)"""
            if os.path.exists(self.db_path):
                try:
                    with open(self.db_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        # [é—œéµä¿®æ”¹] ä½¿ç”¨ update è€Œä¸æ˜¯ç›´æŽ¥è³¦å€¼ï¼Œç¢ºä¿èˆ‡è¨˜æ†¶é«”ç¾æœ‰æ•¸æ“šåˆä½µ
                        disk_terms = set(data.get("terms", []))
                        self.terms.update(disk_terms)
                except Exception as e:
                    print(f"è¼‰å…¥è©žåº«å¤±æ•— (å°‡ä½¿ç”¨ç¾æœ‰è¨˜æ†¶é«”æ•¸æ“š): {e}")
            else:
                # å¦‚æžœæª”æ¡ˆä¸å­˜åœ¨ï¼Œå»ºç«‹ç©ºçš„æˆ–ä½¿ç”¨é è¨­å€¼
                if not self.terms:
                    self.terms = {"å¿ƒæ‚¸", "æ°£çŸ­"} # æœ€å°ç¨®å­
                    self._save_terms()

    def _save_terms(self):
        """ä¿å­˜è©žåº«åˆ°ç¡¬ç¢Ÿ (åŽŸå­å¯«å…¥)"""
        try:
            os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
            
            # [ä¿®æ”¹] è®€å–ç¾æœ‰æª”æ¡ˆï¼Œç¢ºä¿ä¸è¦†è“‹æ‰‹å‹•ç·¨è¼¯
            current_disk_terms = set()
            if os.path.exists(self.db_path):
                try:
                    with open(self.db_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        current_disk_terms = set(data.get("terms", []))
                except:
                    pass
            
            # åˆä½µè¨˜æ†¶é«”èˆ‡ç¡¬ç¢Ÿ
            all_terms = self.terms.union(current_disk_terms)
            
            # å¯«å…¥
            with open(self.db_path, 'w', encoding='utf-8') as f:
                json.dump({"terms": list(all_terms), "count": len(all_terms)}, f, ensure_ascii=False, indent=2)
            
            # æ›´æ–°è¨˜æ†¶é«”
            self.terms = all_terms
            print(f"ðŸ’¾ [TerminologyManager] å·²åŒæ­¥å¯«å…¥ ({len(self.terms)} è©ž)")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜è©žåº«å¤±æ•—: {e}")

    def is_term(self, word: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºæ¨™æº–è¡“èªž (O(1) è¤‡é›œåº¦)"""
        return word in self.terms
        
    def add_term(self, word: str):
        """å­¸ç¿’æ–°è©žå½™"""
        if word and len(word) > 1:
            # ç›´æŽ¥å‘¼å« saveï¼Œè®“ save è² è²¬åˆä½µé‚è¼¯
            if word not in self.terms:
                self.terms.add(word)
                self._save_terms()
                print(f"ðŸ“– [TerminologyManager] å­¸ç¿’æ–°è©ž: {word}")

    def get_density(self, word_list: list) -> float:
        """è¨ˆç®—ä¸€çµ„è©žä¸­æœ‰å¤šå°‘æ˜¯æ¨™æº–è¡“èªž"""
        if not word_list: return 0.0
        hits = sum(1 for w in word_list if w in self.terms)
        return hits / len(word_list)