# -*- coding: utf-8 -*-
"""
SpiralEngineï¼šå‘é‡åŒ– â†’ å¤šç´¢å¼•æª¢ç´¢ â†’ åŠ æ¬Šèåˆ â†’ LLM æ½¤ç­† â†’ å›å‰ç«¯
- åµŒå…¥å™¨ï¼šNVIDIA nv-embedqa-e5-v5ï¼ˆ1024 ç¶­ï¼›å„ªå…ˆè®€ config.embedding.api_keyï¼‰
- æª¢ç´¢ï¼šCase / PulsePJ / RPCaseï¼ˆHybrid æˆ– BM25-onlyï¼‰
- èåˆï¼šå‘é‡åˆ† + è©é¢åˆ†ï¼ˆç¼ºå‘é‡æ™‚è‡ªå‹• vec_w=0ï¼‰
- LLMï¼šåƒ…ä¿®é£¾æ–‡å­—å“è³ªèˆ‡æ ¼å¼ï¼Œä¸è¼¸å‡ºæ²»ç™‚æ–¹æ¡ˆ
"""

import os
import re
import logging
from typing import Any, Dict, List, Optional, Tuple

# å…è¨±å¥—ä»¶/å–®æª”å…©ç¨®åŒ¯å…¥æ–¹å¼
try:
    from .search_engine import SearchEngine
except ImportError:
    from search_engine import SearchEngine

logger = logging.getLogger("s_cbr.SpiralEngine")
logger.setLevel(logging.INFO)


# ---------- NVIDIA å‘é‡å™¨ ----------
class NvidiaEmbedder:
    """
    ä»¥ NVIDIA integrate API ç”¢ç”Ÿ 1024 ç¶­å‘é‡
    - æ¨¡å‹ï¼šnvidia/nv-embedqa-e5-v5
    - input_type: "query"ï¼ˆæŸ¥è©¢ç”¨ï¼‰
    - é‡‘é‘°ä¾†æºï¼šå„ªå…ˆç”¨å»ºæ§‹å­å‚³å…¥ï¼›å¦å‰‡è®€ç’°å¢ƒè®Šæ•¸ NVIDIA_API_KEY / NV_API_KEY
    """
    def __init__(self, api_key: Optional[str] = None, model: str = "nvidia/nv-embedqa-e5-v5", timeout: int = 60):
        import requests  # å»¶é²åŒ¯å…¥
        self._requests = requests
        self.api_key = api_key or os.getenv("NVIDIA_API_KEY") or os.getenv("NV_API_KEY")
        if not self.api_key:
            raise RuntimeError("æœªè¨­å®š NVIDIA_API_KEY")
        self.model = model
        self.url = "https://integrate.api.nvidia.com/v1/embeddings"
        self.timeout = timeout
        self.dim = 1024

    def embed(self, text: str, input_type: str = "query") -> List[float]:
        r = self._requests.post(
            self.url,
            headers={"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"},
            json={"model": self.model, "input": [text], "input_type": input_type},
            timeout=self.timeout,
        )
        if not r.ok:
            raise RuntimeError(f"NVIDIA embeddings error: {r.status_code} {r.text[:200]}")
        vec = r.json()["data"][0]["embedding"]
        if len(vec) != self.dim:
            raise ValueError(f"Embedding ç¶­åº¦ {len(vec)} != {self.dim}")
        return vec


# ---------- å°å·¥å…· ----------
_PUNCT = r"[\s,;ï¼Œã€‚ï¼ï¼Ÿã€()\[\]{}:ï¼š/\\\-]+"

def _as_text(x: Any) -> str:
    if x is None: return ""
    if isinstance(x, str): return x
    if isinstance(x, (list, tuple, set)): return "ã€".join(map(_as_text, x))
    return str(x)

def _rough_tokens(s: str) -> List[str]:
    s = (s or "").strip()
    if not s: return []
    toks = [t for t in re.split(_PUNCT, s) if t]
    out: List[str] = []
    for t in toks:
        out.append(t)
        if re.search(r"[\u4e00-\u9fff]", t) and len(t) >= 2:
            out.extend([t[i:i+2] for i in range(len(t)-1)])
    seen = set(); ded = []
    for t in out:
        if t not in seen:
            ded.append(t); seen.add(t)
    return ded

def _overlap_score(q: str, doc: str) -> Tuple[float, List[str]]:
    q_toks = _rough_tokens(q)
    if not q_toks: return (0.0, [])
    hits = []
    seen = set()
    for tok in q_toks:
        if tok and tok in doc and tok not in seen:
            hits.append(tok); seen.add(tok)
    score = min(1.0, len(hits) / max(4, len(q_toks)))
    return score, hits[:8]


class SpiralEngine:
    def __init__(self, config: Any = None, search_engine: Optional[SearchEngine] = None, embedder: Any = None, llm: Any = None):
        """
        é‡è¦ï¼šé€™è£¡æœƒã€Œå„ªå…ˆè®€ config.embedding.api_keyã€æä¾›çµ¦ NvidiaEmbedder ä½¿ç”¨ã€‚
        è‹¥å¤–éƒ¨å·²æ³¨å…¥ embedderï¼Œå‰‡ç›´æ¥ä½¿ç”¨ä¹‹ã€‚
        """
        self.config = config
        self.search_engine = search_engine or SearchEngine(config)
        # åµŒå…¥å™¨æ±ºç­–ï¼šå„ªå…ˆå¤–éƒ¨ â†’ å…¶å¾Œè®€ config â†’ æœ€å¾Œæ‰ç”¨ç’°å¢ƒè®Šæ•¸
        if embedder is not None:
            self.embedder = embedder
        else:
            key_from_cfg = getattr(getattr(config, "embedding", None), "api_key", None)
            if key_from_cfg:
                # ç›´æ¥å»ºç«‹ NvidiaEmbedderï¼Œé‡‘é‘°å–è‡ª config
                self.embedder = NvidiaEmbedder(api_key=key_from_cfg)
            else:
                # æš«ä¸å»ºç«‹ï¼ŒåŸ·è¡Œæ™‚å†å˜—è©¦å¾ç’°å¢ƒè®Šæ•¸å»ºç«‹
                self.embedder = None
        # LLM å®¢æˆ¶ç«¯ï¼ˆå¯ç‚º Noneï¼‰ï¼šåªåšèªæ°£/æ ¼å¼æ½¤ç­†
        self.llm = llm or getattr(getattr(config, "llm", None), "client", None) or getattr(config, "llm_client", None)

    async def execute_spiral_cycle(self, question: str, session_id: str, alpha: float = 0.5, limit: int = 10) -> Dict[str, Any]:
        # 1) å‘é‡ï¼ˆå¯ç¼ºçœï¼‰
        q_vec: List[float] = []
        try:
            if self.embedder is None:
                # ä»å¯å¾ç’°å¢ƒè®Šæ•¸å»ºç«‹å‚™æ´
                self.embedder = NvidiaEmbedder()
            if hasattr(self.embedder, "embed"):
                q_vec = self.embedder.embed(question, input_type="query")
        except Exception as e:
            logger.warning(f"[Spiral] ç”¢ç”Ÿå‘é‡å¤±æ•—ï¼Œæ”¹ BM25-onlyï¼š{e}")
            q_vec = []
        logger.info(f"ğŸ§­ q_vector: dim={len(q_vec)}")

        # 2) ä¸‰ç´¢å¼•æª¢ç´¢
        se = self.search_engine
        case_hits  = await se.hybrid_search("Case",    text=question, vector=(q_vec or None), alpha=alpha, limit=limit)
        pulse_hits = await se.hybrid_search("PulsePJ", text=question, vector=(q_vec or None), alpha=alpha, limit=limit)
        rpc_hits   = await se.hybrid_search("RPCase",  text=question, vector=(q_vec or None), alpha=alpha, limit=max(2, limit//2))

        logger.info(f"ğŸ“Š Case: {len(case_hits)} | PulsePJ: {len(pulse_hits)} | RPCase: {len(rpc_hits)}")

        if not (case_hits or pulse_hits or rpc_hits):
            return {
                "text": "ã€ç³»çµ±è¨Šæ¯ã€‘æœªæª¢ç´¢åˆ°ç›¸è¿‘å…§å®¹ã€‚è«‹è£œå……èˆŒè„ˆã€ç—‡ç‹€æ™‚åºèˆ‡å½±éŸ¿å› å­å¾Œé‡è©¦ã€‚",
                "diagnosis": "",
                "evidence": [],
                "advice": ["è£œå……èˆŒè‰²/è‹”è±¡èˆ‡å¯¸é—œå°ºè„ˆè±¡", "æè¿°ç™¼ç”Ÿæ™‚ç¨‹èˆ‡èª˜å› ï¼ˆæƒ…å¿—/é£²é£Ÿ/ä½œæ¯ï¼‰"],
                "meta": {"retrieval": {"Case":0,"PulsePJ":0,"RPCase":0}, "qdim": len(q_vec)},
            }

        # 3) çµ±ä¸€å€™é¸
        def _score(h: Dict[str, Any]) -> float:
            try:
                return float((h.get("_additional") or {}).get("score") or h.get("_confidence") or 0.0)
            except Exception:
                return 0.0

        def _case(h):
            return {
                "source": "Case",
                "id": h.get("src_casev_uuid") or h.get("case_id") or "",
                "diagnosis": _as_text(h.get("diagnosis_main")),
                "pulse": _as_text(h.get("pulse_text")),
                "symptoms": (_as_text(h.get("chiefComplaint")) + " " + _as_text(h.get("presentIllness"))).strip(),
                "_v": _score(h), "raw": h,
            }

        def _pulse(h):
            return {
                "source": "PulsePJ",
                "id": h.get("pid") or h.get("category_id") or "",
                "diagnosis": _as_text(h.get("name")),
                "pulse": "",
                "symptoms": _as_text(h.get("symptoms")),
                "_v": _score(h), "raw": h,
            }

        def _rpc(h):
            return {
                "source": "RPCase",
                "id": h.get("rid") or "",
                "diagnosis": _as_text(h.get("final_diagnosis")),
                "pulse": _as_text(h.get("pulse_tags")),
                "symptoms": _as_text(h.get("symptom_tags")),
                "_v": _score(h), "raw": h,
            }

        cands: List[Dict[str, Any]] = list(map(_case, case_hits)) + list(map(_pulse, pulse_hits)) + list(map(_rpc, rpc_hits))

        # 4) èåˆï¼ˆå‘é‡åˆ† + è©é¢åˆ†ï¼‰
        vec_w = 0.55 if q_vec else 0.0
        lex_w = 1.0 - vec_w
        for c in cands:
            doc = " ".join([c.get("diagnosis",""), c.get("pulse",""), c.get("symptoms","")])
            lex, hits = _overlap_score(question, doc)
            final = vec_w * max(0.0, float(c.get("_v",0.0))) + lex_w * lex
            src_boost = {"Case": 1.00, "RPCase": 0.98, "PulsePJ": 0.95}.get(c["source"], 1.0)
            c["_lex"] = lex
            c["_final"] = final * src_boost
            c["_hits"] = hits
        cands.sort(key=lambda x: x["_final"], reverse=True)
        best = cands[0]

        # 5) çµ„è£è¼¸å‡ºï¼ˆäº¤çµ¦ LLM æ½¤ç­†ï¼‰
        conclusion = (
            best.get("diagnosis") or
            _as_text(best.get("raw", {}).get("diagnosis_main")) or
            _as_text(best.get("raw", {}).get("final_diagnosis")) or
            _as_text(best.get("raw", {}).get("name")) or
            "æ ¹æ“šç›¸è¿‘æ¡ˆä¾‹æ¨æ¸¬ä¹‹å€™é¸è­‰å€™"
        ).strip()

        evid = []
        if best.get("_hits"):
            evid.append("ç‰¹å¾µå°æ‡‰ï¼š" + "ã€".join(best["_hits"]))
        if best["source"] == "Case":
            if best.get("pulse"):    evid.append(f"è„ˆè±¡ï¼š{best['pulse'][:240]}{'â€¦' if len(best['pulse'])>240 else ''}")
            if best.get("symptoms"): evid.append(f"ä¸»è¨´/ç¾ç—…å²ï¼š{best['symptoms'][:240]}{'â€¦' if len(best['symptoms'])>240 else ''}")
        elif best["source"] == "RPCase":
            if best.get("pulse"):    evid.append(f"è„ˆè±¡è¦ç´ ï¼š{best['pulse']}")
            if best.get("symptoms"): evid.append(f"ç—‡ç‹€è¦ç´ ï¼š{best['symptoms']}")
        else:
            if best.get("symptoms"): evid.append(f"æ¢æ–‡/ç—‡ç‹€ï¼š{best['symptoms']}")
        evid.append(f"èåˆåˆ†ï¼šå‘é‡ {best.get('_v',0.0):.2f} + è©é¢ {best.get('_lex',0.0):.2f} â†’ æœ€çµ‚ {best.get('_final',0.0):.2f}")

        advice = [
            "è£œé½Šå¯¸é—œå°ºè„ˆè±¡çš„å…·é«”è§€å¯Ÿã€‚",
            "ç´€éŒ„ç¡çœ çš„å…¥ç¡æ½›ä¼æœŸã€å¤œé†’æ¬¡æ•¸/æ™‚æ®µã€æ—©é†’èˆ‡å¤¢å¢ƒæ€§è³ªã€‚",
            "æ¨™è¨»èª˜å› ï¼šæƒ…å¿—ã€å’–å•¡å› /é…’ç²¾ã€ä½œæ¯è®ŠåŒ–ã€åˆä½µç—‡æˆ–ç”¨è—¥å²ã€‚",
            "1~2 é€±å¾Œæ›´æ–°è³‡æ–™å¯æé«˜ç›¸ä¼¼æ¡ˆä¾‹çš„æº–ç¢ºåº¦ã€‚",
        ]

        base = (
            f"ã€è¨ºæ–·çµæœï¼ˆçµè«–ï¼‰ã€‘\n{conclusion}\n\n"
            f"ã€ä¾æ“šã€‘\n- " + "\n- ".join(evid) + "\n\n"
            f"ã€å»ºè­°ï¼ˆéæ²»ç™‚ï¼‰ã€‘\n- " + "\n- ".join(advice)
        )
        final_text = base
        if self.llm:
            try:
                prompt = (
                    "è«‹ä»¥å°ˆæ¥­è€Œç²¾ç°¡çš„ä¸­æ–‡ï¼Œå°‡ä¸‹åˆ—è‡¨åºŠæ‘˜è¦æ½¤ç­†ï¼Œç¶­æŒä¸‰æ®µï¼š"
                    "ã€è¨ºæ–·çµæœï¼ˆçµè«–ï¼‰ã€‘ã€ä¾æ“šã€‘ã€å»ºè­°ï¼ˆéæ²»ç™‚ï¼‰ã€‘ï¼›"
                    "ä¸å¯åŠ å…¥ä»»ä½•æ²»ç™‚æ–¹æ¡ˆã€è—¥æ–¹æˆ–åŠ‘é‡ï¼›é¿å…å†—é•·èˆ‡å£èªã€‚\n====\n" + base
                )
                if hasattr(self.llm, "generate"):
                    final_text = self.llm.generate(prompt=prompt, model=getattr(getattr(self.config, "llm", None), "model", None))
                elif hasattr(self.llm, "chat"):
                    final_text = self.llm.chat(prompt=prompt, model=getattr(getattr(self.config, "llm", None), "model", None))
            except Exception as e:
                logger.warning(f"[Spiral] LLM æ½¤ç­†å¤±æ•—ï¼Œä½¿ç”¨åŸæ–‡ï¼š{e}")
                final_text = base

        return {
            "text": final_text,
            "diagnosis": conclusion,
            "evidence": evid,
            "advice": advice,
            "meta": {
                "retrieval": {"Case": len(case_hits), "PulsePJ": len(pulse_hits), "RPCase": len(rpc_hits)},
                "qdim": len(q_vec),
                "best": {"source": best["source"], "id": best.get("id"),
                         "scores": {"vector": best.get("_v",0.0), "lexical": best.get("_lex",0.0), "final": best.get("_final",0.0)}}
            },
        }
