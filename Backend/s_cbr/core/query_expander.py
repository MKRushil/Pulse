# -*- coding: utf-8 -*-
"""
Backend/s_cbr/core/query_expander.py
æŸ¥è©¢æ“´å……å™¨ - åŒç¾©è©æ˜ å°„ã€å¦å®šè©ç¶å®šã€æŸ¥è©¢é‡æ§‹
"""

from typing import Dict, List, Set, Tuple
import re
from dataclasses import dataclass
from ..utils.logger import get_logger

logger = get_logger("QueryExpander")

@dataclass
class ExpansionConfig:
    """æŸ¥è©¢æ“´å……é…ç½®"""
    # é‡è¤‡æ¬Šé‡
    original_weight: int = 3  # åŸè©é‡è¤‡ 3 æ¬¡
    synonym_weight: int = 1   # åŒç¾©è©é‡è¤‡ 1 æ¬¡
    mapping_weight: int = 1   # æ˜ å°„è©é‡è¤‡ 1 æ¬¡
    
    # å•Ÿç”¨åŠŸèƒ½é–‹é—œ
    enable_synonym: bool = True
    enable_negation_binding: bool = True
    enable_tcm_mapping: bool = True

class QueryExpander:
    """æŸ¥è©¢æ“´å……å™¨"""
    
    def __init__(self, config: ExpansionConfig = None):
        self.config = config or ExpansionConfig()
        
        # ==================== åŒç¾©è©æ˜ å°„è¡¨ ====================
        self.synonym_map = {
            # ç¡çœ ç›¸é—œ
            "æ˜“é†’": ["ç¡çœ æ·º", "é©šé†’", "å¤šé†’"],
            "ç¡çœ æ·º": ["æ˜“é†’", "ç¡ä¸å®‰ç©©"],
            "å…¥ç¡é›£": ["å…¥ç¡å›°é›£", "é›£ä»¥å…¥çœ "],
            
            # å¿ƒæ‚¸ç›¸é—œ
            "å¿ƒæ‚¶": ["èƒ¸æ‚¶", "å¿ƒèƒ¸æ‚¶"],
            "å¿ƒæ…Œ": ["å¿ƒæ‚¸", "å¿ƒè·³å¿«"],
            "å¿ƒç…©": ["ç…©èº", "å¿ƒä¸­ç…©ç†±"],
            
            # å£ä¹¾ç›¸é—œ
            "å£ä¹¾": ["å£æ¸´", "å’½ä¹¾"],
            "æ¬²æº«é£²": ["å£ä¹¾å–œé£²æº«æ°´", "å–œæº«é£²"],
            "æ¬²å†·é£²": ["å£ä¹¾å–œå†·é£²", "å–œå†·é£²"],
            
            # ç–¼ç—›ç›¸é—œ
            "é ­ç—›": ["é ­ç–¼", "è…¦ç—›"],
            "è…¹ç—›": ["è‚šå­ç—›", "è…¹éƒ¨ç–¼ç—›"],
            "èƒ¸ç—›": ["èƒ¸å£ç—›", "å‰èƒ¸ç—›"],
            
            # ç–²å‹ç›¸é—œ
            "ç–²å€¦": ["ä¹åŠ›", "å€¦æ€ ", "ç–²å‹"],
            "ä¹åŠ›": ["ç„¡åŠ›", "ç¥ç–²", "æ°£çŸ­ä¹åŠ›"],
            
            # æ¶ˆåŒ–ç›¸é—œ
            "é£Ÿæ…¾ä¸æŒ¯": ["èƒƒå£å·®", "ä¸æƒ³åƒ", "ç´å·®"],
            "è…¹è„¹": ["è‚šå­è„¹", "èƒƒè„¹", "è„¹æ»¿"],
            "ä¾¿ç§˜": ["å¤§ä¾¿ä¹¾", "å¤§ä¾¿é›£", "æ’ä¾¿å›°é›£"],
            "è…¹ç€‰": ["æ‹‰è‚šå­", "ä¾¿æº", "å¤§ä¾¿ç¨€"],
            
            # æƒ…å¿—ç›¸é—œ
            "ç„¦æ…®": ["æ“”å¿ƒ", "ç·Šå¼µ", "å¿ƒç¥ä¸å¯§"],
            "æŠ‘é¬±": ["æƒ…ç·’ä½è½", "å¿ƒæƒ…ä½è½", "ä¸é–‹å¿ƒ"],
            "æ˜“æ€’": ["å®¹æ˜“ç”Ÿæ°£", "ç…©èºæ˜“æ€’"],
        }
        
        # ==================== ä¸­é†«æ˜ å°„è¡¨ ====================
        self.tcm_mapping = {
            # èˆŒè±¡æ˜ å°„
            "èˆŒå°–ç´…": ["å¿ƒç«", "é™°è™›ç«æ—º"],
            "èˆŒè³ªæ·¡": ["æ°£è¡€è™›", "é™½è™›"],
            "èˆŒè³ªç´…": ["ç†±è­‰", "é™°è™›"],
            "èˆŒç´«æš—": ["è¡€ç˜€", "æ°£æ»¯è¡€ç˜€"],
            "èˆŒè‹”åšè†©": ["ç—°æ¿•", "æ¿•ç†±"],
            
            # è„ˆè±¡æ˜ å°„
            "ç´°è„ˆ": ["è¡€è™›", "é™°è™›"],
            "é²è„ˆ": ["å¯’è­‰", "é™½è™›"],
            "æ•¸è„ˆ": ["ç†±è­‰", "é™°è™›ç«æ—º"],
            "å¼¦è„ˆ": ["è‚é¬±", "è‚é™½ä¸Šäº¢"],
            "æ»‘è„ˆ": ["ç—°æ¿•", "é£Ÿç©"],
            
            # ç—‡ç‹€æ˜ å°„
            "æ‰‹è¶³å†°å†·": ["é™½è™›", "å¯’è­‰"],
            "äº”å¿ƒç…©ç†±": ["é™°è™›", "é™°è™›ç«æ—º"],
            "ç›œæ±—": ["é™°è™›", "ç‡Ÿè¡›ä¸å’Œ"],
            "è‡ªæ±—": ["æ°£è™›", "é™½è™›"],
            "æ½®ç†±": ["é™°è™›", "æ¿•ç†±"],
        }
        
        # ==================== å¦å®šè©åˆ—è¡¨ ====================
        self.negation_words = {
            "ç„¡", "æ²’æœ‰", "ä¸", "æœª", "é", "å¦",
            "æ²’", "ç„¡æ˜é¡¯", "ä¸å¤ª", "ä¸æ€éº¼"
        }
        
        # ==================== ç¨‹åº¦è©åˆ—è¡¨ ====================
        self.degree_words = {
            "å¾ˆ", "éå¸¸", "ç‰¹åˆ¥", "æ¥µ", "ç¨", "ç•¥",
            "æœ‰é»", "æ¯”è¼ƒ", "è¼ƒ", "äº›è¨±", "è¼•å¾®"
        }
        
        logger.info("âœ… æŸ¥è©¢æ“´å……å™¨åˆå§‹åŒ–")
        logger.info(f"   åŒç¾©è©æ˜ å°„: {len(self.synonym_map)} çµ„")
        logger.info(f"   ä¸­é†«æ˜ å°„: {len(self.tcm_mapping)} çµ„")
    
    # ==================== æ ¸å¿ƒæ“´å……æ–¹æ³• ====================
    def expand_query(
        self,
        query: str,
        symptoms: List[str] = None
    ) -> Dict[str, any]:
        """
        å®Œæ•´æŸ¥è©¢æ“´å……
        
        Args:
            query: åŸå§‹æŸ¥è©¢
            symptoms: æå–çš„ç—‡ç‹€åˆ—è¡¨ï¼ˆå¯é¸ï¼‰
            
        Returns:
            {
                "original": åŸå§‹æŸ¥è©¢,
                "expanded": æ“´å……å¾ŒæŸ¥è©¢,
                "tokens": [æ“´å……è©é …åˆ—è¡¨],
                "negations": [å¦å®šè©ç¶å®š],
                "mappings": {è©é …: [æ˜ å°„è©]}
            }
        """
        result = {
            "original": query,
            "expanded": "",
            "tokens": [],
            "negations": [],
            "mappings": {}
        }
        
        # 1. å¦å®šè©ç¶å®š
        if self.config.enable_negation_binding:
            bound_query, negations = self._bind_negations(query)
            result["negations"] = negations
        else:
            bound_query = query
        
        # 2. æå–ç—‡ç‹€ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if symptoms is None:
            symptoms = self._extract_symptoms_from_query(bound_query)
        
        # 3. æ§‹å»ºæ“´å……è©é …
        expanded_tokens = []
        
        for symptom in symptoms:
            # åŸè©ï¼ˆé‡è¤‡ N æ¬¡ï¼‰
            expanded_tokens.extend([symptom] * self.config.original_weight)
            
            # åŒç¾©è©æ“´å……
            if self.config.enable_synonym:
                synonyms = self.synonym_map.get(symptom, [])
                for syn in synonyms:
                    expanded_tokens.extend([syn] * self.config.synonym_weight)
                    
                if synonyms:
                    result["mappings"][symptom] = {
                        "type": "synonym",
                        "terms": synonyms
                    }
            
            # ä¸­é†«æ˜ å°„æ“´å……
            if self.config.enable_tcm_mapping:
                mappings = self.tcm_mapping.get(symptom, [])
                for mapping in mappings:
                    expanded_tokens.extend([mapping] * self.config.mapping_weight)
                    
                if mappings:
                    if symptom in result["mappings"]:
                        result["mappings"][symptom]["tcm_terms"] = mappings
                    else:
                        result["mappings"][symptom] = {
                            "type": "tcm",
                            "terms": mappings
                        }
        
        # 4. æ§‹å»ºæ“´å……æŸ¥è©¢
        result["tokens"] = expanded_tokens
        result["expanded"] = " ".join(expanded_tokens)
        
        logger.info(f"ğŸ” æŸ¥è©¢æ“´å……:")
        logger.info(f"   åŸå§‹: {query[:50]}...")
        logger.info(f"   ç—‡ç‹€æ•¸: {len(symptoms)}")
        logger.info(f"   æ“´å……è©é …æ•¸: {len(expanded_tokens)}")
        logger.info(f"   å¦å®šç¶å®š: {len(result['negations'])} å€‹")
        logger.info(f"   æ˜ å°„: {len(result['mappings'])} å€‹")
        
        return result
    
    # ==================== å¦å®šè©ç¶å®š ====================
    def _bind_negations(self, text: str) -> Tuple[str, List[str]]:
        """
        ç¶å®šå¦å®šè©èˆ‡å¾ŒçºŒè©é …
        
        ä¾‹å¦‚ï¼šã€Œç„¡å’³å—½ã€â†’ã€Œç„¡_å’³å—½ã€
        
        Returns:
            (ç¶å®šå¾Œæ–‡æœ¬, [å¦å®šè©çµ„åˆ—è¡¨])
        """
        bound_text = text
        negations = []
        
        # å¦å®šæ¨¡å¼ï¼šå¦å®šè© + 1-4å€‹å­—çš„ç—‡ç‹€
        pattern = r'(' + '|'.join(self.negation_words) + r')([^\sï¼Œã€‚ï¼›]{1,4})'
        
        matches = re.finditer(pattern, text)
        
        for match in matches:
            negation = match.group(1)
            symptom = match.group(2)
            
            # æ§‹å»ºç¶å®šè©
            bound_term = f"{negation}_{symptom}"
            negations.append(bound_term)
            
            # æ›¿æ›åŸæ–‡æœ¬
            bound_text = bound_text.replace(
                match.group(0),
                bound_term
            )
        
        if negations:
            logger.debug(f"   å¦å®šè©ç¶å®š: {negations}")
        
        return bound_text, negations
    
    # ==================== ç¨‹åº¦è©ç¶å®š ====================
    def _bind_degrees(self, text: str) -> Tuple[str, List[str]]:
        """
        ç¶å®šç¨‹åº¦è©èˆ‡ç—‡ç‹€
        
        ä¾‹å¦‚ï¼šã€Œå¾ˆå£ä¹¾ã€â†’ã€Œå¾ˆ_å£ä¹¾ã€
        """
        bound_text = text
        degree_terms = []
        
        # ç¨‹åº¦è©æ¨¡å¼
        pattern = r'(' + '|'.join(self.degree_words) + r')([^\sï¼Œã€‚ï¼›]{1,4})'
        
        matches = re.finditer(pattern, text)
        
        for match in matches:
            degree = match.group(1)
            symptom = match.group(2)
            
            bound_term = f"{degree}_{symptom}"
            degree_terms.append(bound_term)
            
            bound_text = bound_text.replace(
                match.group(0),
                bound_term
            )
        
        return bound_text, degree_terms
    
    # ==================== ç—‡ç‹€æå– ====================
    def _extract_symptoms_from_query(self, query: str) -> List[str]:
        """å¾æŸ¥è©¢ä¸­æå–ç—‡ç‹€é—œéµè©"""
        symptoms = []
        
        # æª¢æŸ¥æ‰€æœ‰åŒç¾©è©æ˜ å°„ä¸­çš„é—œéµè©
        all_keywords = set(self.synonym_map.keys())
        for synonyms in self.synonym_map.values():
            all_keywords.update(synonyms)
        
        # æª¢æŸ¥ä¸­é†«æ˜ å°„ä¸­çš„é—œéµè©
        all_keywords.update(self.tcm_mapping.keys())
        
        # æŸ¥æ‰¾åŒ¹é…
        for keyword in all_keywords:
            if keyword in query:
                symptoms.append(keyword)
        
        return symptoms
    
    # ==================== åŒç¾©è©æŸ¥è©¢ ====================
    def get_synonyms(self, term: str) -> List[str]:
        """ç²å–è©é …çš„åŒç¾©è©"""
        # ç›´æ¥æŸ¥æ‰¾
        if term in self.synonym_map:
            return self.synonym_map[term]
        
        # åå‘æŸ¥æ‰¾
        for key, synonyms in self.synonym_map.items():
            if term in synonyms:
                return [key] + [s for s in synonyms if s != term]
        
        return []
    
    def get_tcm_mappings(self, term: str) -> List[str]:
        """ç²å–è©é …çš„ä¸­é†«æ˜ å°„"""
        return self.tcm_mapping.get(term, [])
    
    # ==================== æ·»åŠ è‡ªå®šç¾©æ˜ å°„ ====================
    def add_synonym(self, term: str, synonyms: List[str]):
        """æ·»åŠ åŒç¾©è©æ˜ å°„"""
        if term in self.synonym_map:
            self.synonym_map[term].extend(synonyms)
            self.synonym_map[term] = list(set(self.synonym_map[term]))
        else:
            self.synonym_map[term] = synonyms
        
        logger.info(f"â• æ·»åŠ åŒç¾©è©æ˜ å°„: {term} â†’ {synonyms}")
    
    def add_tcm_mapping(self, term: str, mappings: List[str]):
        """æ·»åŠ ä¸­é†«æ˜ å°„"""
        if term in self.tcm_mapping:
            self.tcm_mapping[term].extend(mappings)
            self.tcm_mapping[term] = list(set(self.tcm_mapping[term]))
        else:
            self.tcm_mapping[term] = mappings
        
        logger.info(f"â• æ·»åŠ ä¸­é†«æ˜ å°„: {term} â†’ {mappings}")