# -*- coding: utf-8 -*-
"""
Backend/s_cbr/core/dynamic_retrieval.py
å‹•æ…‹æª¢ç´¢å„ªåŒ–å™¨ - å¯¦ç¾å‹•æ…‹ Î±ã€å¤šæ¬„ä½åŠ æ¬Šã€RRF èåˆ
"""

from typing import Dict, List, Tuple, Optional, Any
import numpy as np
from dataclasses import dataclass
from ..utils.logger import get_logger

logger = get_logger("DynamicRetrieval")

@dataclass
class RetrievalConfig:
    """æª¢ç´¢é…ç½®"""
    # æ¬„ä½æ¬Šé‡ï¼ˆç”¨æ–¼ BM25 å’Œå‘é‡åŠ æ¬Šï¼‰
    field_weights: Dict[str, float] = None
    
    # Î± å‹•æ…‹èª¿æ•´ç¯„åœ
    alpha_min: float = 0.35
    alpha_max: float = 0.70
    alpha_base: float = 0.3
    alpha_increment: float = 0.05
    
    # Top-k è¨­å®š
    initial_k: int = 30
    final_k: int = 10
    
    # RRF åƒæ•¸
    rrf_k: int = 60
    
    # MMR åƒæ•¸
    mmr_lambda: float = 0.7
    mmr_threshold: float = 0.85
    
    def __post_init__(self):
        if self.field_weights is None:
            self.field_weights = {
                "symptom_terms": 1.0,
                "pulse_terms": 1.2,
                "tongue_terms": 1.2,
                "zangfu_terms": 0.9,
                "syndrome_terms": 1.1,
                "jieba_tokens": 0.6
            }

class DynamicRetrievalOptimizer:
    """å‹•æ…‹æª¢ç´¢å„ªåŒ–å™¨"""
    
    def __init__(self, config: RetrievalConfig = None):
        self.config = config or RetrievalConfig()
        logger.info("âœ… å‹•æ…‹æª¢ç´¢å„ªåŒ–å™¨åˆå§‹åŒ–")
        logger.info(f"   æ¬„ä½æ¬Šé‡: {self.config.field_weights}")
    
    # ==================== A1: å‹•æ…‹ Î± è¨ˆç®— ====================
    def calculate_dynamic_alpha(
        self,
        round_num: int,
        symptom_count: int,
        coverage: float = 0.0,
        is_rpcase_empty: bool = False
    ) -> float:
        """
        å‹•æ…‹è¨ˆç®— Î± å€¼
        
        ç­–ç•¥ï¼š
        1. åŸºç¤å…¬å¼ï¼šÎ± = clip(0.3 + 0.05*m, 0.35, 0.70)
        2. è¼ªæ¬¡èª¿æ•´ï¼šç¬¬1è¼ªå BM25ï¼Œç¬¬2è¼ªèµ·åå‘é‡
        3. è¦†è“‹ç‡èª¿æ•´ï¼šCoverage<0.4 é™ä½ Î±
        4. RPCase ç©ºé›†è™•ç†ï¼šé™ä½ Î± é‡æœ
        
        Args:
            round_num: ç•¶å‰è¼ªæ¬¡
            symptom_count: æœ‰æ•ˆç—‡ç‹€æ•¸é‡
            coverage: ç•¶å‰è¦†è“‹ç‡
            is_rpcase_empty: RPCase æ˜¯å¦ç‚ºç©º
            
        Returns:
            å‹•æ…‹èª¿æ•´å¾Œçš„ Î± å€¼
        """
        # åŸºç¤è¨ˆç®—
        m = symptom_count
        base_alpha = np.clip(
            self.config.alpha_base + self.config.alpha_increment * m,
            self.config.alpha_min,
            self.config.alpha_max
        )
        
        # è¼ªæ¬¡èª¿æ•´
        if round_num == 1:
            # ç¬¬1è¼ªï¼šå BM25ï¼ˆ0.4Â±0.05ï¼‰
            round_alpha = 0.4 + np.random.uniform(-0.05, 0.05)
        elif round_num == 2:
            # ç¬¬2è¼ªï¼šåå‘é‡ï¼ˆ0.6Â±0.1ï¼‰
            round_alpha = 0.6 + np.random.uniform(-0.1, 0.1)
        else:
            # ç¬¬3è¼ªèµ·ï¼šæ›´åå‘é‡ï¼ˆ0.65Â±0.1ï¼‰
            round_alpha = 0.65 + np.random.uniform(-0.1, 0.1)
        
        # åŠ æ¬Šèåˆ
        alpha = 0.6 * base_alpha + 0.4 * round_alpha
        
        # è¦†è“‹ç‡èª¿æ•´ï¼šCoverage < 0.4 é™ä½ Î±ï¼ˆå› BM25ï¼‰
        if coverage < 0.4:
            alpha *= 0.85
            logger.info(f"   âš ï¸  Coverage={coverage:.2f} < 0.4ï¼Œé™ä½ Î±")
        
        # RPCase ç©ºé›†èª¿æ•´
        if is_rpcase_empty:
            alpha *= 0.9
            logger.info(f"   âš ï¸  RPCase ç‚ºç©ºï¼Œé™ä½ Î±")
        
        # æœ€çµ‚é™åˆ¶ç¯„åœ
        alpha = np.clip(alpha, self.config.alpha_min, self.config.alpha_max)
        
        logger.info(f"ğŸ¯ å‹•æ…‹ Î± è¨ˆç®— [ç¬¬{round_num}è¼ª]:")
        logger.info(f"   ç—‡ç‹€æ•¸={m}, è¦†è“‹ç‡={coverage:.2f}")
        logger.info(f"   åŸºç¤Î±={base_alpha:.3f}, è¼ªæ¬¡Î±={round_alpha:.3f}")
        logger.info(f"   æœ€çµ‚Î±={alpha:.3f}")
        
        return alpha
    
    # ==================== A2: å¤šæ¬„ä½åŠ æ¬Š ====================
    def get_weighted_search_fields(
        self,
        available_fields: List[str]
    ) -> List[Tuple[str, float]]:
        """
        ç²å–åŠ æ¬Šå¾Œçš„æœç´¢æ¬„ä½
        
        Returns:
            [(field_name, weight), ...]
        """
        weighted_fields = []
        for field in available_fields:
            weight = self.config.field_weights.get(field, 1.0)
            weighted_fields.append((field, weight))
        
        # æŒ‰æ¬Šé‡é™åºæ’åˆ—
        weighted_fields.sort(key=lambda x: x[1], reverse=True)
        
        logger.info(f"ğŸ“Š åŠ æ¬Šæœç´¢æ¬„ä½: {weighted_fields}")
        return weighted_fields
    
    # ==================== A4: RRF èåˆ ====================
    def reciprocal_rank_fusion(
        self,
        rankings: List[List[Dict[str, Any]]],
        k: int = 60
    ) -> List[Dict[str, Any]]:
        """
        RRF (Reciprocal Rank Fusion) èåˆå¤šå€‹æ’åºçµæœ
        
        å…¬å¼ï¼šRRF(d) = Î£ 1/(k + rank_i(d))
        
        Args:
            rankings: å¤šå€‹æ’åºåˆ—è¡¨ [[doc1, doc2, ...], [doc1, doc3, ...], ...]
            k: RRF å¸¸æ•¸ï¼Œé€šå¸¸ç‚º 60
            
        Returns:
            èåˆå¾Œçš„æ’åºåˆ—è¡¨
        """
        # æ”¶é›†æ‰€æœ‰æ–‡æª”åŠå…¶ RRF åˆ†æ•¸
        doc_scores = {}
        
        for ranking in rankings:
            for rank, doc in enumerate(ranking, 1):
                doc_id = self._get_doc_id(doc)
                
                # RRF åˆ†æ•¸ç´¯åŠ 
                rrf_score = 1.0 / (k + rank)
                
                if doc_id not in doc_scores:
                    doc_scores[doc_id] = {
                        'doc': doc,
                        'rrf_score': 0.0,
                        'appearances': 0
                    }
                
                doc_scores[doc_id]['rrf_score'] += rrf_score
                doc_scores[doc_id]['appearances'] += 1
        
        # è½‰æ›ç‚ºåˆ—è¡¨ä¸¦æ’åº
        fused_results = [
            {
                **item['doc'],
                '_rrf_score': item['rrf_score'],
                '_appearances': item['appearances']
            }
            for item in doc_scores.values()
        ]
        
        fused_results.sort(key=lambda x: x['_rrf_score'], reverse=True)
        
        logger.info(f"ğŸ”€ RRF èåˆ: {len(rankings)} å€‹æ’åº â†’ {len(fused_results)} å€‹çµæœ")
        
        return fused_results
    
    # ==================== A4: MMR å»é‡ ====================
    def maximal_marginal_relevance(
        self,
        documents: List[Dict[str, Any]],
        lambda_param: float = 0.7,
        similarity_threshold: float = 0.85,
        max_results: int = 10
    ) -> List[Dict[str, Any]]:
        """
        MMR (Maximal Marginal Relevance) å¤šæ¨£æ€§é‡æ’
        
        å¹³è¡¡ç›¸é—œæ€§å’Œå¤šæ¨£æ€§ï¼š
        MMR = Î» * Relevance - (1-Î») * max(Similarity)
        
        Args:
            documents: å¾…é‡æ’çš„æ–‡æª”åˆ—è¡¨
            lambda_param: ç›¸é—œæ€§æ¬Šé‡ï¼ˆ0.7 = 70% ç›¸é—œæ€§ + 30% å¤šæ¨£æ€§ï¼‰
            similarity_threshold: ç›¸ä¼¼åº¦é–¾å€¼ï¼Œè¶…éå‰‡èªç‚ºé‡è¤‡
            max_results: æœ€å¤§è¿”å›æ•¸é‡
            
        Returns:
            MMR é‡æ’å¾Œçš„æ–‡æª”åˆ—è¡¨
        """
        if not documents:
            return []
        
        selected = []
        remaining = documents.copy()
        
        # é¸æ“‡ç¬¬ä¸€å€‹ï¼ˆæœ€ç›¸é—œçš„ï¼‰
        selected.append(remaining.pop(0))
        
        while remaining and len(selected) < max_results:
            best_score = -float('inf')
            best_idx = -1
            
            for idx, doc in enumerate(remaining):
                # ç›¸é—œæ€§åˆ†æ•¸
                relevance = doc.get('_rrf_score', doc.get('_confidence', 0))
                
                # èˆ‡å·²é¸æ–‡æª”çš„æœ€å¤§ç›¸ä¼¼åº¦
                max_similarity = 0.0
                for selected_doc in selected:
                    sim = self._calculate_similarity(doc, selected_doc)
                    max_similarity = max(max_similarity, sim)
                
                # MMR åˆ†æ•¸
                mmr_score = lambda_param * relevance - (1 - lambda_param) * max_similarity
                
                if mmr_score > best_score:
                    best_score = mmr_score
                    best_idx = idx
            
            if best_idx >= 0:
                selected.append(remaining.pop(best_idx))
        
        logger.info(f"ğŸ¨ MMR é‡æ’: {len(documents)} â†’ {len(selected)} å€‹ï¼ˆÎ»={lambda_param}ï¼‰")
        
        return selected
    
    # ==================== è¼”åŠ©æ–¹æ³• ====================
    def _get_doc_id(self, doc: Dict[str, Any]) -> str:
        """ç²å–æ–‡æª”å”¯ä¸€ ID"""
        # å˜—è©¦å¤šç¨®å¯èƒ½çš„ ID æ¬„ä½
        for key in ['case_id', 'pid', 'rid', 'id', '_id']:
            if key in doc:
                return str(doc[key])
        
        # Fallback: ä½¿ç”¨å‰å¹¾å€‹æ¬„ä½çš„çµ„åˆ
        return hash(frozenset(doc.items()))
    
    def _calculate_similarity(
        self,
        doc1: Dict[str, Any],
        doc2: Dict[str, Any]
    ) -> float:
        """è¨ˆç®—å…©å€‹æ–‡æª”çš„ç›¸ä¼¼åº¦"""
        # åŸºæ–¼ç—‡ç‹€çš„ Jaccard ç›¸ä¼¼åº¦
        symptoms1 = set(doc1.get('_hits', []))
        symptoms2 = set(doc2.get('_hits', []))
        
        if not symptoms1 or not symptoms2:
            return 0.0
        
        intersection = len(symptoms1 & symptoms2)
        union = len(symptoms1 | symptoms2)
        
        return intersection / union if union > 0 else 0.0
    
    # ==================== A4: å®Œæ•´æª¢ç´¢æµç¨‹ ====================
    async def optimized_retrieval(
        self,
        search_engine,
        query: str,
        vector: Optional[List[float]],
        round_num: int,
        symptom_count: int,
        coverage: float = 0.0
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        å„ªåŒ–å¾Œçš„å®Œæ•´æª¢ç´¢æµç¨‹
        
        æµç¨‹ï¼š
        1. è¨ˆç®—å‹•æ…‹ Î±
        2. å¤šåº«ä¸¦è¡Œæª¢ç´¢ï¼ˆå– k=30ï¼‰
        3. RRF èåˆ
        4. MMR å»é‡
        5. è¿”å› Top-10
        """
        # 1. è¨ˆç®—å‹•æ…‹ Î±
        alpha_case = self.calculate_dynamic_alpha(
            round_num, symptom_count, coverage, False
        )
        alpha_pulse = alpha_case
        alpha_rpcase = alpha_case
        
        # 2. ä¸¦è¡Œæª¢ç´¢ï¼ˆæ“´å¤§ Top-kï¼‰
        case_hits = await search_engine.hybrid_search(
            index="TCMCase",
            text=query,
            vector=vector,
            alpha=alpha_case,
            limit=self.config.initial_k,
            search_fields=["symptom_terms", "syndrome_terms", "pulse_terms"],
            return_props=["case_id", "diagnosis", "symptom_terms", "syndrome_terms"]
        )
        
        pulse_hits = await search_engine.hybrid_search(
            index="PulsePJ",
            text=query,
            vector=vector,
            alpha=alpha_pulse,
            limit=self.config.initial_k,
            search_fields=["bm25_cjk"],
            return_props=["pid", "name", "symptoms"]
        )
        
        rpcase_hits = await search_engine.hybrid_search(
            index="RPCase",
            text=query,
            vector=vector,
            alpha=alpha_rpcase,
            limit=self.config.initial_k,
            search_fields=["bm25_text"],
            return_props=["rid", "final_diagnosis", "symptom_tags"]
        )
        
        # æª¢æŸ¥ RPCase æ˜¯å¦ç‚ºç©ºï¼Œéœ€è¦é‡æœ
        if not rpcase_hits and coverage < 0.4:
            logger.info("ğŸ”„ RPCase ç‚ºç©ºä¸”è¦†è“‹ç‡ä½ï¼Œé™ä½ Î± é‡æœ")
            alpha_rpcase_retry = alpha_rpcase * 0.8
            rpcase_hits = await search_engine.hybrid_search(
                index="RPCase",
                text=query,
                vector=vector,
                alpha=alpha_rpcase_retry,
                limit=self.config.initial_k,
                search_fields=["bm25_text"],
                return_props=["rid", "final_diagnosis", "symptom_tags"]
            )
        
        # 3. RRF èåˆï¼ˆé‡å°æ¯å€‹åº«ï¼‰
        case_fused = self.reciprocal_rank_fusion([case_hits], self.config.rrf_k)
        pulse_fused = self.reciprocal_rank_fusion([pulse_hits], self.config.rrf_k)
        rpcase_fused = self.reciprocal_rank_fusion([rpcase_hits], self.config.rrf_k)
        
        # 4. MMR å»é‡
        case_final = self.maximal_marginal_relevance(
            case_fused,
            self.config.mmr_lambda,
            self.config.mmr_threshold,
            self.config.final_k
        )
        pulse_final = self.maximal_marginal_relevance(
            pulse_fused,
            self.config.mmr_lambda,
            self.config.mmr_threshold,
            self.config.final_k
        )
        rpcase_final = self.maximal_marginal_relevance(
            rpcase_fused,
            self.config.mmr_lambda,
            self.config.mmr_threshold,
            self.config.final_k
        )
        
        logger.info(f"âœ… å„ªåŒ–æª¢ç´¢å®Œæˆ:")
        logger.info(f"   TCMCase: {len(case_hits)} â†’ {len(case_final)}")
        logger.info(f"   PulsePJ: {len(pulse_hits)} â†’ {len(pulse_final)}")
        logger.info(f"   RPCase: {len(rpcase_hits)} â†’ {len(rpcase_final)}")
        
        return {
            "case": case_final,
            "pulse": pulse_final,
            "rpcase": rpcase_final,
            "alpha_used": {
                "case": alpha_case,
                "pulse": alpha_pulse,
                "rpcase": alpha_rpcase
            }
        }