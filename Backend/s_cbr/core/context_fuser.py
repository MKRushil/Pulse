# -*- coding: utf-8 -*-
"""
Patient Context Fusion
çµ±ä¸€è™•ç†å¢é‡åˆä½µã€å»é‡ã€å¦å®šè¦å‰‡åŒ–ã€æ¬Šé‡é‡˜é¸
"""

from typing import Dict, List, Set, Any, Optional, Tuple
from collections import defaultdict
from datetime import datetime
from ..utils.logger import get_logger

logger = get_logger("ContextFuser")

class ContextFuser:
    """ä¸Šä¸‹æ–‡èåˆå™¨"""
    
    def __init__(self, config=None):
        self.config = config
        self.pin_threshold = 0.8  # é‡˜é¸é–¾å€¼
        self.negation_patterns = ["ç„¡", "æ²’æœ‰", "ä¸", "æœª"]
        logger.info("âœ… Context Fuser åˆå§‹åŒ–")
    
    def update(
        self,
        prev_ctx: Dict[str, Any],
        new_ctx: Dict[str, Any],
        round_num: int = 1
    ) -> Dict[str, Any]:
        """
        æ›´æ–°ä¸¦èåˆæ‚£è€…ä¸Šä¸‹æ–‡
        
        Args:
            prev_ctx: å‰ä¸€è¼ªä¸Šä¸‹æ–‡
            new_ctx: æ–°è¼¸å…¥ä¸Šä¸‹æ–‡
            round_num: ç•¶å‰è¼ªæ¬¡
            
        Returns:
            èåˆå¾Œçš„ä¸Šä¸‹æ–‡
        """
        fused = {
            "round": round_num,
            "timestamp": datetime.now().isoformat(),
            "symptoms": [],
            "negated_symptoms": [],
            "key_signs": [],
            "pinned_terms": [],
            "symptom_sources": defaultdict(list),  # ç—‡ç‹€ä¾†æºè¿½è¹¤
            "intensity_map": {},  # ç—‡ç‹€å¼·åº¦æ˜ å°„
            "history": []
        }
        
        # Step 1: åˆä½µç—‡ç‹€åˆ—è¡¨
        prev_symptoms = set(prev_ctx.get("symptoms", []))
        new_symptoms = set(self._extract_symptoms(new_ctx))
        
        # Step 2: è™•ç†å¦å®šç—‡ç‹€
        new_negated = self._process_negations(new_ctx)
        prev_negated = set(prev_ctx.get("negated_symptoms", []))
        
        # ç§»é™¤è¢«å¦å®šçš„ç—‡ç‹€
        for neg in new_negated:
            base_symptom = neg.replace("ç„¡_", "")
            prev_symptoms.discard(base_symptom)
            new_symptoms.discard(base_symptom)
        
        # Step 3: åˆä½µä¸¦å»é‡
        all_symptoms = prev_symptoms | new_symptoms
        all_negated = prev_negated | new_negated
        
        # Step 4: è¨˜éŒ„ç—‡ç‹€ä¾†æº
        for symptom in new_symptoms:
            fused["symptom_sources"][symptom].append(round_num)
        
        for symptom in prev_symptoms:
            sources = prev_ctx.get("symptom_sources", {}).get(symptom, [])
            fused["symptom_sources"][symptom].extend(sources)
        
        # Step 5: è­˜åˆ¥é—œéµç—‡ç‹€ï¼ˆé‡˜é¸ï¼‰
        key_signs = self._identify_key_signs(
            all_symptoms,
            fused["symptom_sources"]
        )
        
        # Step 6: æå–å¼·åº¦ä¿¡æ¯
        intensity_map = self._extract_intensity(new_ctx)
        if prev_ctx.get("intensity_map"):
            intensity_map.update(prev_ctx["intensity_map"])
        
        # Step 7: çµ„è£èåˆçµæœ
        fused.update({
            "symptoms": sorted(list(all_symptoms)),
            "negated_symptoms": sorted(list(all_negated)),
            "key_signs": key_signs,
            "pinned_terms": self._get_pinned_terms(key_signs, round_num),
            "intensity_map": intensity_map,
            "accumulated_question": self._merge_questions(
                prev_ctx.get("accumulated_question", ""),
                new_ctx.get("question", "")
            )
        })
        
        # Step 8: ä¿å­˜æ­·å²
        if prev_ctx.get("history"):
            fused["history"] = prev_ctx["history"][-5:]  # ä¿ç•™æœ€è¿‘5è¼ª
        fused["history"].append({
            "round": round_num,
            "new_symptoms": list(new_symptoms),
            "negated": list(new_negated)
        })
        
        logger.info(f"ğŸ”„ Context Fusion å®Œæˆ [Round {round_num}]")
        logger.info(f"   ç—‡ç‹€æ•¸: {len(all_symptoms)}, å¦å®šæ•¸: {len(all_negated)}")
        logger.info(f"   é—œéµç—‡ç‹€: {key_signs[:3]}")
        
        return fused
    
    def _extract_symptoms(self, ctx: Dict) -> List[str]:
        """æå–ç—‡ç‹€"""
        symptoms = []
        
        # å¾å¤šå€‹å¯èƒ½æ¬„ä½æå–
        for field in ["symptoms", "symptom_list", "chief_complaint"]:
            if field in ctx:
                value = ctx[field]
                if isinstance(value, list):
                    symptoms.extend(value)
                elif isinstance(value, str):
                    # ç°¡å–®åˆ†è©
                    symptoms.extend(self._tokenize_symptoms(value))
        
        return symptoms
    
    def _process_negations(self, ctx: Dict) -> Set[str]:
        """è™•ç†å¦å®šç—‡ç‹€"""
        negated = set()
        text = ctx.get("question", "") + " " + ctx.get("text", "")
        
        for neg_word in self.negation_patterns:
            # ç°¡å–®çš„å¦å®šæ¨¡å¼åŒ¹é…
            import re
            pattern = f"{neg_word}([^ï¼Œã€‚ï¼›]{1,4})"
            matches = re.findall(pattern, text)
            for match in matches:
                negated.add(f"ç„¡_{match}")
        
        return negated
    
    def _identify_key_signs(
        self,
        symptoms: Set[str],
        sources: Dict[str, List[int]]
    ) -> List[str]:
        """
        è­˜åˆ¥é—œéµç—‡ç‹€
        - å¤šè¼ªé‡è¤‡å‡ºç¾
        - é«˜é »ç—‡ç‹€
        - ç‰¹å®šé‡è¦ç—‡ç‹€
        """
        key_signs = []
        
        # é‡è¦ç—‡ç‹€é—œéµè©
        important_keywords = {
            "å¤±çœ ", "å¿ƒæ‚¸", "é ­æšˆ", "èƒ¸æ‚¶", "è…¹ç—›",
            "ç™¼ç†±", "å’³å—½", "è…°ç— ", "è€³é³´", "ç›œæ±—"
        }
        
        # è¨ˆç®—ç—‡ç‹€é‡è¦æ€§åˆ†æ•¸
        symptom_scores = {}
        for symptom in symptoms:
            score = 0.0
            
            # å‡ºç¾é »ç‡
            frequency = len(sources.get(symptom, []))
            score += frequency * 0.3
            
            # æ˜¯å¦ç‚ºé‡è¦ç—‡ç‹€
            if symptom in important_keywords:
                score += 0.5
            
            # æ˜¯å¦è·¨è¼ªå‡ºç¾
            rounds = set(sources.get(symptom, []))
            if len(rounds) > 1:
                score += 0.2
            
            symptom_scores[symptom] = score
        
        # æ’åºä¸¦é¸æ“‡å‰Nå€‹
        sorted_symptoms = sorted(
            symptom_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        key_signs = [s[0] for s in sorted_symptoms[:5]]
        
        return key_signs
    
    def _get_pinned_terms(
        self,
        key_signs: List[str],
        round_num: int
    ) -> List[str]:
        """
        ç²å–é‡˜é¸è©ï¼ˆå¿…é ˆåœ¨å¾ŒçºŒæª¢ç´¢ä¸­åŒ…å«ï¼‰
        """
        pinned = []
        
        # å‰3å€‹é—œéµç—‡ç‹€å¿…å®šé‡˜é¸
        pinned.extend(key_signs[:3])
        
        # å¦‚æœæ˜¯å¾ŒæœŸè¼ªæ¬¡ï¼Œé‡˜é¸æ›´å¤š
        if round_num >= 3:
            pinned.extend(key_signs[3:5])
        
        return pinned
    
    def _extract_intensity(self, ctx: Dict) -> Dict[str, str]:
        """
        æå–ç—‡ç‹€å¼·åº¦
        è¼•åº¦/ä¸­åº¦/é‡åº¦/æ¥µé‡
        """
        intensity_map = {}
        text = ctx.get("question", "") + " " + ctx.get("text", "")
        
        intensity_patterns = {
            "è¼•å¾®": "è¼•åº¦",
            "ç¨å¾®": "è¼•åº¦",
            "æœ‰é»": "è¼•åº¦",
            "æ¯”è¼ƒ": "ä¸­åº¦",
            "å¾ˆ": "é‡åº¦",
            "éå¸¸": "é‡åº¦",
            "æ¥µ": "æ¥µé‡",
            "åš´é‡": "é‡åº¦"
        }
        
        for pattern, level in intensity_patterns.items():
            import re
            matches = re.findall(f"{pattern}([^ï¼Œã€‚ï¼›]{1,4})", text)
            for match in matches:
                intensity_map[match] = level
        
        return intensity_map
    
    def _tokenize_symptoms(self, text: str) -> List[str]:
        """ç°¡å–®ç—‡ç‹€åˆ†è©"""
        # ä½¿ç”¨æ¨™é»åˆ†å‰²
        import re
        tokens = re.split(r'[ï¼Œã€‚ã€ï¼›\s]+', text)
        
        # éæ¿¾çŸ­è©
        valid_tokens = [
            t for t in tokens
            if len(t) >= 2 and len(t) <= 4
        ]
        
        return valid_tokens
    
    def _merge_questions(self, prev_q: str, new_q: str) -> str:
        """åˆä½µå•é¡Œæ–‡æœ¬"""
        if not prev_q:
            return new_q
        if not new_q:
            return prev_q
        
        # é¿å…é‡è¤‡
        if new_q in prev_q:
            return prev_q
        
        return f"{prev_q} {new_q}".strip()
    
    def get_retrieval_query(self, fused_ctx: Dict) -> str:
        """
        ç”Ÿæˆæª¢ç´¢æŸ¥è©¢ï¼ˆåŒ…å«é‡˜é¸è©ï¼‰
        """
        query_parts = []
        
        # 1. é‡˜é¸è©å¿…é ˆåŒ…å«ï¼ˆé‡è¤‡3æ¬¡æé«˜æ¬Šé‡ï¼‰
        pinned = fused_ctx.get("pinned_terms", [])
        for term in pinned:
            query_parts.extend([term] * 3)
        
        # 2. é—œéµç—‡ç‹€ï¼ˆé‡è¤‡2æ¬¡ï¼‰
        key_signs = fused_ctx.get("key_signs", [])
        for sign in key_signs:
            if sign not in pinned:
                query_parts.extend([sign] * 2)
        
        # 3. å…¶ä»–ç—‡ç‹€ï¼ˆ1æ¬¡ï¼‰
        other_symptoms = fused_ctx.get("symptoms", [])
        for symptom in other_symptoms:
            if symptom not in pinned and symptom not in key_signs:
                query_parts.append(symptom)
        
        # 4. å¦å®šç—‡ç‹€ï¼ˆæ˜ç¢ºæ¨™è¨˜ï¼‰
        negated = fused_ctx.get("negated_symptoms", [])
        for neg in negated:
            query_parts.append(neg)
        
        return " ".join(query_parts)