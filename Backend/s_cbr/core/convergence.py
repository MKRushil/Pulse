# -*- coding: utf-8 -*-
"""
èºæ—‹æ¨ç†æ”¶æ–‚åº¦è¨ˆç®—æ¨¡çµ„
"""

import numpy as np
from typing import Dict, Any, List, Optional
from datetime import datetime

from ..config import SCBRConfig
from ..utils.logger import get_logger

logger = get_logger("ConvergenceMetrics")

class ConvergenceMetrics:
    """æ”¶æ–‚åº¦è¨ˆç®—å™¨"""
    
    def __init__(self, config: SCBRConfig):
        self.config = config
        self.history: Dict[str, List[Dict[str, Any]]] = {}  # session_id -> history
        
        # æ¬Šé‡é…ç½®
        self.weights = {
            'case_stability': config.convergence.case_stability_weight,
            'score_improvement': config.convergence.score_improvement_weight,
            'semantic_consistency': config.convergence.semantic_consistency_weight,
            'evidence_coverage': config.convergence.evidence_coverage_weight
        }
        
        # TCM é—œéµç—‡ç‹€è©å…¸
        self.tcm_symptoms = set(config.text_processor.tcm_keywords)
        
        logger.info("æ”¶æ–‚åº¦è¨ˆç®—å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def calculate_convergence(
        self,
        session_id: str,
        current_result: Dict[str, Any]
    ) -> Dict[str, float]:
        """
        è¨ˆç®—ç•¶å‰è¼ªæ¬¡çš„æ”¶æ–‚åº¦æŒ‡æ¨™
        
        Returns:
            åŒ…å«å„é …æŒ‡æ¨™çš„å­—å…¸ï¼š
            - case_stability: æ¡ˆä¾‹ç©©å®šåº¦ (0-1)
            - score_improvement: åˆ†æ•¸æå‡ç‡ (-1 to 1)
            - semantic_consistency: èªç¾©ä¸€è‡´æ€§ (0-1)
            - evidence_coverage: è­‰æ“šè¦†è“‹åº¦ (0-1)
            - overall_convergence: ç¶œåˆæ”¶æ–‚åº¦ (0-1)
        """
        # åˆå§‹åŒ–æˆ–ç²å–æ­·å²è¨˜éŒ„
        if session_id not in self.history:
            self.history[session_id] = []
        
        session_history = self.history[session_id]
        
        metrics = {
            'case_stability': 0.0,
            'score_improvement': 0.0,
            'semantic_consistency': 0.0,
            'evidence_coverage': 0.0,
            'overall_convergence': 0.0,
            'confidence': 0.0
        }
        
        # ç²å–ç•¶å‰æ¡ˆä¾‹è³‡è¨Š
        current_case_id = None
        current_score = 0.0
        current_symptoms = set()
        
        if "primary" in current_result and current_result["primary"]:
            primary = current_result["primary"]
            current_case_id = primary.get("id")
            current_score = primary.get("_final", 0.0)
            current_symptoms = set(primary.get("_hits", []))
        
        # è¨ˆç®—å„é …æŒ‡æ¨™
        if len(session_history) > 0:
            prev_result = session_history[-1]
            
            # 1. æ¡ˆä¾‹ç©©å®šåº¦
            metrics['case_stability'] = self._calculate_case_stability(
                session_history, current_case_id
            )
            
            # 2. åˆ†æ•¸æå‡ç‡
            metrics['score_improvement'] = self._calculate_score_improvement(
                prev_result, current_score
            )
            
            # 3. èªç¾©ä¸€è‡´æ€§
            metrics['semantic_consistency'] = self._calculate_semantic_consistency(
                session_history, current_result
            )
            
            # 4. è­‰æ“šè¦†è“‹åº¦
            metrics['evidence_coverage'] = self._calculate_evidence_coverage(
                session_history, current_symptoms
            )
        else:
            # é¦–è¼ªåˆå§‹åŒ–
            metrics['case_stability'] = 0.0
            metrics['score_improvement'] = 0.0
            metrics['semantic_consistency'] = 1.0
            metrics['evidence_coverage'] = len(current_symptoms & self.tcm_symptoms) / max(1, len(self.tcm_symptoms))
        
        # è¨ˆç®—ç¶œåˆæ”¶æ–‚åº¦
        metrics['overall_convergence'] = self._calculate_overall_convergence(metrics)
        
        # è¨ˆç®—ç½®ä¿¡åº¦
        metrics['confidence'] = self._calculate_confidence(metrics, len(session_history) + 1)
        
        # è¨˜éŒ„åˆ°æ­·å²
        self.history[session_id].append({
            'timestamp': datetime.now().isoformat(),
            'case_id': current_case_id,
            'score': current_score,
            'symptoms': list(current_symptoms),
            'metrics': metrics.copy()
        })
        
        logger.info(f"ğŸ“ˆ æœƒè©± {session_id} æ”¶æ–‚åº¦: {metrics['overall_convergence']:.3f}")
        
        return metrics
    
    def _calculate_case_stability(
        self,
        history: List[Dict[str, Any]],
        current_case_id: str
    ) -> float:
        """è¨ˆç®—æ¡ˆä¾‹ç©©å®šåº¦"""
        if not current_case_id:
            return 0.0
        
        # æª¢æŸ¥æœ€è¿‘Nè¼ªæ˜¯å¦ä½¿ç”¨ç›¸åŒæ¡ˆä¾‹
        recent_window = min(3, len(history))
        if recent_window == 0:
            return 0.0
        
        same_case_count = sum(
            1 for h in history[-recent_window:]
            if h.get('case_id') == current_case_id
        )
        
        return same_case_count / recent_window
    
    def _calculate_score_improvement(
        self,
        prev_result: Dict[str, Any],
        current_score: float
    ) -> float:
        """è¨ˆç®—åˆ†æ•¸æå‡ç‡"""
        prev_score = prev_result.get('score', 0.0)
        
        if prev_score == 0:
            return current_score
        
        improvement = (current_score - prev_score) / max(0.01, prev_score)
        
        # é™åˆ¶åœ¨ [-1, 1] ç¯„åœ
        return max(-1.0, min(1.0, improvement))
    

    def calculate_evaluation_metrics(
        self,
        session_id: str,
        current_result: Dict[str, Any]
    ) -> Dict[str, float]:
        """
        è¨ˆç®—çµ±ä¸€çš„å››é …è©•ä¼°æŒ‡æ¨™
        
        Returns:
            RCI: Retrieval Case Index (æ¡ˆä¾‹æª¢ç´¢ç›¸ä¼¼åº¦)
            CMS: Convergence Measure Score (æ”¶æ–‚åº¦)
            CSC: Consistency Score (è¾¨è­‰èˆ‡è¨ºæ–·ä¸€è‡´æ€§)
            CAS: Case Agreement Score (æ¡ˆä¾‹å…§å®¹ä¸€è‡´åº¦)
            Final: æœ€çµ‚ç½®ä¿¡åº¦
        """
        # å…ˆè¨ˆç®—åŸæœ‰æŒ‡æ¨™
        raw_metrics = self.calculate_convergence(session_id, current_result)
        
        # æå–å¿…è¦è³‡è¨Š
        round_num = len(self.history.get(session_id, [])) + 1
        
        # è¨ˆç®—çµ±ä¸€æŒ‡æ¨™
        rci = self._calculate_rci(current_result)
        cms = raw_metrics.get("overall_convergence", 0.0)
        csc = self._calculate_csc(current_result, session_id)
        cas = self._calculate_cas(current_result)
        
        # è¨ˆç®—æœ€çµ‚ç½®ä¿¡åº¦ï¼ˆå‹•æ…‹æ¬Šé‡ï¼‰
        weights = self._get_dynamic_weights(round_num)
        final = (
            weights["RCI"] * rci +
            weights["CMS"] * cms +
            weights["CSC"] * csc +
            weights["CAS"] * cas
        )
        
        metrics = {
            "RCI": round(rci, 3),
            "CMS": round(cms, 3),
            "CSC": round(csc, 3),
            "CAS": round(cas, 3),
            "Final": round(final, 3),
            # ä¿ç•™åŸæœ‰æŒ‡æ¨™ç”¨æ–¼å…§éƒ¨é‚è¼¯
            "_raw": raw_metrics
        }
        
        logger.info(f"ğŸ“Š è©•ä¼°æŒ‡æ¨™ [Round {round_num}]:")
        logger.info(f"   RCI={metrics['RCI']:.3f}, CMS={metrics['CMS']:.3f}")
        logger.info(f"   CSC={metrics['CSC']:.3f}, CAS={metrics['CAS']:.3f}")
        logger.info(f"   Final={metrics['Final']:.3f}")
        
        return metrics

    def _calculate_rci(self, current_result: Dict) -> float:
        """
        è¨ˆç®— RCI (Retrieval Case Index)
        æ¡ˆä¾‹æª¢ç´¢ç›¸ä¼¼åº¦ï¼šTop-k æ¡ˆä¾‹å¹³å‡ç›¸ä¼¼åº¦åŠ æ¬Š
        """
        if "primary" not in current_result or not current_result["primary"]:
            return 0.0
        
        primary = current_result["primary"]
        primary_score = primary.get("_final", 0.0)
        
        # å¦‚æœæœ‰è£œå……æ¡ˆä¾‹
        supplement_score = 0.0
        if "supplement" in current_result and current_result["supplement"]:
            supplement_score = current_result["supplement"].get("_final", 0.0)
        
        # åŠ æ¬Šå¹³å‡ï¼ˆä¸»æ¡ˆä¾‹æ¬Šé‡0.7ï¼Œè£œå……æ¡ˆä¾‹0.3ï¼‰
        rci = primary_score * 0.7
        if supplement_score > 0:
            rci += supplement_score * 0.3
        else:
            rci = primary_score
        
        return min(rci, 1.0)

    def _calculate_csc(self, current_result: Dict, session_id: str = None) -> float:
        """
        è¨ˆç®— CSC (Consistency Score)
        è¾¨è­‰èˆ‡è¨ºæ–·ä¸€è‡´æ€§ï¼šå…«ç¶±å±¬æ€§ + è‡Ÿè…‘æ­¸å±¬ä¸€è‡´ç‡
        
        Args:
            current_result: ç•¶å‰æ¨ç†çµæœ
            session_id: æœƒè©±IDï¼ˆç”¨æ–¼ç²å–æ­·å²ï¼‰
        
        Returns:
            ä¸€è‡´æ€§åˆ†æ•¸ (0-1)
        """
        if "pattern_diagnosis" not in current_result:
            # Fallbackï¼šä½¿ç”¨åŸæœ‰çš„èªç¾©ä¸€è‡´æ€§
            if session_id and session_id in self.history:
                return self._calculate_semantic_consistency(
                    self.history.get(session_id, []),
                    current_result
                )
            else:
                # å¦‚æœæ²’æœ‰ session_id æˆ–æ­·å²ï¼Œè¿”å›é»˜èªå€¼
                return 0.5
        
        pd = current_result["pattern_diagnosis"]
        pattern_reasoning = pd.get("pattern_reasoning", {})
        diagnosis_reasoning = pd.get("diagnosis_reasoning", {})
        
        # æª¢æŸ¥å…«ç¶±èˆ‡ç—…æ©Ÿçš„ä¸€è‡´æ€§
        eight_principles = set(pattern_reasoning.get("eight_principles", []))
        pathomechanism = diagnosis_reasoning.get("pathomechanism", "")
        
        consistency_score = 0.0
        
        # è¦å‰‡æª¢æŸ¥
        if "é™°è™›" in eight_principles and "é™°è™›" in pathomechanism:
            consistency_score += 0.3
        if "é™½è™›" in eight_principles and "é™½è™›" in pathomechanism:
            consistency_score += 0.3
        if "æ°£æ»¯" in eight_principles and "æ°£æ»¯" in pathomechanism:
            consistency_score += 0.2
        
        # è‡Ÿè…‘ä¸€è‡´æ€§
        zangfu = set(pattern_reasoning.get("zangfu", []))
        if zangfu:
            for organ in zangfu:
                if organ in pathomechanism:
                    consistency_score += 0.2
        
        return min(consistency_score, 1.0)

    def _calculate_cas(self, current_result: Dict) -> float:
        """
        è¨ˆç®— CAS (Case Agreement Score)
        æ¡ˆä¾‹å…§å®¹ä¸€è‡´åº¦
        å…¬å¼ï¼šCAS = 0.5*pattern_match + 0.3*pathomechanism + 0.2*snippet
        """
        pattern_match = self._calc_pattern_tag_match(current_result)
        pathomechanism_overlap = self._calc_pathomechanism_overlap(current_result)
        snippet_alignment = self._calc_snippet_alignment(current_result)
        
        cas = (
            0.5 * pattern_match +
            0.3 * pathomechanism_overlap +
            0.2 * snippet_alignment
        )
        
        return min(cas, 1.0)

    def _calc_pattern_tag_match(self, result: Dict) -> float:
        """è¨ˆç®—è­‰å‹æ¨™ç±¤åŒ¹é…åº¦ï¼ˆJaccardç›¸ä¼¼åº¦ï¼‰"""
        if "pattern_diagnosis" not in result or "primary" not in result:
            return 0.5
        
        # å¾é›™å±¤æ¨ç†çµæœæå–è­‰å‹
        pd_patterns = set()
        if "pattern_diagnosis" in result:
            pr = result["pattern_diagnosis"].get("pattern_reasoning", {})
            primary = pr.get("primary_pattern", {})
            if primary.get("label"):
                pd_patterns.add(primary["label"])
        
        # å¾æ¡ˆä¾‹æå–è­‰å‹
        case_patterns = set()
        if "primary" in result and result["primary"]:
            syndrome_terms = result["primary"].get("syndrome_terms", [])
            if syndrome_terms:
                case_patterns.update(syndrome_terms[:3])
        
        # Jaccard ç›¸ä¼¼åº¦
        if not pd_patterns and not case_patterns:
            return 0.0
        
        intersection = pd_patterns & case_patterns
        union = pd_patterns | case_patterns
        
        return len(intersection) / len(union) if union else 0.0

    def _calc_pathomechanism_overlap(self, result: Dict) -> float:
        """è¨ˆç®—ç—…æ©Ÿé‡ç–Šåº¦"""
        if "pattern_diagnosis" not in result:
            return 0.5
        
        pd = result["pattern_diagnosis"]
        diagnosis_reasoning = pd.get("diagnosis_reasoning", {})
        pathomechanism = diagnosis_reasoning.get("pathomechanism", "")
        
        if not pathomechanism:
            return 0.0
        
        # ç°¡å–®çš„é—œéµè©åŒ¹é…è©•åˆ†
        score = 0.0
        keywords = ["é™°è™›", "é™½è™›", "æ°£æ»¯", "è¡€ç˜€", "ç—°æ¿•", "ç«æ—º"]
        
        for kw in keywords:
            if kw in pathomechanism:
                score += 0.2
        
        return min(score, 1.0)

    def _calc_snippet_alignment(self, result: Dict) -> float:
        """è¨ˆç®—ç‰‡æ®µå°é½Šåº¦"""
        if "primary" not in result or not result["primary"]:
            return 0.0
        
        primary = result["primary"]
        
        # æå–é—œéµç—‡ç‹€
        hits = primary.get("_hits", [])
        if not hits:
            return 0.0
        
        # ç°¡å–®è©•åˆ†ï¼šå‘½ä¸­ç—‡ç‹€æ•¸é‡
        score = min(len(hits) / 5.0, 1.0)  # å‡è¨­5å€‹ç—‡ç‹€ç‚ºå®Œæ•´
        
        return score

    def _get_dynamic_weights(self, round_num: int) -> Dict[str, float]:
            """
            æ ¹æ“šè¼ªæ¬¡å‹•æ…‹èª¿æ•´æ¬Šé‡
            
            ç­–ç•¥:
            - R1: æ¢ç´¢æœŸï¼ˆRCI ä¸»å°ï¼‰- å…è¨±æª¢ç´¢æ¢ç´¢
            - R2-R3: å¹³è¡¡æœŸ - ç—‡ç‹€è¦†è“‹èˆ‡æª¢ç´¢ä¸¦é‡
            - R4+: æ”¶æ–‚æœŸï¼ˆCMSã€CSC ä¸»å°ï¼‰- å¼·èª¿æ”¶æ–‚èˆ‡ä¸€è‡´æ€§
            
            Returns:
                æ¬Šé‡å­—å…¸ {æŒ‡æ¨™å: æ¬Šé‡å€¼}
            """
            if round_num == 1:
                # ç¬¬1è¼ªï¼šæ¢ç´¢æœŸï¼ˆRCI ä¸»å°ï¼‰
                return {
                    "RCI": 0.50,  # æª¢ç´¢ç›¸é—œæ€§æœ€é‡è¦
                    "CMS": 0.20,  # æ¡ˆä¾‹åŒ¹é…
                    "CSC": 0.20,  # ä¸€è‡´æ€§
                    "CAS": 0.10   # æ¡ˆä¾‹ç¬¦åˆ
                }
            elif round_num <= 3:
                # ç¬¬2-3è¼ªï¼šå¹³è¡¡æœŸ
                return {
                    "RCI": 0.30,  # é™ä½æ¢ç´¢æ¬Šé‡
                    "CMS": 0.30,  # æé«˜æ”¶æ–‚æ¬Šé‡
                    "CSC": 0.25,  # ä¸€è‡´æ€§
                    "CAS": 0.15   # æ¡ˆä¾‹ç¬¦åˆ
                }
            else:
                # ç¬¬4è¼ª+ï¼šæ”¶æ–‚æœŸ
                return {
                    "RCI": 0.15,  # æœ€å°æ¢ç´¢
                    "CMS": 0.35,  # æœ€å¤§æ”¶æ–‚
                    "CSC": 0.30,  # å¼·èª¿ä¸€è‡´æ€§
                    "CAS": 0.20   # å¼·èª¿æ¡ˆä¾‹ç¬¦åˆ
                }
        
    def _calculate_semantic_consistency(
        self,
        history: List[Dict[str, Any]],
        current_result: Dict[str, Any]
    ) -> float:
        """è¨ˆç®—èªç¾©ä¸€è‡´æ€§"""
        if len(history) == 0:
            return 1.0
        
        # ä½¿ç”¨ç—‡ç‹€é‡ç–Šåº¦ä½œç‚ºèªç¾©ä¸€è‡´æ€§çš„ä»£ç†æŒ‡æ¨™
        current_symptoms = set()
        if "primary" in current_result and current_result["primary"]:
            current_symptoms = set(current_result["primary"].get("_hits", []))
        
        if not current_symptoms:
            return 0.5
        
        # è¨ˆç®—èˆ‡æ­·å²ç—‡ç‹€çš„å¹³å‡é‡ç–Šåº¦
        overlaps = []
        for h in history[-3:]:  # åªçœ‹æœ€è¿‘3è¼ª
            hist_symptoms = set(h.get('symptoms', []))
            if hist_symptoms:
                overlap = len(current_symptoms & hist_symptoms) / len(current_symptoms | hist_symptoms)
                overlaps.append(overlap)
        
        if overlaps:
            return sum(overlaps) / len(overlaps)
        
        return 0.5
    
    def _calculate_evidence_coverage(
        self,
        history: List[Dict[str, Any]],
        current_symptoms: set
    ) -> float:
        """è¨ˆç®—è­‰æ“šè¦†è“‹åº¦"""
        # æ”¶é›†æ‰€æœ‰æ­·å²ç—‡ç‹€
        all_symptoms = current_symptoms.copy()
        for h in history:
            all_symptoms.update(h.get('symptoms', []))
        
        # è¨ˆç®—TCMç—‡ç‹€è¦†è“‹ç‡
        covered = all_symptoms & self.tcm_symptoms
        
        if not self.tcm_symptoms:
            return 0.5
        
        return len(covered) / len(self.tcm_symptoms)
    
    def _calculate_overall_convergence(self, metrics: Dict[str, float]) -> float:
        """è¨ˆç®—ç¶œåˆæ”¶æ–‚åº¦"""
        weighted_sum = 0.0
        
        for key, weight in self.weights.items():
            value = metrics.get(key, 0.0)
            
            # ç‰¹æ®Šè™•ç†åˆ†æ•¸æå‡ç‡ï¼ˆå¯èƒ½ç‚ºè² ï¼‰
            if key == 'score_improvement':
                value = (value + 1.0) / 2.0  # è½‰æ›åˆ° [0, 1]
            
            weighted_sum += value * weight
        
        return max(0.0, min(1.0, weighted_sum))
    
    def _calculate_confidence(self, metrics: Dict[str, float], round_num: int) -> float:
        """è¨ˆç®—ç½®ä¿¡åº¦"""
        # åŸºæ–¼æ”¶æ–‚åº¦å’Œè¼ªæ¬¡è¨ˆç®—ç½®ä¿¡åº¦
        base_confidence = metrics['overall_convergence']
        
        # è¼ªæ¬¡èª¿æ•´å› å­ï¼ˆè¶Šå¤šè¼ªæ¬¡ç½®ä¿¡åº¦è¶Šé«˜ï¼Œä½†æœ‰ä¸Šé™ï¼‰
        round_factor = min(1.0, round_num / 5.0)
        
        # ç©©å®šæ€§åŠ æˆ
        stability_bonus = metrics['case_stability'] * 0.2
        
        confidence = base_confidence * 0.7 + round_factor * 0.2 + stability_bonus * 0.1
        
        return max(0.0, min(1.0, confidence))
    
    def should_stop(
        self,
        metrics: Dict[str, float],
        round_num: int
    ) -> Dict[str, Any]:  # âœ… æ”¹ç‚ºè¿”å›å­—å…¸
        """
        åˆ¤æ–·æ˜¯å¦æ‡‰è©²åœæ­¢èºæ—‹æ¨ç†
        
        Returns:
            {
                "should_stop": bool,  # æ˜¯å¦åœæ­¢
                "can_save": bool,  # æ˜¯å¦å¯å„²å­˜
                "treatment_effective": bool,  # æ²»ç™‚æ˜¯å¦æœ‰æ•ˆ
                "stop_reason": str,  # åœæ­¢åŸå› 
                "continue_reason": str  # ç¹¼çºŒåŸå› 
            }
        """
        
        # æœªé”æœ€å°è¼ªæ¬¡ä¸åœæ­¢
        if round_num < self.config.spiral.min_rounds:
            logger.info(f"æœªé”æœ€å°è¼ªæ¬¡ {self.config.spiral.min_rounds}")
            return {
                "should_stop": False,
                "can_save": False,
                "treatment_effective": False,
                "stop_reason": "",
                "continue_reason": f"æœªé”æœ€å°è¼ªæ¬¡ {self.config.spiral.min_rounds}"
            }
        
        # é”åˆ°æœ€å¤§è¼ªæ¬¡å¼·åˆ¶åœæ­¢
        if round_num >= self.config.spiral.max_rounds:
            logger.info(f"âœ‹ é”åˆ°æœ€å¤§è¼ªæ¬¡ {self.config.spiral.max_rounds}ï¼Œåœæ­¢æ¨ç†")
            return {
                "should_stop": True,
                "can_save": False,
                "treatment_effective": False,
                "stop_reason": f"é”åˆ°æœ€å¤§è¼ªæ¬¡ {self.config.spiral.max_rounds}",
                "continue_reason": ""
            }
        
        # âœ… æ”¶æ–‚åº¦é”æ¨™ï¼ˆä½¿ç”¨é…ç½®çš„é–¾å€¼ï¼‰
        threshold = self.config.convergence.convergence_threshold
        overall_conv = metrics['overall_convergence']
        
        if overall_conv >= threshold:
            logger.info(f"âœ… æ”¶æ–‚åº¦é”æ¨™ {overall_conv:.3f} â‰¥ {threshold}ï¼Œåœæ­¢æ¨ç†")
            
            # åˆ¤æ–·æ˜¯å¦æœ‰æ•ˆæ²»ç™‚ï¼ˆå¯å„²å­˜ï¼‰
            is_stable = metrics['case_stability'] >= 0.8
            is_covered = metrics['evidence_coverage'] >= 0.6
            treatment_effective = is_stable and is_covered
            
            return {
                "should_stop": True,
                "can_save": treatment_effective,
                "treatment_effective": treatment_effective,
                "stop_reason": f"æ”¶æ–‚åº¦é”æ¨™ {overall_conv:.3f}",
                "continue_reason": ""
            }
        
        # æ¡ˆä¾‹ç©©å®šä¸”åˆ†æ•¸ä¸å†æå‡
        if (metrics['case_stability'] >= 0.9 and 
            metrics['score_improvement'] <= 0.01):
            logger.info("âœ… æ¡ˆä¾‹ç©©å®šä¸”åˆ†æ•¸ä¸å†æå‡ï¼Œåœæ­¢æ¨ç†")
            return {
                "should_stop": True,
                "can_save": True,
                "treatment_effective": True,
                "stop_reason": "æ¡ˆä¾‹ç©©å®šä¸”åˆ†æ•¸ä¸å†æå‡",
                "continue_reason": ""
            }
        
        logger.info(f"â³ ç¹¼çºŒæ¨ç†ï¼ˆæ”¶æ–‚åº¦ {overall_conv:.3f} < {threshold}ï¼‰")
        return {
            "should_stop": False,
            "can_save": False,
            "treatment_effective": False,
            "stop_reason": "",
            "continue_reason": f"æ”¶æ–‚åº¦ {overall_conv:.3f} < {threshold}"
        }

    def _evaluate_treatment_effectiveness(
        self,
        metrics: Dict[str, float],
        primary_case: Optional[Dict[str, Any]],
        round_num: int
    ) -> bool:
        """
        è©•ä¼°æ²»ç™‚æ˜¯å¦æœ‰æ•ˆ
        
        åˆ¤æ–·æ¨™æº–ï¼š
        1. æ”¶æ–‚åº¦ >= 0.8
        2. æ¡ˆä¾‹ç©©å®šåº¦ >= 0.7
        3. ç—‡ç‹€è¦†è“‹ç‡ >= 0.6ï¼ˆå¦‚æœæœ‰èª¿æ•´å¾Œæ¡ˆä¾‹ï¼‰
        4. è‡³å°‘é€²è¡Œé 2 è¼ªæ¨ç†
        """
        
        # åŸºç¤æ¢ä»¶
        if round_num < 2:
            return False
        
        overall = metrics.get('overall_convergence', 0)
        stability = metrics.get('case_stability', 0)
        
        # æ ¸å¿ƒåˆ¤æ–·
        is_converged = overall >= 0.8
        is_stable = stability >= 0.7
        
        # å¦‚æœæœ‰èª¿æ•´å¾Œæ¡ˆä¾‹ï¼Œæª¢æŸ¥ç—‡ç‹€è¦†è“‹ç‡
        has_good_coverage = True
        if primary_case and primary_case.get("adjusted"):
            coverage = primary_case.get("match_stats", {}).get("coverage", 0)
            has_good_coverage = coverage >= 0.6
        
        is_effective = is_converged and is_stable and has_good_coverage
        
        logger.info(f"ğŸ“Š æ²»ç™‚æœ‰æ•ˆæ€§è©•ä¼°:")
        logger.info(f"   æ”¶æ–‚: {overall:.1%} {'âœ“' if is_converged else 'âœ—'}")
        logger.info(f"   ç©©å®š: {stability:.1%} {'âœ“' if is_stable else 'âœ—'}")
        if primary_case and primary_case.get("adjusted"):
            logger.info(f"   è¦†è“‹: {primary_case.get('match_stats', {}).get('coverage', 0):.1%} {'âœ“' if has_good_coverage else 'âœ—'}")
        logger.info(f"   çµè«–: {'æœ‰æ•ˆ âœ…' if is_effective else 'ç„¡æ•ˆ âŒ'}")
        
        return is_effective
    
    def clear_history(self, session_id: str):
        """æ¸…é™¤æœƒè©±æ­·å²"""
        if session_id in self.history:
            del self.history[session_id]
            logger.info(f"æ¸…é™¤æœƒè©± {session_id} çš„æ”¶æ–‚æ­·å²")
    
    def get_convergence_report(self, session_id: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ”¶æ–‚å ±å‘Š"""
        if session_id not in self.history:
            return {"error": "No history found"}
        
        history = self.history[session_id]
        
        if not history:
            return {"error": "Empty history"}
        
        # æå–æ‰€æœ‰æ”¶æ–‚åº¦å€¼
        convergence_values = [h['metrics']['overall_convergence'] for h in history]
        
        # è¨ˆç®—çµ±è¨ˆè³‡è¨Š
        report = {
            'session_id': session_id,
            'total_rounds': len(history),
            'final_convergence': convergence_values[-1],
            'average_convergence': np.mean(convergence_values),
            'convergence_trend': convergence_values,
            'final_case_id': history[-1].get('case_id'),
            'final_score': history[-1].get('score'),
            'symptoms_collected': list(set(
                sym for h in history 
                for sym in h.get('symptoms', [])
            )),
            'improvement_rate': self._calculate_improvement_rate(convergence_values)
        }
        
        return report
    
    def _calculate_improvement_rate(self, values: List[float]) -> float:
        """è¨ˆç®—æ”¹å–„ç‡"""
        if len(values) < 2:
            return 0.0
        
        # ä½¿ç”¨ç·šæ€§å›æ­¸è¨ˆç®—è¶¨å‹¢
        x = np.arange(len(values))
        coeffs = np.polyfit(x, values, 1)
        
        return float(coeffs[0])  # æ–œç‡å³ç‚ºæ”¹å–„ç‡
    
    # åœ¨ ConvergenceMetrics é¡ä¸­æ·»åŠ 

    def calculate_enhanced_convergence(
        self,
        session_id: str,
        current_result: Dict[str, Any],
        tongue_pulse_hits: int = 0  # æ–°å¢ï¼šèˆŒè„ˆå‘½ä¸­æ•¸
    ) -> Dict[str, float]:
        """
        å¢å¼·ç‰ˆæ”¶æ–‚åº¦è¨ˆç®—
        
        å…¬å¼ï¼š
        - Coverage: åŠ æ¬Šå‘½ä¸­æ¯”ä¾‹ï¼ˆèˆŒ/è„ˆ Ã—1.3ï¼‰
        - Stability: ä¸»è­‰é€£çºŒä¸€è‡´ + é—œéµä¾æ“š IoU
        - Confidence: ä¸»è­‰èˆ‡æ¬¡è­‰åˆ†å·®çš„ sigmoid
        - Convergence = 0.4*Stability + 0.35*Coverage + 0.25*Confidence
        """
        if session_id not in self.history:
            self.history[session_id] = []
        
        session_history = self.history[session_id]
        
        metrics = {
            'case_stability': 0.0,
            'score_improvement': 0.0,
            'semantic_consistency': 0.0,
            'evidence_coverage': 0.0,
            'overall_convergence': 0.0,
            'confidence': 0.0,
            'syndrome_confidence': 0.0  # æ–°å¢
        }
        
        # ç²å–ç•¶å‰è³‡è¨Š
        current_case_id = None
        current_score = 0.0
        current_symptoms = set()
        primary_syndrome = None
        secondary_syndromes = []
        
        if "primary" in current_result and current_result["primary"]:
            primary = current_result["primary"]
            current_case_id = primary.get("id")
            current_score = primary.get("_final", 0.0)
            current_symptoms = set(primary.get("_hits", []))
            
            # æå–è­‰å‹ä¿¡æ¯ï¼ˆå¦‚æœæœ‰è¾¨è­‰çµæœï¼‰
            if "syndrome_result" in current_result:
                syndrome_result = current_result["syndrome_result"]
                primary_syndrome = syndrome_result.primary_syndrome
                secondary_syndromes = syndrome_result.secondary_syndromes
        
        if len(session_history) > 0:
            prev_result = session_history[-1]
            
            # 1. æ¡ˆä¾‹ç©©å®šåº¦
            metrics['case_stability'] = self._calculate_case_stability(
                session_history, current_case_id
            )
            
            # 2. åˆ†æ•¸æå‡ç‡
            metrics['score_improvement'] = self._calculate_score_improvement(
                prev_result, current_score
            )
            
            # 3. èªç¾©ä¸€è‡´æ€§
            metrics['semantic_consistency'] = self._calculate_semantic_consistency(
                session_history, current_result
            )
            
            # 4. âœ… å¢å¼·ç‰ˆè­‰æ“šè¦†è“‹åº¦ï¼ˆè€ƒæ…®èˆŒè„ˆåŠ æ¬Šï¼‰
            metrics['evidence_coverage'] = self._calculate_enhanced_evidence_coverage(
                session_history, current_symptoms, tongue_pulse_hits
            )
            
            # 5. âœ… è­‰å‹ç½®ä¿¡åº¦ï¼ˆä¸»è­‰èˆ‡æ¬¡è­‰åˆ†å·®ï¼‰
            if primary_syndrome:
                metrics['syndrome_confidence'] = self._calculate_syndrome_confidence(
                    primary_syndrome, secondary_syndromes, current_result
                )
        else:
            # é¦–è¼ªåˆå§‹åŒ–
            metrics['case_stability'] = 0.0
            metrics['score_improvement'] = 0.0
            metrics['semantic_consistency'] = 1.0
            metrics['evidence_coverage'] = self._calculate_enhanced_evidence_coverage(
                [], current_symptoms, tongue_pulse_hits
            )
        
        # âœ… è¨ˆç®—ç¶œåˆæ”¶æ–‚åº¦ï¼ˆæ–°æ¬Šé‡ï¼‰
        metrics['overall_convergence'] = self._calculate_enhanced_overall_convergence(metrics)
        
        # è¨ˆç®—ç½®ä¿¡åº¦
        metrics['confidence'] = self._calculate_confidence(metrics, len(session_history) + 1)
        
        # è¨˜éŒ„åˆ°æ­·å²
        self.history[session_id].append({
            'timestamp': datetime.now().isoformat(),
            'case_id': current_case_id,
            'score': current_score,
            'symptoms': list(current_symptoms),
            'primary_syndrome': primary_syndrome,
            'metrics': metrics.copy()
        })
        
        logger.info(f"ğŸ“ˆ å¢å¼·ç‰ˆæ”¶æ–‚åº¦ [æœƒè©± {session_id}]: {metrics['overall_convergence']:.3f}")
        logger.info(f"   ç©©å®šæ€§={metrics['case_stability']:.2f}, è¦†è“‹ç‡={metrics['evidence_coverage']:.2f}, è­‰å‹ç½®ä¿¡={metrics['syndrome_confidence']:.2f}")
        
        return metrics
    
    def _calculate_enhanced_evidence_coverage(
        self,
        history: List[Dict[str, Any]],
        current_symptoms: set,
        tongue_pulse_hits: int
        ) -> float:
        """
        å¢å¼·ç‰ˆè­‰æ“šè¦†è“‹åº¦ï¼šèˆŒè„ˆå‘½ä¸­ Ã—1.3
        """
        all_symptoms = current_symptoms.copy()
        for h in history:
            all_symptoms.update(h.get('symptoms', []))
        
        tcm_symptoms = self.tcm_symptoms
        if not tcm_symptoms:
            return 0.5
        
        # æœ‰æ•ˆç—‡ç‹€
        valid_symptoms = all_symptoms & tcm_symptoms
        
        # åŸºç¤è¦†è“‹ç‡
        base_coverage = len(valid_symptoms) / min(len(tcm_symptoms), 50)
        
        # âœ… èˆŒè„ˆåŠ æ¬Šï¼ˆæ¯å€‹èˆŒè„ˆå‘½ä¸­ +0.05ï¼Œæœ€å¤š +0.15ï¼‰
        tongue_pulse_bonus = min(tongue_pulse_hits * 0.05, 0.15)
        
        coverage = base_coverage + tongue_pulse_bonus
        
        logger.debug(f"   è­‰æ“šè¦†è“‹: åŸºç¤={base_coverage:.2f}, èˆŒè„ˆåŠ æ¬Š=+{tongue_pulse_bonus:.2f}")
        
        return min(1.0, coverage)
    
    def _calculate_syndrome_confidence(
        self,
        primary_syndrome: str,
        secondary_syndromes: List[str],
        current_result: Dict[str, Any]
    ) -> float:
        """
        è¨ˆç®—è­‰å‹ç½®ä¿¡åº¦ï¼šä¸»è­‰èˆ‡æ¬¡è­‰åˆ†å·®çš„ sigmoid
        
        å…¬å¼ï¼šsigmoid(ä¸»è­‰åˆ†æ•¸ - æœ€é«˜æ¬¡è­‰åˆ†æ•¸)
        """
        # æå–åˆ†æ•¸
        syndrome_result = current_result.get("syndrome_result")
        if not syndrome_result:
            return 0.5
        
        primary_score = syndrome_result.confidence
        
        # ç²å–æ¬¡è­‰æœ€é«˜åˆ†
        secondary_score = 0.0
        if hasattr(syndrome_result, 'secondary_scores') and syndrome_result.secondary_scores:
            secondary_score = max(syndrome_result.secondary_scores.values())
        elif secondary_syndromes:
            # å‡è¨­æ¬¡è­‰åˆ†æ•¸ç‚ºä¸»è­‰çš„ 0.6-0.8
            secondary_score = primary_score * 0.7
        
        # åˆ†å·®
        diff = primary_score - secondary_score
        
        # Sigmoid è½‰æ›
        confidence = 1.0 / (1.0 + np.exp(-5 * diff))
        
        logger.debug(f"   è­‰å‹ç½®ä¿¡: ä¸»={primary_score:.2f}, æ¬¡={secondary_score:.2f}, å·®={diff:.2f} â†’ {confidence:.2f}")
        
        return confidence
    
    def _calculate_enhanced_overall_convergence(self, metrics: Dict[str, float]) -> float:
        """
        å¢å¼·ç‰ˆç¶œåˆæ”¶æ–‚åº¦
        
        å…¬å¼ï¼šConvergence = 0.4*Stability + 0.35*Coverage + 0.25*Confidence
        """
        # æ–°æ¬Šé‡
        weights = {
            'case_stability': 0.4,
            'evidence_coverage': 0.35,
            'syndrome_confidence': 0.25 if metrics.get('syndrome_confidence', 0) > 0 else 0.0
        }
        
        # å¦‚æœæ²’æœ‰è­‰å‹ç½®ä¿¡åº¦ï¼Œä½¿ç”¨èˆŠæ–¹æ¡ˆ
        if weights['syndrome_confidence'] == 0:
            weights = {
                'case_stability': 0.4,
                'evidence_coverage': 0.4,
                'semantic_consistency': 0.2
            }
        
        weighted_sum = 0.0
        for key, weight in weights.items():
            value = metrics.get(key, 0.0)
            
            # åˆ†æ•¸æå‡ç‡ç‰¹æ®Šè™•ç†
            if key == 'score_improvement':
                value = (value + 1.0) / 2.0
            
            weighted_sum += value * weight
        
        return max(0.0, min(1.0, weighted_sum))