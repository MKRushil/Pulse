# -*- coding: utf-8 -*-
"""
çµ‚æ­¢æ¢ä»¶ç®¡ç†å™¨ - ç¡¬æ¢ä»¶ + è»Ÿæ¢ä»¶é›™å±¤åˆ¤æ–·
"""

from typing import Dict, List, Any, Tuple
from dataclasses import dataclass
import yaml
from pathlib import Path
from ..utils.logger import get_logger

logger = get_logger("StopCriteria")

@dataclass
class StopDecision:
    """çµ‚æ­¢æ±ºç­–"""
    should_stop: bool
    stop_reason: str
    hard_rule_triggered: str  # è§¸ç™¼çš„ç¡¬è¦å‰‡åç¨±
    soft_score: float         # è»Ÿæ¢ä»¶åŠ æ¬Šåˆ†æ•¸
    can_save: bool
    treatment_effective: bool
    recommendations: List[str]  # çµ¦ä½¿ç”¨è€…çš„å»ºè­°

class StopCriteriaManager:
    """çµ‚æ­¢æ¢ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, config_path: Path = None):
        """è¼‰å…¥çµ‚æ­¢è¦å‰‡é…ç½®"""
        if config_path is None:
            config_path = Path(__file__).parent.parent / "knowledge" / "stop_rules.yaml"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            self.rules = yaml.safe_load(f)
        
        self.hard_rules = self.rules['hard_rules']
        self.soft_rules = self.rules['soft_rules']
        self.strategy = self.rules['stop_strategy']
        self.feedback_criteria = self.rules['feedback_criteria']
        
        logger.info("âœ… çµ‚æ­¢æ¢ä»¶ç®¡ç†å™¨åˆå§‹åŒ–")
        logger.info(f"   ç¡¬è¦å‰‡: {len(self.hard_rules)} æ¢")
        logger.info(f"   è»Ÿè¦å‰‡: {len(self.soft_rules)} æ¢")
    
    def evaluate(
        self,
        session_id: str,
        round_num: int,
        metrics: Dict[str, float],
        history: List[Dict[str, Any]],
        user_satisfied: bool = False
    ) -> StopDecision:
        """
        è©•ä¼°æ˜¯å¦æ‡‰è©²çµ‚æ­¢
        
        Args:
            session_id: æœƒè©±ID
            round_num: ç•¶å‰è¼ªæ¬¡
            metrics: æ”¶æ–‚æŒ‡æ¨™ {CI, SC, RCI, CMS, CSC, CAS, ...}
            history: æ­·å²è¨˜éŒ„
            user_satisfied: ä½¿ç”¨è€…æ˜¯å¦æ¨™è¨˜æ»¿æ„
        
        Returns:
            StopDecision
        """
        
        # ==================== 1. æœ€å°è¼ªæ¬¡ä¿è­· ====================
        if round_num < self.strategy['min_rounds']:
            return StopDecision(
                should_stop=False,
                stop_reason=f"æœªé”æœ€å°è¼ªæ¬¡ {self.strategy['min_rounds']}",
                hard_rule_triggered="",
                soft_score=0.0,
                can_save=False,
                treatment_effective=False,
                recommendations=["ç¹¼çºŒè£œå……ç—‡ç‹€è³‡è¨Š"]
            )
        
        # ==================== 2. ç¡¬æ¢ä»¶æª¢æŸ¥ ====================
        hard_triggered, hard_reason = self._check_hard_rules(
            round_num, metrics, history, user_satisfied
        )
        
        if hard_triggered:
            logger.info(f"ğŸ›‘ ç¡¬æ¢ä»¶è§¸ç™¼: {hard_reason}")
            
            # åˆ¤æ–·æ˜¯å¦å¯å„²å­˜
            can_save, treatment_effective = self._evaluate_feedback_criteria(metrics, round_num)
            
            return StopDecision(
                should_stop=True,
                stop_reason=hard_reason,
                hard_rule_triggered=hard_triggered,
                soft_score=0.0,  # ç¡¬æ¢ä»¶è§¸ç™¼æ™‚è»Ÿåˆ†æ•¸ä¸é‡è¦
                can_save=can_save,
                treatment_effective=treatment_effective,
                recommendations=self._generate_recommendations(metrics, can_save)
            )
        
        # ==================== 3. è»Ÿæ¢ä»¶æª¢æŸ¥ ====================
        if round_num >= self.strategy['soft_start_round']:
            soft_score = self._calculate_soft_score(metrics, history)
            
            logger.info(f"ğŸ“Š è»Ÿæ¢ä»¶åˆ†æ•¸: {soft_score:.2f}")
            
            if soft_score >= self.strategy['soft_threshold']:
                logger.info(f"âš ï¸  è»Ÿæ¢ä»¶å»ºè­°çµ‚æ­¢ (åˆ†æ•¸ {soft_score:.2f} â‰¥ {self.strategy['soft_threshold']})")
                
                can_save, treatment_effective = self._evaluate_feedback_criteria(metrics, round_num)
                
                return StopDecision(
                    should_stop=True,
                    stop_reason=f"è»Ÿæ¢ä»¶å»ºè­°çµ‚æ­¢ (åˆ†æ•¸={soft_score:.2f})",
                    hard_rule_triggered="",
                    soft_score=soft_score,
                    can_save=can_save,
                    treatment_effective=treatment_effective,
                    recommendations=self._generate_recommendations(metrics, can_save)
                )
        
        # ==================== 4. ç¹¼çºŒæ¨ç† ====================
        return StopDecision(
            should_stop=False,
            stop_reason="",
            hard_rule_triggered="",
            soft_score=self._calculate_soft_score(metrics, history) if round_num >= self.strategy['soft_start_round'] else 0.0,
            can_save=False,
            treatment_effective=False,
            recommendations=self._generate_continue_recommendations(metrics, history)
        )
    
    def _check_hard_rules(
        self,
        round_num: int,
        metrics: Dict[str, float],
        history: List[Dict[str, Any]],
        user_satisfied: bool
    ) -> Tuple[str, str]:
        """
        æª¢æŸ¥ç¡¬æ¢ä»¶
        
        Returns:
            (è§¸ç™¼çš„è¦å‰‡åç¨±, åŸå› æè¿°)
        """
        # æŒ‰å„ªå…ˆç´šæ’åº
        sorted_rules = sorted(self.hard_rules, key=lambda r: r.get('priority', 999))
        
        for rule in sorted_rules:
            name = rule['name']
            conditions = rule['conditions']
            
            # è¦å‰‡ 1: convergence_coverage
            if name == "convergence_coverage":
                ci = metrics.get('Final', metrics.get('overall_convergence', 0))
                sc = metrics.get('evidence_coverage', 0)
                
                if ci >= conditions['ci_min'] and sc >= conditions['sc_min']:
                    return name, f"CI={ci:.2f} â‰¥ {conditions['ci_min']}, SC={sc:.2f} â‰¥ {conditions['sc_min']}"
            
            # è¦å‰‡ 2: retrieval_stability
            elif name == "retrieval_stability":
                rci = metrics.get('RCI', 0)
                same_rounds = conditions['same_diagnosis_rounds']
                
                if rci >= conditions['rci_min']:
                    # æª¢æŸ¥æœ€è¿‘ N è¼ªè¨ºæ–·æ˜¯å¦ç›¸åŒ
                    if self._check_diagnosis_consistency(history, same_rounds):
                        return name, f"RCI={rci:.2f} â‰¥ {conditions['rci_min']}, é€£çºŒ{same_rounds}è¼ªè¨ºæ–·ä¸€è‡´"
            
            # è¦å‰‡ 3: user_satisfied
            elif name == "user_satisfied":
                if user_satisfied:
                    return name, "ä½¿ç”¨è€…æ¨™è¨˜æ»¿æ„"
            
            # è¦å‰‡ 4: max_rounds_reached
            elif name == "max_rounds_reached":
                if round_num >= conditions['max_rounds']:
                    return name, f"é”åˆ°æœ€å¤§è¼ªæ¬¡ {conditions['max_rounds']}"
        
        return "", ""
    
    def _calculate_soft_score(
        self,
        metrics: Dict[str, float],
        history: List[Dict[str, Any]]
    ) -> float:
        """è¨ˆç®—è»Ÿæ¢ä»¶åŠ æ¬Šåˆ†æ•¸"""
        total_score = 0.0
        
        for rule in self.soft_rules:
            name = rule['name']
            conditions = rule['conditions']
            weight = rule['weight']
            satisfied = False
            
            # è»Ÿè¦å‰‡ 1: convergence_plateau
            if name == "convergence_plateau":
                satisfied = self._check_convergence_plateau(
                    history,
                    conditions['delta_ci_max'],
                    conditions['plateau_rounds']
                )
            
            # è»Ÿè¦å‰‡ 2: low_new_symptoms
            elif name == "low_new_symptoms":
                new_rate = metrics.get('new_symptom_rate', 1.0)
                satisfied = new_rate <= conditions['new_symptom_rate_max']
            
            # è»Ÿè¦å‰‡ 3: high_case_stability
            elif name == "high_case_stability":
                stability = metrics.get('case_stability', 0)
                satisfied = stability >= conditions['case_stability_min']
            
            # è»Ÿè¦å‰‡ 4: high_semantic_consistency
            elif name == "high_semantic_consistency":
                consistency = metrics.get('semantic_consistency', 0)
                satisfied = consistency >= conditions['semantic_consistency_min']
            
            if satisfied:
                total_score += weight
                logger.debug(f"  âœ“ {name} æ»¿è¶³ (+{weight})")
        
        return total_score
    
    def _check_diagnosis_consistency(
        self,
        history: List[Dict[str, Any]],
        required_rounds: int
    ) -> bool:
        """æª¢æŸ¥æœ€è¿‘ N è¼ªè¨ºæ–·æ˜¯å¦ä¸€è‡´"""
        if len(history) < required_rounds:
            return False
        
        recent = history[-required_rounds:]
        diagnoses = [h.get('primary', {}).get('diagnosis', '') for h in recent]
        
        return len(set(diagnoses)) == 1 and diagnoses[0] != ''
    
    def _check_convergence_plateau(
        self,
        history: List[Dict[str, Any]],
        max_delta: float,
        required_rounds: int
    ) -> bool:
        """æª¢æŸ¥æ”¶æ–‚æ˜¯å¦è¶¨ç·©"""
        if len(history) < required_rounds + 1:
            return False
        
        recent = history[-(required_rounds + 1):]
        cis = [h.get('convergence', {}).get('overall_convergence', 0) for h in recent]
        
        # è¨ˆç®—ç›¸é„°è¼ªæ¬¡çš„è®ŠåŒ–é‡
        deltas = [abs(cis[i+1] - cis[i]) for i in range(len(cis) - 1)]
        
        return all(d <= max_delta for d in deltas)
    
    def _evaluate_feedback_criteria(
        self,
        metrics: Dict[str, float],
        round_num: int
    ) -> Tuple[bool, bool]:
        """
        è©•ä¼°å›é¥‹åˆ¤å®š
        
        Returns:
            (can_save, treatment_effective)
        """
        save_crit = self.feedback_criteria['can_save']
        treat_crit = self.feedback_criteria['treatment_effective']
        
        ci = metrics.get('Final', metrics.get('overall_convergence', 0))
        coverage = metrics.get('evidence_coverage', 0)
        stability = metrics.get('case_stability', 0)
        semantic = metrics.get('semantic_consistency', 0)
        
        # å¯å„²å­˜åˆ¤å®š
        can_save = (
            ci >= save_crit['ci_min'] and
            coverage >= save_crit['coverage_min'] and
            stability >= save_crit['stability_min'] and
            round_num >= save_crit['min_rounds']
        )
        
        # æ²»ç™‚æœ‰æ•ˆåˆ¤å®šï¼ˆæ›´åš´æ ¼ï¼‰
        treatment_effective = (
            ci >= treat_crit['ci_min'] and
            coverage >= treat_crit['coverage_min'] and
            stability >= treat_crit['stability_min'] and
            semantic >= treat_crit['semantic_min']
        )
        
        return can_save, treatment_effective
    
    def _generate_recommendations(
        self,
        metrics: Dict[str, float],
        can_save: bool
    ) -> List[str]:
        """ç”Ÿæˆçµ‚æ­¢å¾Œçš„å»ºè­°"""
        recs = []
        
        if can_save:
            recs.append("âœ… è¨ºæ–·å·²æ”¶æ–‚ï¼Œå¯å„²å­˜ç‚ºå›é¥‹æ¡ˆä¾‹")
        
        ci = metrics.get('Final', 0)
        if ci >= 0.90:
            recs.append("ğŸ¯ è¨ºæ–·ç½®ä¿¡åº¦æ¥µé«˜ï¼Œå»ºè­°ä¾æ­¤åˆ¶å®šæ²»ç™‚æ–¹æ¡ˆ")
        elif ci >= 0.85:
            recs.append("ğŸ“‹ è¨ºæ–·åŸºæœ¬ç¢ºå®šï¼Œå¯ä½œç‚ºè‡¨åºŠåƒè€ƒ")
        else:
            recs.append("âš ï¸  è¨ºæ–·å°šå¯ï¼Œå»ºè­°çµåˆè‡¨åºŠè¤‡è¨º")
        
        return recs
    
    def _generate_continue_recommendations(
        self,
        metrics: Dict[str, float],
        history: List[Dict[str, Any]]
    ) -> List[str]:
        """ç”Ÿæˆç¹¼çºŒæ¨ç†çš„å»ºè­°"""
        recs = []
        
        # æª¢æŸ¥ç¼ºå£
        coverage = metrics.get('evidence_coverage', 0)
        if coverage < 0.6:
            recs.append("è«‹è£œå……æ›´å¤šç—‡ç‹€æè¿°")
        
        # æª¢æŸ¥èˆŒè„ˆ
        has_tongue = any('èˆŒ' in str(h) for h in history)
        has_pulse = any('è„ˆ' in str(h) for h in history)
        
        if not has_tongue:
            recs.append("å»ºè­°è£œå……èˆŒè±¡è³‡è¨Šï¼ˆèˆŒè³ªã€èˆŒè‹”ï¼‰")
        if not has_pulse:
            recs.append("å»ºè­°è£œå……è„ˆè±¡è³‡è¨Š")
        
        if not recs:
            recs.append("ç¹¼çºŒè£œå……ç´°ç¯€ä»¥æé«˜è¨ºæ–·æº–ç¢ºæ€§")
        
        return recs