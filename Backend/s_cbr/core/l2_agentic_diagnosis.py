# -*- coding: utf-8 -*-
"""
L2 Agentic è¨ºæ–·å±¤ - å·¥å…·æ•´åˆæ¨¡çµ„ï¼ˆä¿®æ­£ç‰ˆï¼‰
================================

ä¿®æ­£å…§å®¹ï¼š
1. âœ… æ·»åŠ  enhance_diagnosis() é©é…æ–¹æ³•ï¼ˆç”¨æ–¼ four_layer_pipeline èª¿ç”¨ï¼‰
2. âœ… æ·»åŠ  _extract_diagnosis_from_l2_result() è¼”åŠ©æ–¹æ³•
3. âœ… æ·»åŠ  _evaluate_case_completeness_from_l2() è©•ä¼°æ–¹æ³•
4. âœ… æ·»åŠ  _evaluate_diagnosis_confidence_from_l2() è©•ä¼°æ–¹æ³•
5. âœ… å‹•æ…‹æ·»åŠ  diagnosis_confidence å’Œ case_completeness å±¬æ€§åˆ°è¼¸å‡º

è·è²¬ï¼š
1. æ¥æ”¶ L1 æª¢ç´¢çµæœï¼Œé€²è¡Œæ¡ˆä¾‹éŒ¨å®šè¨ºæ–·
2. è‡ªä¸»åˆ¤æ–·æ˜¯å¦éœ€è¦èª¿ç”¨å¤–éƒ¨å·¥å…·
3. åŸ·è¡Œå¹»è¦ºæ ¡é©—ã€çŸ¥è­˜è£œå……ã€æ¬Šå¨èƒŒæ›¸
4. è¼¸å‡ºç¶“éé©—è­‰çš„è¨ºæ–·çµæœ

å·¥å…·èª¿ç”¨ç­–ç•¥ï¼š
- Tool A (ICD-11)ï¼šæ¬Šå¨æ€§èƒŒæ›¸ï¼Œè¨ºæ–·è¼¸å‡ºæ™‚èª¿ç”¨
- Tool B (A+ç™¾ç§‘)ï¼šçŸ¥è­˜è£œå……ï¼Œæ¡ˆä¾‹è³‡è¨Šä¸è¶³æ™‚èª¿ç”¨
- Tool C (ETCM)ï¼šå¹»è¦ºæ ¡é©—ï¼Œè­‰å‹åˆ¤æ–·éœ€è¦ç§‘å­¸é©—è­‰æ™‚èª¿ç”¨

è¨­è¨ˆåŸå‰‡ï¼š
- å·¥å…·èª¿ç”¨æ˜¯ã€Œå¯é¸å¢å¼·ã€ï¼Œä¸æ˜¯ã€Œå¿…è¦æ­¥é©Ÿã€
- å„ªå…ˆä½¿ç”¨æ¡ˆä¾‹çŸ¥è­˜ï¼Œå·¥å…·ç”¨æ–¼è£œå……å’Œé©—è­‰
- å·¥å…·å¤±æ•—ä¸æ‡‰é˜»æ–·è¨ºæ–·æµç¨‹
"""

from __future__ import annotations
from typing import Any, Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import logging
import asyncio

# å°å…¥æ‚¨å·²é–‹ç™¼çš„å·¥å…·åº«
from ..tools.tcm_tools import TCMTools, TCMUnifiedToolkit
from ..utils.terminology_manager import TerminologyManager

logger = logging.getLogger("L2AgenticDiagnosis")


# ==================== æ•¸æ“šçµæ§‹å®šç¾© ====================

class ToolCallReason(Enum):
    """å·¥å…·èª¿ç”¨åŸå› æšèˆ‰"""
    KNOWLEDGE_GAP = "knowledge_gap"           # æ¡ˆä¾‹çŸ¥è­˜ä¸è¶³
    HALLUCINATION_CHECK = "hallucination_check"  # éœ€è¦å¹»è¦ºæ ¡é©—
    AUTHORITY_ENDORSEMENT = "authority_endorsement"  # éœ€è¦æ¬Šå¨èƒŒæ›¸
    FULL_VALIDATION = "full_validation"       # å®Œæ•´é©—è­‰ï¼ˆfallbackï¼‰


@dataclass
class ToolCallDecision:
    """å·¥å…·èª¿ç”¨æ±ºç­–çµæœ"""
    should_call_tool_a: bool = False  # ICD-11 è¡“èªæ¨™æº–åŒ–
    should_call_tool_b: bool = False  # A+ç™¾ç§‘ è¾¨è­‰é‚è¼¯
    should_call_tool_c: bool = False  # ETCM ç¾ä»£å°ç…§
    reasons: List[ToolCallReason] = field(default_factory=list)
    target_terms: List[str] = field(default_factory=list)  # éœ€è¦æŸ¥è©¢çš„è¡“èª


@dataclass
class ToolCallResult:
    """å·¥å…·èª¿ç”¨çµæœ"""
    tool_name: str
    success: bool
    content: str
    error: Optional[str] = None


@dataclass
class L2AgenticOutput:
    """L2 Agentic è¼¸å‡ºçµæ§‹"""
    # æ ¸å¿ƒè¨ºæ–·çµæœ
    anchored_case: Dict[str, Any]           # éŒ¨å®šæ¡ˆä¾‹
    syndrome_analysis: str                   # è­‰å‹åˆ†æ
    diagnosis_reasoning: str                 # è¨ºæ–·æ¨ç†
    
    # å·¥å…·å¢å¼·çµæœ
    tool_decisions: ToolCallDecision         # å·¥å…·èª¿ç”¨æ±ºç­–
    tool_results: List[ToolCallResult]       # å·¥å…·èª¿ç”¨çµæœ
    
    # é©—è­‰èˆ‡èƒŒæ›¸
    validation_status: str                   # "validated" | "partially_validated" | "unvalidated"
    authority_references: List[str]          # æ¬Šå¨å¼•ç”¨
    knowledge_supplements: List[str]         # çŸ¥è­˜è£œå……
    modern_evidence: List[str]                  # ç¾ä»£ç§‘å­¸è­‰æ“šï¼ˆTool Cï¼‰
    
    # å…ƒæ•¸æ“š
    coverage_score: float                    # è¦†è“‹åº¦
    confidence_boost: float                  # å·¥å…·å¸¶ä¾†çš„ç½®ä¿¡åº¦æå‡
    follow_up_questions: List[str]           # è¿½å•å•é¡Œ


# ==================== L2 Agentic æ ¸å¿ƒé‚è¼¯ ====================

class L2AgenticDiagnosis:
    """
    L2 Agentic è¨ºæ–·å±¤
    
    æ ¸å¿ƒèƒ½åŠ›ï¼š
    1. æ¡ˆä¾‹éŒ¨å®šèˆ‡è¨ºæ–·æ¨ç†ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
    2. è‡ªä¸»æ±ºç­–æ˜¯å¦éœ€è¦å·¥å…·è¼”åŠ©ï¼ˆæ–°å¢ï¼‰
    3. å·¥å…·èª¿ç”¨èˆ‡çµæœæ•´åˆï¼ˆæ–°å¢ï¼‰
    4. è¨ºæ–·çµæœé©—è­‰èˆ‡å¢å¼·ï¼ˆæ–°å¢ï¼‰
    """
    
    def __init__(self, config: Any):
        """
        åˆå§‹åŒ– L2 Agentic è¨ºæ–·å±¤
        
        Args:
            config: SCBRConfig é…ç½®å¯¦ä¾‹
        """
        self.config = config
        self.toolkit = TCMUnifiedToolkit()
        self.tools = TCMTools()
        self.term_manager = TerminologyManager()
        
        # å·¥å…·èª¿ç”¨é…ç½®
        self.tool_config = {
            "enable_tool_calls": True,           # ç¸½é–‹é—œ
            "enable_tool_a": True,               # ICD-11 é–‹é—œ
            "enable_tool_b": True,               # A+ç™¾ç§‘ é–‹é—œ
            "enable_tool_c": True,               # ETCM é–‹é—œ
            "knowledge_gap_threshold": 0.6,      # çŸ¥è­˜ç¼ºå£é–€æª»ï¼ˆæ¡ˆä¾‹å®Œæ•´åº¦ä½æ–¼æ­¤å€¼è§¸ç™¼ Tool Bï¼‰
            "validation_confidence_threshold": 0.7,  # éœ€è¦é©—è­‰çš„ç½®ä¿¡åº¦é–€æª»
            "max_tool_calls_per_diagnosis": 3,   # å–®æ¬¡è¨ºæ–·æœ€å¤§å·¥å…·èª¿ç”¨æ¬¡æ•¸
            "tool_timeout": 15.0,                # å·¥å…·èª¿ç”¨è¶…æ™‚ï¼ˆç§’ï¼‰
        }
        
        logger.info("[L2Agentic] åˆå§‹åŒ–å®Œæˆ - å·¥å…·èª¿ç”¨å·²å•Ÿç”¨")
    
    # ==================== ä¸»è¦è¨ºæ–·æµç¨‹ ====================
    
    async def diagnose_with_tools(
        self,
        user_symptoms: str,
        retrieved_cases: List[Dict[str, Any]],
        l1_decision: Dict[str, Any]
    ) -> L2AgenticOutput:
        """
        åŸ·è¡Œå¸¶å·¥å…·å¢å¼·çš„è¨ºæ–·æµç¨‹
        
        Args:
            user_symptoms: ç”¨æˆ¶ç—‡ç‹€æè¿°ï¼ˆç´¯ç©å¾Œçš„å®Œæ•´æè¿°ï¼‰
            retrieved_cases: L1 æª¢ç´¢åˆ°çš„æ¡ˆä¾‹åˆ—è¡¨
            l1_decision: L1 çš„æ±ºç­–è³‡è¨Šï¼ˆåŒ…å«é—œéµè©ã€ç½®ä¿¡åº¦ç­‰ï¼‰
        
        Returns:
            L2AgenticOutput: å®Œæ•´çš„è¨ºæ–·è¼¸å‡º
        """
        logger.info("[L2Agentic] é–‹å§‹è¨ºæ–·æµç¨‹")
        
        # æ­¥é©Ÿ 1ï¼šæ¡ˆä¾‹éŒ¨å®šèˆ‡åˆæ­¥è¨ºæ–·
        anchored_case, initial_diagnosis = await self._anchor_and_diagnose(
            user_symptoms, retrieved_cases
        )
        
        # æ­¥é©Ÿ 2ï¼šè©•ä¼°æ¡ˆä¾‹å®Œæ•´åº¦èˆ‡è¨ºæ–·å“è³ª
        case_completeness = self._evaluate_case_completeness(anchored_case)
        diagnosis_confidence = self._evaluate_diagnosis_confidence(
            initial_diagnosis, l1_decision
        )
        
        # æ­¥é©Ÿ 3ï¼šè‡ªä¸»æ±ºç­–æ˜¯å¦éœ€è¦å·¥å…·èª¿ç”¨
        tool_decision = self._decide_tool_calls(
            anchored_case=anchored_case,
            initial_diagnosis=initial_diagnosis,
            case_completeness=case_completeness,
            diagnosis_confidence=diagnosis_confidence,
            l1_decision=l1_decision
        )
        
        # æ­¥é©Ÿ 4ï¼šåŸ·è¡Œå·¥å…·èª¿ç”¨ï¼ˆå¦‚æœ‰éœ€è¦ï¼‰
        tool_results = []
        if self._should_call_any_tool(tool_decision):
            tool_results = await self._execute_tool_calls(
                tool_decision, 
                initial_diagnosis.get("primary_syndrome", "")
            )
        
        # æ­¥é©Ÿ 5ï¼šæ•´åˆå·¥å…·çµæœï¼Œå¢å¼·è¨ºæ–·
        enhanced_diagnosis = self._integrate_tool_results(
            initial_diagnosis, tool_results
        )
        
        # æ­¥é©Ÿ 6ï¼šç”Ÿæˆæœ€çµ‚è¼¸å‡º
        output = self._build_output(
            anchored_case=anchored_case,
            enhanced_diagnosis=enhanced_diagnosis,
            tool_decision=tool_decision,
            tool_results=tool_results,
            case_completeness=case_completeness
        )
        
        logger.info(f"[L2Agentic] è¨ºæ–·å®Œæˆ - é©—è­‰ç‹€æ…‹: {output.validation_status}")
        return output
    
    # ==================== é©é…æ–¹æ³•ï¼ˆç”¨æ–¼ four_layer_pipeline èª¿ç”¨ï¼‰====================
    
    async def enhance_diagnosis(
        self,
        l2_raw_result: Dict[str, Any],
        l1_decision: Dict[str, Any],
        retrieved_cases: List[Dict[str, Any]]
    ) -> L2AgenticOutput:
        """
        è¨ºæ–·å¢å¼·æ–¹æ³• - é©é… four_layer_pipeline.py çš„èª¿ç”¨ä»‹é¢
        
        ğŸ†• é€™æ˜¯ä¸€å€‹é©é…å™¨æ–¹æ³•ï¼Œå°‡ four_layer_pipeline çš„èª¿ç”¨æ ¼å¼
        è½‰æ›ç‚ºå…§éƒ¨è¨ºæ–·é‚è¼¯çš„æ ¼å¼ã€‚
        """
        logger.info("[L2Agentic] ä½¿ç”¨ enhance_diagnosis é©é…æ–¹æ³•")
        
        # [MODIFIED] è™›æ“¬æ¡ˆä¾‹é˜²è­·ç¶²
        # è¬ä¸€çœŸçš„æ²’æœ‰æ¡ˆä¾‹ (retrieved_cases ç‚ºç©º)ï¼Œå‰µå»ºä¸€å€‹è™›æ“¬æ¡ˆä¾‹ä»¥é˜²å´©æ½°
        if not retrieved_cases:
            logger.warning("âš ï¸ L2 æ”¶åˆ° 0 å€‹æ¡ˆä¾‹ï¼Œä½¿ç”¨è™›æ“¬æ¡ˆä¾‹é€²è¡Œç´”ç†è«–è¨ºæ–·")
            virtual_case = {
                "case_id": "VIRTUAL_THEORY_CASE",
                "diagnosis": "å¾…å®š(ä¾ç—‡ç‹€æ¨æ–·)",
                "syndrome": "å¾…å®š",
                "chief_complaint": "è³‡è¨Šä¸è¶³ï¼Œå•Ÿå‹•ç´”ç†è«–æ¨æ–·æ¨¡å¼",
                "treatment": "å»ºè­°è«®è©¢é†«å¸«",
                "score": 0.0,
                "full_text": "æœ¬æ¡ˆä¾‹ç‚ºç³»çµ±ç”Ÿæˆçš„è™›æ“¬æ¡ˆä¾‹ï¼Œç”¨æ–¼åœ¨ç¼ºä¹æª¢ç´¢çµæœæ™‚ç¶­æŒæ¨ç†æµç¨‹ã€‚"
            }
            # é€™è£¡å¿…é ˆä½¿ç”¨ list æ›¿æ›ï¼Œä¸èƒ½ appendï¼Œå› ç‚ºåŸè®Šæ•¸å¯èƒ½æ˜¯ None
            retrieved_cases = [virtual_case]

        # æ­¥é©Ÿ 1ï¼šè©•ä¼°å‚³çµ± L2 è¨ºæ–·çš„å“è³ª
        case_completeness = self._evaluate_case_completeness_from_l2(l2_raw_result, retrieved_cases)
        diagnosis_confidence = self._evaluate_diagnosis_confidence_from_l2(
            l2_raw_result, l1_decision
        )
        
        logger.info(
            f"[L2Agentic] è©•ä¼°çµæœ\n"
            f"  æ¡ˆä¾‹å®Œæ•´åº¦: {case_completeness:.2f}\n"
            f"  è¨ºæ–·ç½®ä¿¡åº¦: {diagnosis_confidence:.2f}"
        )
        
        # æ­¥é©Ÿ 2ï¼šä½¿ç”¨éŒ¨å®šæ¡ˆä¾‹ï¼ˆç¾åœ¨ä¿è­‰è‡³å°‘æœ‰ä¸€å€‹ï¼Œå³ä½¿æ˜¯è™›æ“¬çš„ï¼‰
        anchored_case = retrieved_cases[0]
        
        # æ­¥é©Ÿ 3ï¼šå¾ l2_raw_result æå–è¨ºæ–·è³‡è¨Š
        # [MODIFIED] å‚³å…¥ retrieved_cases ä»¥ä¾›ä¿åº•ä½¿ç”¨ (åˆ©ç”¨æˆ‘å€‘å…ˆå‰ä¿®æ”¹éçš„ _extract æ–¹æ³•)
        initial_diagnosis = self._extract_diagnosis_from_l2_result(
            l2_raw_result,
            retrieved_cases=retrieved_cases
        )
        
        # æ­¥é©Ÿ 4ï¼šæ±ºç­–æ˜¯å¦éœ€è¦å·¥å…·èª¿ç”¨
        tool_decision = self._decide_tool_calls(
            anchored_case=anchored_case,
            initial_diagnosis=initial_diagnosis,
            case_completeness=case_completeness,
            diagnosis_confidence=diagnosis_confidence,
            l1_decision=l1_decision
        )
        
        # æ­¥é©Ÿ 5ï¼šåŸ·è¡Œå·¥å…·èª¿ç”¨ï¼ˆå¦‚æœ‰éœ€è¦ï¼‰
        tool_results = []
        if self._should_call_any_tool(tool_decision):
            num_tools = sum([
                tool_decision.should_call_tool_a,
                tool_decision.should_call_tool_b,
                tool_decision.should_call_tool_c
            ])
            logger.info(f"[L2Agentic] ä¸¦è¡ŒåŸ·è¡Œ {num_tools} å€‹å·¥å…·èª¿ç”¨")
            tool_results = await self._execute_tool_calls(
                tool_decision,
                initial_diagnosis.get("primary_syndrome", "")
            )
        else:
            logger.info("[L2Agentic] ç„¡éœ€èª¿ç”¨å·¥å…·ï¼Œæ¢ä»¶æœªè§¸ç™¼")
        
        # æ­¥é©Ÿ 6ï¼šæ•´åˆå·¥å…·çµæœ
        enhanced_diagnosis = self._integrate_tool_results(
            initial_diagnosis, tool_results
        )
        
        # æ­¥é©Ÿ 7ï¼šæ§‹å»ºè¼¸å‡º
        output = self._build_output(
            anchored_case=anchored_case,
            enhanced_diagnosis=enhanced_diagnosis,
            tool_decision=tool_decision,
            tool_results=tool_results,
            case_completeness=case_completeness
        )
        
        # ğŸ†• å‹•æ…‹æ·»åŠ å±¬æ€§ä¾› four_layer_pipeline ä½¿ç”¨
        output.diagnosis_confidence = diagnosis_confidence
        output.case_completeness = case_completeness
        
        logger.info(
            f"[L2Agentic] å¢å¼·å®Œæˆ\n"
            f"  é©—è­‰ç‹€æ…‹: {output.validation_status}\n"
            f"  å·¥å…·èª¿ç”¨æ•¸: {len(tool_results)}\n"
            f"  ç½®ä¿¡åº¦æå‡: +{output.confidence_boost:.2f}"
        )
        
        return output
    
    # ==================== [æ–°å¢] è¼”åŠ©æ–¹æ³• ====================

    def _extract_diagnosis_from_l2_result(
        self,
        l2_result: Dict[str, Any], retrieved_cases: List[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        å¾å‚³çµ± L2 è¨ºæ–·çµæœä¸­æå–è¨ºæ–·è³‡è¨Š (ä¿®æ­£åµŒå¥—çµæ§‹è®€å–)
        """
        # å„ªå…ˆå¾ tcm_inference æå–ï¼Œå¦‚æœæ²’æœ‰å‰‡å˜—è©¦å¾æ ¹ç›®éŒ„æå– (å…¼å®¹èˆŠç‰ˆ)
        inference = l2_result.get("tcm_inference", {})
        
        # ç›¸å®¹æ€§è™•ç†ï¼šå¦‚æœ LLM æ²’è¼¸å‡º tcm_inference å±¤ï¼Œä½†ç›´æ¥è¼¸å‡ºäº†æ¬„ä½
        if not inference and "primary_pattern" in l2_result:
             inference = l2_result

        # æ³¨æ„ï¼šPrompt ä¸­çš„æ¬„ä½åæ˜¯ primary_patternï¼Œä½†é€™è£¡å…§éƒ¨è®Šæ•¸ç”¨ primary_syndromeï¼Œéœ€æ˜ å°„
        primary = (
            inference.get("primary_pattern") or 
            l2_result.get("primary_pattern") or 
            l2_result.get("primary_syndrome") or 
            "å¾…å®š(è³‡è¨Šä¸è¶³)"
        )

        refusal_keywords = [
            "ç„¡æ³•å½¢æˆ", "ç„¡æ³•åˆ¤æ–·", "è³‡è¨Šä¸è¶³", "not be determined", 
            "no primary pattern", "n/a", "unknown", "none"
        ]
        
        # å¦‚æœ primary ç‚ºç©ºï¼Œæˆ–åŒ…å«æ‹’çµ•é—œéµè©
        if not primary or any(k in primary.lower() for k in refusal_keywords):
            # å˜—è©¦ä½¿ç”¨æª¢ç´¢åˆ°çš„ç¬¬ä¸€å€‹æ¡ˆä¾‹ä½œç‚ºä¿åº•
            if retrieved_cases and len(retrieved_cases) > 0:
                top_case = retrieved_cases[0]
                # å˜—è©¦å¾æ¡ˆä¾‹ä¸­æå–è¨ºæ–·
                fallback_diag = (
                    top_case.get("diagnosis") or 
                    top_case.get("syndrome") or 
                    top_case.get("primary_pattern")
                )
                if fallback_diag:
                    primary = f"{fallback_diag} (ç³»çµ±å¼·åˆ¶éŒ¨å®š)"
                    logger.warning(f"âš ï¸ LLM æ‹’çµ•è¨ºæ–·ï¼Œå·²å¼·åˆ¶ä½¿ç”¨ Top-1 æ¡ˆä¾‹ä¿åº•: {primary}")
            
            # å¦‚æœé€£æ¡ˆä¾‹éƒ½æ²’æœ‰ï¼Œæ‰çµ¦æœ€çµ‚ä¿åº•
            if not primary or any(k in primary.lower() for k in refusal_keywords):
                primary = "å¾…å®š (è³‡è¨Šæ¥µåº¦ç¼ºä¹)"

        return {
            "primary_syndrome": primary,
            "secondary_syndromes": [], 
            "pathogenesis": inference.get("pathogenesis", "") or l2_result.get("pathogenesis", ""),
            "treatment_principle": inference.get("treatment_principle", "") or l2_result.get("treatment_principle", ""),
            
            # status ä¹Ÿä¸åœ¨ inference è£¡ï¼Œè€Œæ˜¯åœ¨æ ¹ç›®éŒ„
            "confidence": 0.9 if l2_result.get("status") == "ok" else 0.6, 
            
            # reasoning å°æ‡‰ syndrome_analysis
            "reasoning": inference.get("syndrome_analysis", "åŸºæ–¼æ¡ˆä¾‹ç›¸ä¼¼åº¦æ¨æ–·")
        }
    
    def _evaluate_case_completeness_from_l2(
            self,
            l2_result: Dict[str, Any],
            retrieved_cases: List[Dict[str, Any]] = None
        ) -> float:
            """
            å¾ L2 è¨ºæ–·çµæœè©•ä¼°æ¡ˆä¾‹å®Œæ•´åº¦ï¼ˆå¼•å…¥æª¢ç´¢å“è³ªæ‡²ç½° & ä¿®æ­£è·¯å¾‘ï¼‰
            
            æª¢æŸ¥è¨ºæ–·çµæœä¸­æ˜¯å¦åŒ…å«å®Œæ•´çš„è¾¨è­‰è¦ç´ ï¼Œä¸¦æ ¹æ“šæª¢ç´¢åˆ†æ•¸é€²è¡ŒåŠ æ¬Šã€‚
            å¦‚æœæª¢ç´¢åˆ†æ•¸éä½ï¼Œä»£è¡¨ LLM çš„å…§å®¹å¯èƒ½æ˜¯å¼·è¡Œç”Ÿæˆçš„ï¼Œéœ€é™ä½å®Œæ•´åº¦ä»¥è§¸ç™¼å·¥å…·ã€‚
            
            Returns:
                å®Œæ•´åº¦åˆ†æ•¸ (0.0 - 1.0)
            """
            # 1. è¨ˆç®—åŸºç¤å…§å®¹åˆ†æ•¸ (Based on Content)
            content_score = 0.0
            
            # æå–æ¨è«–å±¤è³‡æ–™
            inference = l2_result.get("tcm_inference", {})
            
            # å®šç¾©æ¬„ä½æ˜ å°„ (æ¬Šé‡å -> JSON æ¬„ä½å)
            # å› ç‚º Prompt è¼¸å‡ºçš„æ˜¯ primary_pattern, syndrome_analysis ç­‰
            field_mapping = {
                "primary_syndrome": "primary_pattern",
                "pathogenesis": "pathogenesis",
                "treatment_principle": "treatment_principle",
                "reasoning": "syndrome_analysis"
            }
            
            weights = {
                "primary_syndrome": 0.4,      # ä¸»è­‰ (æ¬Šé‡èª¿é«˜)
                "pathogenesis": 0.3,          # ç—…å› ç—…æ©Ÿ
                "treatment_principle": 0.2,   # æ²»æ³•
                "reasoning": 0.1              # æ¨ç†ä¾æ“š
            }
            
            for weight_key, weight in weights.items():
                # å–å¾—æ­£ç¢ºçš„ JSON éµå
                json_key = field_mapping.get(weight_key, weight_key)
                
                # å„ªå…ˆæŸ¥ tcm_inferenceï¼Œæ²’æœ‰æŸ¥ root (ç›¸å®¹æ€§)
                value = inference.get(json_key) or l2_result.get(json_key)
                
                if value:
                    # æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ„ç¾©çš„å…§å®¹
                    # ç°¡å–®éæ¿¾ï¼šé•·åº¦ > 5 ä¸”ä¸åŒ…å«æ˜é¡¯çš„ã€Œå¾…å®šã€å­—çœ¼
                    if isinstance(value, str) and len(value) > 5 and "å¾…å®š" not in value:
                        content_score += weight
                    elif isinstance(value, (list, dict)) and len(value) > 0:
                        content_score += weight
            
            # 2. è¨ˆç®—æª¢ç´¢æ‡²ç½°å› å­ (Retrieval Penalty)
            penalty_factor = 1.0
            if retrieved_cases and len(retrieved_cases) > 0:
                top_case = retrieved_cases[0]
                # å…¼å®¹å¤šç¨®åˆ†æ•¸æ ¼å¼ (SearchEngine çš„ä¸åŒç‰ˆæœ¬å¯èƒ½å›å‚³ä¸åŒçµæ§‹)
                max_score = float(
                    top_case.get("score") or 
                    top_case.get("_additional", {}).get("score") or 
                    top_case.get("_final_score") or 
                    0.0
                )
                
                # é‚è¼¯ï¼šå¦‚æœæœ€é«˜åˆ†æ¡ˆä¾‹åˆ†æ•¸ä½æ–¼ 0.75ï¼Œèªªæ˜çŸ¥è­˜åº«æ”¯æŒä¸è¶³
                if max_score < 0.60:
                    penalty_factor = 0.5  # åš´é‡ä¸è¶³ -> å¿…è§¸ç™¼å·¥å…·
                elif max_score < 0.75:
                    penalty_factor = 0.7  # ä¸­åº¦ä¸è¶³ -> æ¥µå¯èƒ½è§¸ç™¼å·¥å…·

            final_score = content_score * penalty_factor
            return min(1.0, final_score)
    
    def _evaluate_case_completeness_from_l2(
        self,
        l2_result: Dict[str, Any],
        retrieved_cases: List[Dict[str, Any]] = None
    ) -> float:
        """
        å¾ L2 è¨ºæ–·çµæœè©•ä¼°æ¡ˆä¾‹å®Œæ•´åº¦ï¼ˆå¼•å…¥æª¢ç´¢å“è³ªæ‡²ç½°ï¼‰
        
        æª¢æŸ¥è¨ºæ–·çµæœä¸­æ˜¯å¦åŒ…å«å®Œæ•´çš„è¾¨è­‰è¦ç´ ï¼Œä¸¦æ ¹æ“šæª¢ç´¢åˆ†æ•¸é€²è¡ŒåŠ æ¬Šã€‚
        å¦‚æœæª¢ç´¢åˆ†æ•¸éä½ï¼Œä»£è¡¨ LLM çš„å…§å®¹å¯èƒ½æ˜¯å¼·è¡Œç”Ÿæˆçš„ï¼Œéœ€é™ä½å®Œæ•´åº¦ä»¥è§¸ç™¼å·¥å…·ã€‚
        
        Returns:
            å®Œæ•´åº¦åˆ†æ•¸ (0.0 - 1.0)
        """
        # 1. è¨ˆç®—åŸºç¤å…§å®¹åˆ†æ•¸ (Based on Content)
        content_score = 0.0
        # æå–æ¨è«–å±¤è³‡æ–™
        inference = l2_result.get("tcm_inference", {})
        
        # å®šç¾©æ¬„ä½æ˜ å°„ (æ¬Šé‡å -> JSON æ¬„ä½å)
        field_mapping = {
            "primary_syndrome": "primary_pattern",
            "pathogenesis": "pathogenesis",
            "treatment_principle": "treatment_principle",
            "reasoning": "syndrome_analysis"
        }
        
        weights = {
            "primary_syndrome": 0.4,      # ä¸»è­‰ (æ¬Šé‡èª¿é«˜)
            "pathogenesis": 0.3,          # ç—…å› ç—…æ©Ÿ
            "treatment_principle": 0.2,   # æ²»æ³•
            "reasoning": 0.1              # æ¨ç†ä¾æ“š
        }
        
        for weight_key, weight in weights.items():
            json_key = field_mapping.get(weight_key, weight_key)
            # å„ªå…ˆæŸ¥ tcm_inferenceï¼Œæ²’æœ‰æŸ¥ root
            value = inference.get(json_key) or l2_result.get(json_key)
            
            if value:
                # æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ„ç¾©çš„å…§å®¹
                if isinstance(value, str) and len(value) > 5 and "å¾…å®š" not in value:
                    content_score += weight
        
        # 2. è¨ˆç®—æª¢ç´¢æ‡²ç½°å› å­ (Retrieval Penalty)
        penalty_factor = 1.0
        if retrieved_cases:
            # ç²å–æœ€é«˜åˆ†æ¡ˆä¾‹çš„åˆ†æ•¸ (å…¼å®¹å¤šç¨®æ ¼å¼)
            top_case = retrieved_cases[0]
            max_score = float(
                top_case.get("score") or 
                top_case.get("_additional", {}).get("score") or 
                top_case.get("_final_score") or 
                0.0
            )
            
            # é‚è¼¯ï¼šå¦‚æœæœ€é«˜åˆ†æ¡ˆä¾‹åˆ†æ•¸ä½æ–¼ 0.75ï¼Œèªªæ˜çŸ¥è­˜åº«æ”¯æŒä¸è¶³
            # å¼·åˆ¶æ‰“æŠ˜ä»¥è§¸ç™¼ Tool B (Knowledge Gap)
            if max_score < 0.60:
                penalty_factor = 0.5  # åš´é‡ä¸è¶³ï¼Œåˆ†æ•¸æ¸›åŠ -> å¿…è§¸ç™¼å·¥å…·
            elif max_score < 0.75:
                penalty_factor = 0.7  # ä¸­åº¦ä¸è¶³ï¼Œæ‰“ä¸ƒæŠ˜ -> æ¥µå¯èƒ½è§¸ç™¼å·¥å…·
                
        final_score = content_score * penalty_factor
        return min(1.0, final_score)
    
    def _evaluate_diagnosis_confidence_from_l2(
        self,
        l2_result: Dict[str, Any],
        l1_decision: Dict[str, Any]
    ) -> float:
        """
        å¾ L2 è¨ºæ–·çµæœå’Œ L1 æ±ºç­–è©•ä¼°è¨ºæ–·ç½®ä¿¡åº¦
        
        ç¶œåˆè€ƒæ…®ï¼š
        - L2 è¨ºæ–·çš„æ˜ç¢ºæ€§
        - L1 æª¢ç´¢çš„ç½®ä¿¡åº¦
        - è¨ºæ–·æ¨ç†çš„å®Œæ•´æ€§
        
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•¸ (0.0 - 1.0)
        """
        # åŸºç¤ç½®ä¿¡åº¦ä¾†è‡ª L2 è¨ºæ–·æœ¬èº«
        base_confidence = l2_result.get("confidence", 0.7)
        
        # L1 çš„æ•´é«”ç½®ä¿¡åº¦å½±éŸ¿
        l1_confidence = l1_decision.get("overall_confidence", 0.7)
        
        # ç¶œåˆè©•ä¼°ï¼ˆåŠ æ¬Šå¹³å‡ï¼‰
        # L2 è¨ºæ–·ç½®ä¿¡åº¦å  70%ï¼ŒL1 æª¢ç´¢ç½®ä¿¡åº¦å  30%
        combined_confidence = base_confidence * 0.7 + l1_confidence * 0.3
        
        # å¦‚æœè¨ºæ–·æ¨ç†å……åˆ†ï¼Œçµ¦äºˆçå‹µ
        if l2_result.get("reasoning") and len(str(l2_result["reasoning"])) > 50:
            combined_confidence += 0.05
        
        # å¦‚æœæœ‰æ˜ç¢ºçš„ç—…å› ç—…æ©Ÿï¼Œçµ¦äºˆçå‹µ
        if l2_result.get("pathogenesis") and len(str(l2_result["pathogenesis"])) > 30:
            combined_confidence += 0.05
        
        return min(1.0, combined_confidence)
    
    # ==================== æ¡ˆä¾‹éŒ¨å®šèˆ‡åˆæ­¥è¨ºæ–· ====================
    
    async def _anchor_and_diagnose(
        self,
        user_symptoms: str,
        retrieved_cases: List[Dict[str, Any]]
    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """
        åŸ·è¡Œæ¡ˆä¾‹éŒ¨å®šèˆ‡åˆæ­¥è¨ºæ–·ï¼ˆåŸæœ‰ L2 é‚è¼¯ï¼‰
        
        Returns:
            Tuple[éŒ¨å®šæ¡ˆä¾‹, åˆæ­¥è¨ºæ–·çµæœ]
        """
        # é¸æ“‡æœ€ä½³éŒ¨å®šæ¡ˆä¾‹
        if not retrieved_cases:
            return {}, {"error": "ç„¡å¯ç”¨æ¡ˆä¾‹"}
        
        # ç°¡åŒ–ç‰ˆï¼šé¸æ“‡ç¬¬ä¸€å€‹æ¡ˆä¾‹ä½œç‚ºéŒ¨å®š
        # å¯¦éš›æ‡‰ä½¿ç”¨åŠ æ¬Šç®—æ³•é¸æ“‡
        anchored_case = retrieved_cases[0]
        
        # ç”Ÿæˆåˆæ­¥è¨ºæ–·ï¼ˆé€™è£¡æ‡‰èª¿ç”¨ LLMï¼‰
        # ç›®å‰è¿”å›ä½”ä½çµæ§‹
        initial_diagnosis = {
            "primary_syndrome": anchored_case.get("syndrome", "å¾…åˆ†æ"),
            "secondary_syndromes": [],
            "pathogenesis": anchored_case.get("pathogenesis", ""),
            "treatment_principle": anchored_case.get("treatment", ""),
            "confidence": 0.7,
            "reasoning": "åŸºæ–¼æ¡ˆä¾‹ç›¸ä¼¼åº¦æ¨æ–·"
        }
        
        return anchored_case, initial_diagnosis
    
    # ==================== è©•ä¼°å‡½æ•¸ ====================
    
    def _evaluate_case_completeness(self, case: Dict[str, Any]) -> float:
        """
        è©•ä¼°æ¡ˆä¾‹è³‡è¨Šå®Œæ•´åº¦
        
        æª¢æŸ¥é …ç›®ï¼š
        - ç—‡ç‹€æè¿°
        - èˆŒè„ˆè³‡è¨Š
        - ç—…å› ç—…æ©Ÿ
        - è¾¨è­‰åˆ†æ
        - æ²»ç™‚æ–¹æ¡ˆ
        
        Returns:
            å®Œæ•´åº¦åˆ†æ•¸ (0.0 - 1.0)
        """
        if not case:
            return 0.0
        
        # å®šç¾©å¿…è¦æ¬„ä½åŠå…¶æ¬Šé‡
        required_fields = {
            "symptoms": 0.25,
            "tongue_pulse": 0.20,
            "pathogenesis": 0.20,
            "syndrome": 0.20,
            "treatment": 0.15
        }
        
        score = 0.0
        for field, weight in required_fields.items():
            if case.get(field):
                # ç°¡å–®æª¢æŸ¥ï¼šå­˜åœ¨ä¸”éç©º
                value = case[field]
                if isinstance(value, str) and len(value) > 5:
                    score += weight
                elif isinstance(value, (list, dict)) and len(value) > 0:
                    score += weight
        
        return score
    
    def _evaluate_diagnosis_confidence(
        self,
        diagnosis: Dict[str, Any],
        l1_decision: Dict[str, Any]
    ) -> float:
        """
        è©•ä¼°è¨ºæ–·çš„ç½®ä¿¡åº¦
        
        ç¶œåˆè€ƒæ…®ï¼š
        - L1 æª¢ç´¢çš„ç½®ä¿¡åº¦
        - è¨ºæ–·çš„å®Œæ•´æ€§
        - è­‰å‹çš„æ˜ç¢ºæ€§
        
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•¸ (0.0 - 1.0)
        """
        # åŸºç¤ç½®ä¿¡åº¦ä¾†è‡ªè¨ºæ–·æœ¬èº«
        base_confidence = diagnosis.get("confidence", 0.7)
        
        # å¦‚æœæœ‰æ˜ç¢ºçš„ä¸»è­‰ï¼Œæå‡ç½®ä¿¡åº¦
        if diagnosis.get("primary_syndrome") and diagnosis["primary_syndrome"] not in ["å¾…åˆ†æ", ""]:
            base_confidence += 0.05
        
        # å¦‚æœæœ‰ç—…å› ç—…æ©Ÿèªªæ˜ï¼Œæå‡ç½®ä¿¡åº¦
        if diagnosis.get("pathogenesis") and len(diagnosis["pathogenesis"]) > 20:
            base_confidence += 0.05
        
        # ç¶œåˆ L1 çš„ç½®ä¿¡åº¦
        l1_confidence = l1_decision.get("overall_confidence", 0.7)
        final_confidence = (base_confidence + l1_confidence) / 2
        
        return min(1.0, final_confidence)
    
    # ==================== å·¥å…·èª¿ç”¨æ±ºç­– ====================
    
    def _decide_tool_calls(
        self,
        anchored_case: Dict[str, Any],
        initial_diagnosis: Dict[str, Any],
        case_completeness: float,
        diagnosis_confidence: float,
        l1_decision: Dict[str, Any]
    ) -> ToolCallDecision:
        """
        è‡ªä¸»æ±ºç­–æ˜¯å¦éœ€è¦èª¿ç”¨å·¥å…·(æ·±åº¦æ•´åˆæ±ºç­–æ¨¹)
        
        æ±ºç­–é‚è¼¯ï¼š
        1. æ¡ˆä¾‹å®Œæ•´åº¦ < 0.6 â†’ èª¿ç”¨ Tool B è£œå……çŸ¥è­˜
        2. è¨ºæ–·ç½®ä¿¡åº¦ < 0.7 â†’ èª¿ç”¨ Tool C é€²è¡Œå¹»è¦ºæ ¡é©—
        3. æœ‰æ˜ç¢ºè­‰å‹ â†’ èª¿ç”¨ Tool A ç²å–æ¬Šå¨èƒŒæ›¸
        
        Returns:
            å·¥å…·èª¿ç”¨æ±ºç­–
        """
        decision = ToolCallDecision()
        target_syndrome = initial_diagnosis.get("primary_syndrome", "")
        
        # åŸºç¤æª¢æŸ¥ï¼šå¦‚æœæ²’æœ‰ç›®æ¨™è­‰å‹ï¼Œå·¥å…·ä¹Ÿç„¡æ³•æŸ¥è©¢ï¼Œç›´æ¥è¿”å›
        if not target_syndrome or "å¾…å®š" in target_syndrome:
            return decision

        # --- ç­–ç•¥ A: çŸ¥è­˜ç¼ºå£ (Knowledge Gap) -> Tool B (A+ç™¾ç§‘) ---
        # è§¸ç™¼æ¢ä»¶ï¼šå®Œæ•´åº¦ä½ï¼Œæˆ–ã€Œç—…å› ç—…æ©Ÿã€æ¬„ä½ç¼ºå¤±/éçŸ­
        has_pathogenesis = len(initial_diagnosis.get("pathogenesis", "")) > 20
        if case_completeness < self.tool_config["knowledge_gap_threshold"] or not has_pathogenesis:
            if self.tool_config["enable_tool_b"]:
                decision.should_call_tool_b = True
                decision.reasons.append(ToolCallReason.KNOWLEDGE_GAP)
                decision.target_terms.append(target_syndrome)
                logger.info(f"[L2Agentic] è§¸ç™¼ Tool B (ç—…æ©Ÿç¼ºå¤±/å®Œæ•´åº¦ä¸è¶³: {case_completeness:.2f})")

        # --- ç­–ç•¥ B: å¹»è¦ºæ ¡é©— (Hallucination Check) -> Tool C (ETCM) ---
        # è§¸ç™¼æ¢ä»¶ï¼šç½®ä¿¡åº¦ä½ï¼Œæˆ–ç¼ºä¹ç¾ä»£ç§‘å­¸è­‰æ“šæ”¯æŒ
        # é€™è£¡å‡è¨­ LLM è¼¸å‡ºçš„ initial_diagnosis å¯èƒ½åŒ…å«ç©ºçš„ modern_evidence æ¬„ä½
        if diagnosis_confidence < self.tool_config["validation_confidence_threshold"]:
            if self.tool_config["enable_tool_c"]:
                decision.should_call_tool_c = True
                decision.reasons.append(ToolCallReason.HALLUCINATION_CHECK)
                if target_syndrome not in decision.target_terms:
                    decision.target_terms.append(target_syndrome)
                logger.info(f"[L2Agentic] è§¸ç™¼ Tool C (ç½®ä¿¡åº¦ä¸è¶³: {diagnosis_confidence:.2f})")

        # --- ç­–ç•¥ C: æ¬Šå¨èƒŒæ›¸ (Authority Endorsement) -> Tool A (ICD-11) ---
        # è§¸ç™¼æ¢ä»¶ï¼šåªè¦æœ‰æ˜ç¢ºè­‰å‹ï¼Œå°±å˜—è©¦é€²è¡Œæ¨™æº–åŒ–é©—è­‰ (ä¸å†åªçœ‹é«˜ç½®ä¿¡åº¦)
        # é€™æ˜¯ç‚ºäº†é”æˆã€Œç¼ºä¹æ¨™æº–ç—…å -> èª¿ç”¨ Tool Aã€çš„é‚è¼¯
        if target_syndrome and len(target_syndrome) < 10: # é¿å…æ‹¿é•·å¥å­å»æŸ¥
            if self.tool_config["enable_tool_a"]:
                decision.should_call_tool_a = True
                decision.reasons.append(ToolCallReason.AUTHORITY_ENDORSEMENT)
                if target_syndrome not in decision.target_terms:
                    decision.target_terms.append(target_syndrome)
                logger.info("[L2Agentic] è§¸ç™¼ Tool A (å°‹æ±‚ ICD-11 æ¨™æº–åŒ–èƒŒæ›¸)")
        
        return decision
    
    def _should_call_any_tool(self, decision: ToolCallDecision) -> bool:
        """æª¢æŸ¥æ˜¯å¦éœ€è¦èª¿ç”¨ä»»ä½•å·¥å…·"""
        return (
            decision.should_call_tool_a or
            decision.should_call_tool_b or
            decision.should_call_tool_c
        )
    
    # ==================== å·¥å…·èª¿ç”¨åŸ·è¡Œ ====================
    
    async def _execute_tool_calls(
        self,
        decision: ToolCallDecision,
        primary_syndrome: str
    ) -> List[ToolCallResult]:
        """
        ä¸¦è¡ŒåŸ·è¡Œæ‰€æœ‰éœ€è¦çš„å·¥å…·èª¿ç”¨
        
        Args:
            decision: å·¥å…·èª¿ç”¨æ±ºç­–
            primary_syndrome: ä¸»è¦è­‰å‹åç¨±
        
        Returns:
            å·¥å…·èª¿ç”¨çµæœåˆ—è¡¨
        """
        tasks = []
        
        # æº–å‚™å·¥å…·èª¿ç”¨ä»»å‹™
        if decision.should_call_tool_a:
            tasks.append(self._call_tool_a(primary_syndrome))
        
        if decision.should_call_tool_b:
            tasks.append(self._call_tool_b(primary_syndrome))
        
        if decision.should_call_tool_c:
            tasks.append(self._call_tool_c(primary_syndrome))
        
        # ä¸¦è¡ŒåŸ·è¡Œï¼Œè¨­ç½®ç¸½è¶…æ™‚
        results = []
        if tasks:
            try:
                # ä½¿ç”¨ wait_for è¨­ç½®ç¸½é«”è¶…æ™‚
                completed = await asyncio.wait_for(
                    asyncio.gather(*tasks, return_exceptions=True),
                    timeout=self.tool_config["tool_timeout"]
                )
                
                for result in completed:
                    if isinstance(result, Exception):
                        results.append(ToolCallResult(
                            tool_name="unknown",
                            success=False,
                            content="",
                            error=str(result)
                        ))
                    else:
                        results.append(result)
            except asyncio.TimeoutError:
                logger.error("[L2Agentic] å·¥å…·èª¿ç”¨ç¸½é«”è¶…æ™‚")
                results.append(ToolCallResult(
                    tool_name="batch",
                    success=False,
                    content="",
                    error="å·¥å…·èª¿ç”¨æ‰¹æ¬¡è¶…æ™‚"
                ))
        
        return results
    
    async def _call_tool_a(self, term: str) -> ToolCallResult:
        """èª¿ç”¨ Tool A - ICD-11 è¡“èªæ¨™æº–åŒ–"""
        try:
            # ä½¿ç”¨ asyncio åŒ…è£åŒæ­¥èª¿ç”¨
            loop = asyncio.get_event_loop()
            content = await asyncio.wait_for(
                loop.run_in_executor(None, self.tools.tool_a_standardize_term, term),
                timeout=self.tool_config["tool_timeout"]
            )
            return ToolCallResult(
                tool_name="Tool A (ICD-11)",
                success=True,
                content=content
            )
        except asyncio.TimeoutError:
            return ToolCallResult(
                tool_name="Tool A (ICD-11)",
                success=False,
                content="",
                error="å·¥å…·èª¿ç”¨è¶…æ™‚"
            )
        except Exception as e:
            return ToolCallResult(
                tool_name="Tool A (ICD-11)",
                success=False,
                content="",
                error=str(e)
            )
    
    async def _call_tool_b(self, syndrome_name: str) -> ToolCallResult:
        """èª¿ç”¨ Tool B - A+ç™¾ç§‘è¾¨è­‰é‚è¼¯"""
        try:
            loop = asyncio.get_event_loop()
            content = await asyncio.wait_for(
                loop.run_in_executor(None, self.tools.tool_b_syndrome_logic, syndrome_name),
                timeout=self.tool_config["tool_timeout"]
            )
            return ToolCallResult(
                tool_name="Tool B (A+ç™¾ç§‘)",
                success=True,
                content=content
            )
        except asyncio.TimeoutError:
            return ToolCallResult(
                tool_name="Tool B (A+ç™¾ç§‘)",
                success=False,
                content="",
                error="å·¥å…·èª¿ç”¨è¶…æ™‚"
            )
        except Exception as e:
            return ToolCallResult(
                tool_name="Tool B (A+ç™¾ç§‘)",
                success=False,
                content="",
                error=str(e)
            )
    
    async def _call_tool_c(self, syndrome_name: str) -> ToolCallResult:
        """èª¿ç”¨ Tool C - ETCM ç¾ä»£å°ç…§"""
        try:
            loop = asyncio.get_event_loop()
            content = await asyncio.wait_for(
                loop.run_in_executor(None, self.tools.tool_c_modern_evidence, syndrome_name),
                timeout=self.tool_config["tool_timeout"]
            )
            return ToolCallResult(
                tool_name="Tool C (ETCM)",
                success=True,
                content=content
            )
        except asyncio.TimeoutError:
            return ToolCallResult(
                tool_name="Tool C (ETCM)",
                success=False,
                content="",
                error="å·¥å…·èª¿ç”¨è¶…æ™‚"
            )
        except Exception as e:
            return ToolCallResult(
                tool_name="Tool C (ETCM)",
                success=False,
                content="",
                error=str(e)
            )
    
    # ==================== çµæœæ•´åˆ ====================
    
    def _integrate_tool_results(
        self,
        initial_diagnosis: Dict[str, Any],
        tool_results: List[ToolCallResult]
    ) -> Dict[str, Any]:
        """
        æ•´åˆå·¥å…·çµæœåˆ°è¨ºæ–·ä¸­(è³‡è¨Šèåˆ)
        
        æ•´åˆç­–ç•¥ï¼š
        - Tool A çµæœ â†’ æ·»åŠ åˆ°æ¬Šå¨å¼•ç”¨
        - Tool B çµæœ â†’ è£œå……ç—…å› ç—…æ©Ÿã€è¾¨è­‰è¦é»
        - Tool C çµæœ â†’ æ·»åŠ ç¾ä»£ç§‘å­¸èªªæ˜
        
        Returns:
            å¢å¼·å¾Œçš„è¨ºæ–·çµæœ
        """
        enhanced = initial_diagnosis.copy()
        # åˆå§‹åŒ–å¢å¼·æ¬„ä½
        for field in ["authority_references", "knowledge_supplements", "modern_evidence", "validation_notes"]:
            if field not in enhanced: enhanced[field] = []
        
        for result in tool_results:
            if not result.success:
                enhanced["validation_notes"].append(f"{result.tool_name} èª¿ç”¨å¤±æ•—: {result.error}")
                continue

            # è‡ªå‹•å­¸ç¿’æ–°è© (ä¿ç•™åŸæœ¬é‚è¼¯)
            target_term = initial_diagnosis.get("primary_syndrome", "")
            if target_term and len(target_term) > 1 and "å¾…å®š" not in target_term:
                if hasattr(self, 'term_manager'):
                    self.term_manager.add_term(target_term)
            
            # --- èåˆé‚è¼¯ ---
            if "Tool A" in result.tool_name:
                # ICD-11 (æ¬Šå¨æ€§æœ€é«˜)
                if "ICD-11" in result.content and "æœªæ‰¾åˆ°" not in result.content:
                    enhanced["authority_references"].append(result.content)
                    # æ¨™è¨˜ç‚ºæ¨™æº–åŒ–åç¨±åƒè€ƒ (é›–ç„¶ä¸ç›´æ¥è¦†è“‹ primary_syndrome ä»¥å…ç ´å£ä¸Šä¸‹æ–‡ï¼Œä½†çµ¦äºˆæœ€é«˜æ¬Šé‡æ¨™è¨»)
                    enhanced["validation_notes"].insert(0, "â˜… è­‰å‹åç¨±å·²ç² WHO ICD-11 æ¨™æº–é©—è­‰")
            
            elif "Tool B" in result.tool_name:
                # A+ç™¾ç§‘ (å…§å®¹æœ€è±å¯Œ)
                if "è‡¨åºŠè¡¨ç¾" in result.content or "è¾¨è­‰" in result.content:
                    enhanced["knowledge_supplements"].append(result.content)
                    enhanced["validation_notes"].append("âœ“ å·²è£œå……è¾¨è­‰é‚è¼¯")
                    
                    # [é—œéµèåˆ] è‹¥åŸè¨ºæ–·ç¼ºä¹ç—…æ©Ÿï¼Œç›´æ¥ä½¿ç”¨ Tool B çš„å…§å®¹å¡«è£œ
                    if not enhanced.get("pathogenesis") or len(enhanced.get("pathogenesis", "")) < 10:
                        # é€™è£¡åšç°¡å–®æå–ï¼Œå¯¦éš›å¯ç”¨ Regex æå– "ç—…æ©Ÿ" æ®µè½
                        enhanced["pathogenesis"] = f"(ç”±å¤–éƒ¨çŸ¥è­˜åº«è£œå……) åƒè€ƒ A+ç™¾ç§‘ï¼š{result.content[:100]}..."
            
            elif "Tool C" in result.tool_name:
                # ETCM (ç§‘å­¸è­‰æ“š)
                if "ETCM" in result.content and "æœªæ‰¾åˆ°" not in result.content:
                    enhanced["modern_evidence"].append(result.content)
                    enhanced["validation_notes"].append("âœ“ å·²ç²å–ç¾ä»£ç§‘å­¸è­‰æ“š")
        
        return enhanced
    
    # ==================== è¼¸å‡ºæ§‹å»º-ä½¿ç”¨å‹•æ…‹æ¨¡å‹ ====================
    
    # [ä¿®æ”¹ 3] è¼¸å‡ºæ§‹å»ºï¼šä½¿ç”¨å‹•æ…‹æ¨¡å‹
    def _build_output(
        self,
        anchored_case: Dict[str, Any],
        enhanced_diagnosis: Dict[str, Any],
        tool_decision: ToolCallDecision,
        tool_results: List[ToolCallResult],
        case_completeness: float
    ) -> L2AgenticOutput:
        """
        æ§‹å»ºæœ€çµ‚çš„ L2 è¼¸å‡º
        """
        # è¨ˆç®—é©—è­‰ç‹€æ…‹
        successful_tools = sum(1 for r in tool_results if r.success)
        total_tools = len(tool_results)
        
        if total_tools == 0:
            validation_status = "unvalidated"
        elif successful_tools == total_tools:
            validation_status = "validated"
        else:
            validation_status = "partially_validated"
        
        # [ä¿®æ”¹é»] ä½¿ç”¨å‹•æ…‹ç®—æ³•è¨ˆç®—ç½®ä¿¡åº¦å¢ç›Š
        confidence_boost = self._calculate_confidence_boost(enhanced_diagnosis)
        
        # ç”Ÿæˆè¿½å•å•é¡Œï¼ˆå¦‚æœè¦†è“‹åº¦ä¸è¶³ï¼‰
        follow_up_questions = []
        if case_completeness < 0.7:
            follow_up_questions = self._generate_follow_up_questions(
                anchored_case, enhanced_diagnosis
            )
        
        return L2AgenticOutput(
            anchored_case=anchored_case,
            syndrome_analysis=enhanced_diagnosis.get("primary_syndrome", ""),
            diagnosis_reasoning=self._format_diagnosis_reasoning(enhanced_diagnosis),
            tool_decisions=tool_decision,
            tool_results=tool_results,
            validation_status=validation_status,
            authority_references=enhanced_diagnosis.get("authority_references", []),
            knowledge_supplements=enhanced_diagnosis.get("knowledge_supplements", []),
            modern_evidence=enhanced_diagnosis.get("modern_evidence", []),
            coverage_score=case_completeness,
            confidence_boost=confidence_boost, # é€™è£¡ä½¿ç”¨å‹•æ…‹è¨ˆç®—çš„å€¼
            follow_up_questions=follow_up_questions
        )
    
    def _format_diagnosis_reasoning(self, diagnosis: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è¨ºæ–·æ¨ç†èªªæ˜"""
        parts = []
        
        if diagnosis.get("reasoning"):
            parts.append(f"æ¨ç†ä¾æ“šï¼š{diagnosis['reasoning']}")
        
        if diagnosis.get("pathogenesis"):
            parts.append(f"ç—…å› ç—…æ©Ÿï¼š{diagnosis['pathogenesis']}")
        
        if diagnosis.get("validation_notes"):
            parts.append("é©—è­‰ç‹€æ…‹ï¼š" + " | ".join(diagnosis["validation_notes"]))
        
        return "\n".join(parts) if parts else "åŸºæ–¼æ¡ˆä¾‹ç›¸ä¼¼åº¦æ¨æ–·"
    
    def _generate_follow_up_questions(
        self,
        case: Dict[str, Any],
        diagnosis: Dict[str, Any]
    ) -> List[str]:
        """ç”Ÿæˆè¿½å•å•é¡Œ"""
        questions = []
        
        # æª¢æŸ¥ç¼ºå¤±çš„è³‡è¨Šé¡å‹
        if not case.get("tongue_pulse"):
            questions.append("è«‹å•æ‚¨çš„èˆŒè±¡å¦‚ä½•ï¼ŸèˆŒè³ªé¡è‰²ã€èˆŒè‹”åšè–„ï¼Ÿ")
            questions.append("æ‚¨çš„è„ˆè±¡æœ‰ä»€éº¼ç‰¹é»ï¼Ÿæ˜¯å¦æœ‰é†«å¸«æŠŠéè„ˆï¼Ÿ")
        
        if not case.get("duration"):
            questions.append("é€™äº›ç—‡ç‹€æŒçºŒå¤šé•·æ™‚é–“äº†ï¼Ÿ")
        
        if not case.get("triggers"):
            questions.append("æœ‰ä»€éº¼æƒ…æ³æœƒåŠ é‡æˆ–ç·©è§£é€™äº›ç—‡ç‹€ï¼Ÿ")
        
        return questions[:3]  # æœ€å¤šè¿”å› 3 å€‹è¿½å•
    
    #  å‹•æ…‹ç½®ä¿¡åº¦å¢ç›Šç®—æ³•
    def _calculate_confidence_boost(self, enhanced_diagnosis: Dict[str, Any]) -> float:
        """
        è¨ˆç®—è¨ºæ–·ç½®ä¿¡åº¦å¢ç›Š (Confidence Gain Model)
        å…¬å¼: Boost = Î£ (Tool_Relevance * Authority_Weight)
        """
        boost = 0.0
        
        # 1. æ¬Šå¨èƒŒæ›¸ (æ¬Šé‡æœ€é«˜ 0.15)
        # é‚è¼¯ï¼šå¦‚æœæœ‰ ICD-11 çš„çµæœï¼Œä»£è¡¨æ–¹å‘æ­£ç¢º
        if enhanced_diagnosis.get("authority_references"):
            boost += 0.15
            
        # 2. çŸ¥è­˜è£œå…… (æ¬Šé‡ 0.10)
        # é‚è¼¯ï¼šå…§å®¹è¶Šé•·ï¼Œä»£è¡¨çŸ¥è­˜å¡«è£œè¶Šå®Œæ•´ (ç°¡å–®çš„ heuristic)
        supplements = enhanced_diagnosis.get("knowledge_supplements", [])
        if supplements:
            content_len = sum(len(s) for s in supplements)
            if content_len > 100:
                boost += 0.10
            elif content_len > 0:
                boost += 0.05
                
        # 3. ç§‘å­¸é©—è­‰ (æ¬Šé‡ 0.05)
        # é‚è¼¯ï¼šé€™æ˜¯åŠ åˆ†é …
        if enhanced_diagnosis.get("modern_evidence"):
            boost += 0.05
            
        # ä¸Šé™æ§åˆ¶ï¼šå·¥å…·æœ€å¤šæå‡ 0.3 (30%) çš„ç½®ä¿¡åº¦ï¼Œé¿å…éåº¦ä¾è³´
        return min(0.3, boost)