# -*- coding: utf-8 -*-
"""
L2 Agentic è¨ºæ–·å±¤ - å·¥å…·æ•´åˆæ¨¡çµ„ï¼ˆä¿®æ­£ç‰ˆï¼‰
================================

ä¿®æ­£å…§å®¹ï¼š
1. âœ… æ·»åŠ  enhance_diagnosis() é©é…æ–¹æ³•ï¼ˆç”¨æ–¼ four_layer_pipeline èª¿ç”¨ï¼‰
2. âœ… æ·»åŠ  _extract_diagnosis_from_l2_result() è¼”åŠ©æ–¹æ³•
3. âœ… æ·»åŠ  _evaluate_case_completeness_from_l2() è©•ä¼°æ–¹æ³•
4. âœ… æ·»åŠ  _evaluate_diagnosis_confidence_from_l2() è©•ä¼°æ–¹æ³•
5. âœ… å‹•æ…‹æ·»åŠ  diagnosis_confidence å’Œ case_completeness å±¬æ€§åˆ°è¼¸å‡º
6. ğŸš¨ [NEW] æ–¹æ¡ˆä¸‰å¯¦è£ï¼šæª¢ç´¢ç‚º 0 æ™‚çš„è™›æ“¬æ¡ˆä¾‹ä¿åº•æ©Ÿåˆ¶ã€‚

è·è²¬ï¼š
1. æ¥æ”¶ L1 æª¢ç´¢çµæœï¼Œé€²è¡Œæ¡ˆä¾‹éŒ¨å®šè¨ºæ–·
2. è‡ªä¸»åˆ¤æ–·æ˜¯å¦éœ€è¦èª¿ç”¨å¤–éƒ¨å·¥å…·
3. åŸ·è¡Œå¹»è¦ºæ ¡é©—ã€çŸ¥è­˜è£œå……ã€æ¬Šå¨èƒŒæ›¸
4. è¼¸å‡ºç¶“éé©—è­‰çš„è¨ºæ–·çµæœ
"""

from __future__ import annotations
from typing import Any, Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import logging
import asyncio

# å°å…¥æ‚¨å·²é–‹ç™¼çš„å·¥å…·åº«
from ..tools.tcm_tools import TCMTools, TCMUnifiedToolkit
from ..utils.terminology_manager import TerminologyManager
from ..llm.embedding import EmbedClient
# from .search_engine import SearchEngine 

logger = logging.getLogger("L2AgenticDiagnosis")


# ==================== æ•¸æ“šçµæ§‹å®šç¾© ====================

class ToolCallReason(Enum):
    """å·¥å…·èª¿ç”¨åŸå› æšèˆ‰"""
    KNOWLEDGE_GAP = "knowledge_gap"           # æ¡ˆä¾‹çŸ¥è­˜ä¸è¶³
    HALLUCINATION_CHECK = "hallucination_check"  # éœ€è¦å¹»è¦ºæ ¡é©—
    AUTHORITY_ENDORSEMENT = "authority_endorsement"  # éœ€è¦æ¬Šå¨èƒŒæ›¸
    FULL_VALIDATION = "full_validation"       # å®Œæ•´é©—è­‰ï¼ˆfallbackï¼‰


@dataclass
class ToolCallDecision:
    """å·¥å…·èª¿ç”¨æ±ºç­–çµæœ"""
    should_call_tool_a: bool = False  # ICD-11 è¡“èªæ¨™æº–åŒ–
    should_call_tool_b: bool = False  # A+ç™¾ç§‘ è¾¨è­‰é‚è¼¯
    should_call_tool_c: bool = False  # ETCM ç¾ä»£å°ç…§
    reasons: List[ToolCallReason] = field(default_factory=list)
    target_terms: List[str] = field(default_factory=list)  # éœ€è¦æŸ¥è©¢çš„è¡“èª


@dataclass
class ToolCallResult:
    """å·¥å…·èª¿ç”¨çµæœ"""
    tool_name: str
    success: bool
    content: str
    error: Optional[str] = None


@dataclass
class L2AgenticOutput:
    """L2 Agentic è¼¸å‡ºçµæ§‹"""
    # æ ¸å¿ƒè¨ºæ–·çµæœ
    anchored_case: Dict[str, Any]           # éŒ¨å®šæ¡ˆä¾‹
    syndrome_analysis: str                   # è­‰å‹åˆ†æ
    diagnosis_reasoning: str                 # è¨ºæ–·æ¨ç†
    
    # å·¥å…·å¢å¼·çµæœ
    tool_decisions: ToolCallDecision         # å·¥å…·èª¿ç”¨æ±ºç­–
    tool_results: List[ToolCallResult]       # å·¥å…·èª¿ç”¨çµæœ
    
    # é©—è­‰èˆ‡èƒŒæ›¸
    validation_status: str                   # "validated" | "partially_validated" | "unvalidated"
    authority_references: List[str]          # æ¬Šå¨å¼•ç”¨
    knowledge_supplements: List[str]         # çŸ¥è­˜è£œå……
    modern_evidence: List[str]                  # ç¾ä»£ç§‘å­¸è­‰æ“šï¼ˆTool Cï¼‰
    
    # å…ƒæ•¸æ“š
    coverage_score: float                    # è¦†è“‹åº¦
    confidence_boost: float                  # å·¥å…·å¸¶ä¾†çš„ç½®ä¿¡åº¦æå‡
    follow_up_questions: List[str]           # è¿½å•å•é¡Œ


# ==================== L2 Agentic æ ¸å¿ƒé‚è¼¯ ====================

class L2AgenticDiagnosis:
    """
    L2 Agentic è¨ºæ–·å±¤
    """
    
    def __init__(self, config: Any, search_engine: Any = None, embed_client: Any = None):
        """
        åˆå§‹åŒ– L2 Agentic è¨ºæ–·å±¤
        """
        self.config = config
        self.se = search_engine
        self.embed = embed_client
        self.toolkit = TCMUnifiedToolkit()
        self.tools = TCMTools()
        self.term_manager = TerminologyManager()
        
        # å·¥å…·èª¿ç”¨é…ç½®
        self.tool_config = {
            "enable_tool_calls": True,           # ç¸½é–‹é—œ
            "enable_tool_a": True,               # ICD-11 é–‹é—œ
            "enable_tool_b": True,               # A+ç™¾ç§‘ é–‹é—œ
            "enable_tool_c": True,               # ETCM é–‹é—œ
            "knowledge_gap_threshold": 0.6,      # çŸ¥è­˜ç¼ºå£é–€æª»ï¼ˆæ¡ˆä¾‹å®Œæ•´åº¦ä½æ–¼æ­¤å€¼è§¸ç™¼ Tool Bï¼‰
            "validation_confidence_threshold": 0.7,  # éœ€è¦é©—è­‰çš„ç½®ä¿¡åº¦é–€æª»
            "max_tool_calls_per_diagnosis": 3,   # å–®æ¬¡è¨ºæ–·æœ€å¤§å·¥å…·èª¿ç”¨æ¬¡æ•¸
            "tool_timeout": 15.0,                # å·¥å…·èª¿ç”¨è¶…æ™‚ï¼ˆç§’ï¼‰
        }
        
        logger.info("[L2Agentic] åˆå§‹åŒ–å®Œæˆ - å·¥å…·èª¿ç”¨å·²å•Ÿç”¨")
    
    # ==================== ä¸»è¦è¨ºæ–·æµç¨‹ ====================
    
    async def diagnose_with_tools(
        self, 
        user_query: str, 
        retrieved_cases: List[Dict[str, Any]], 
        l1_decision: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        åŸ·è¡Œ L2 Agentic è¨ºæ–·æµç¨‹ (ä¿®å¾©åƒæ•¸å‚³éèˆ‡é¡å‹è½‰æ›)
        """
        # 1. [ç©©å®šæ€§] å¼·åˆ¶é–å®šæœ€ä½³éŒ¨å®š (Top-1)
        target_anchors = retrieved_cases
        best_anchor = None
        if retrieved_cases and len(retrieved_cases) > 0:
            best_anchor = retrieved_cases[0]
            target_anchors = [best_anchor]
            logger.info(f"[L2Agentic] å¼·åˆ¶é–å®šå–®ä¸€éŒ¨å®šæ¡ˆä¾‹: {best_anchor.get('case_id')} (Score: {best_anchor.get('score')})")

        # 2. åŸ·è¡Œåˆæ­¥è¨ºæ–· (L2)
        # [FIX] è™•ç† _anchor_and_diagnose åƒæ•¸æ•¸é‡ä¸å®šçš„å•é¡Œ
        try:
            l2_raw_result = await self._anchor_and_diagnose(user_query, target_anchors)
        except TypeError:
            # å…¼å®¹èˆŠç‰ˆå®šç¾© (å¤šä¸€å€‹ l1_decision)
            l2_raw_result = await self._anchor_and_diagnose(user_query, target_anchors, l1_decision)

        # [FIX] è™•ç† tuple è¿”å›å€¼ (é‡å° AttributeError: tuple has no attribute get)
        initial_diagnosis = l2_raw_result
        if isinstance(l2_raw_result, tuple):
            # æ ¹æ“šæ‚¨çš„ä»£ç¢¼ï¼Œtuple çµæ§‹é€šå¸¸æ˜¯ (anchored_case, diagnosis_dict)
            if len(l2_raw_result) >= 2:
                initial_diagnosis = l2_raw_result[1]
                logger.info("[L2Agentic] æˆåŠŸå¾ tuple è§£åŒ…å‡ºè¨ºæ–·å­—å…¸")
            else:
                initial_diagnosis = l2_raw_result[0] if len(l2_raw_result) > 0 else {}

        # 3. èª¿ç”¨å¢å¼·æµç¨‹ (Enhance Diagnosis)
        # [CRITICAL FIX] ä½¿ç”¨é—œéµå­—åƒæ•¸ (keyword arguments) ç¢ºä¿é †åºæ­£ç¢ºï¼Œé¿å… KeyError: 0
        # ä¹‹å‰éŒ¯èª¤å°‡ l1_decision å‚³çµ¦äº† retrieved_cases
        l2_agentic_output = await self.enhance_diagnosis(
            l2_raw_result=initial_diagnosis,
            l1_decision=l1_decision,
            retrieved_cases=target_anchors  # é€™è£¡å¿…é ˆå‚³å…¥åˆ—è¡¨ï¼
        )
        
        # 4. [æ ¼å¼è½‰æ›] å°‡ dataclass è½‰æ›ç‚º Dictï¼Œä»¥ç¬¦åˆ FourLayerPipeline çš„é æœŸ
        # å¦‚æœä¸è½‰ï¼ŒFourLayerPipeline è£¡çš„ isinstance(x, dict) æœƒå¤±æ•—
        return {
            "final_diagnosis": {
                "primary_syndrome": l2_agentic_output.syndrome_analysis,
                "reasoning": l2_agentic_output.diagnosis_reasoning,
                "pathogenesis": l2_agentic_output.anchored_case.get("pathogenesis", ""),
                "treatment_principle": l2_agentic_output.anchored_case.get("treatment", ""),
                "knowledge_supplements": l2_agentic_output.knowledge_supplements
            },
            "metrics": {
                "case_completeness": l2_agentic_output.coverage_score,
                "final_confidence": l2_agentic_output.coverage_score + l2_agentic_output.confidence_boost
            },
            "tool_outputs": {r.tool_name: r.content for r in l2_agentic_output.tool_results},
            "tool_decision": l2_agentic_output.tool_decisions,
            "initial_diagnosis": initial_diagnosis
        }

        # æ­¥é©Ÿ 6ï¼šåŸ·è¡Œå·¥å…· (å¦‚æœéœ€è¦)
        if tool_decision.should_call_any():
            tool_outputs = await self._execute_tools(tool_decision)
            
            # å†æ¬¡å¢å¼·è¨ºæ–· (æ³¨å…¥å·¥å…·çµæœ)
            final_diagnosis = await self._synthesize_final_diagnosis(
                initial_diagnosis,
                tool_outputs
            )
            final_result["tool_outputs"] = tool_outputs
            final_result["final_diagnosis"] = final_diagnosis
            
            # æ›´æ–°ç½®ä¿¡åº¦
            final_confidence = min(0.95, diagnosis_confidence + 0.15) # ç°¡å–®æå‡
            final_result["metrics"]["final_confidence"] = final_confidence
            
            logger.info(f"[L2Agentic] å¢å¼·å®Œæˆ\n  é©—è­‰ç‹€æ…‹: validated\n  å·¥å…·èª¿ç”¨æ•¸: {len(tool_outputs)}\n  ç½®ä¿¡åº¦æå‡: +0.15")
        else:
            logger.info("[L2Agentic] ç„¡éœ€èª¿ç”¨å·¥å…·ï¼Œæ¢ä»¶æœªè§¸ç™¼")
            final_result["metrics"]["final_confidence"] = diagnosis_confidence
            
            # æ¨™è¨˜ç‹€æ…‹
            final_result["tool_outputs"] = {}
            logger.info(f"[L2Agentic] å¢å¼·å®Œæˆ\n  é©—è­‰ç‹€æ…‹: unvalidated\n  å·¥å…·èª¿ç”¨æ•¸: 0\n  ç½®ä¿¡åº¦æå‡: +0.00")

        return final_result
    
    # [NEW] å…§éƒ¨çŸ¥è­˜åº«æŸ¥è©¢æ–¹æ³•
    async def _query_internal_knowledge(self, query_text: str, vector_search_only: bool = False) -> Dict[str, Any]:
        """
        å¾ Weaviate TCM Class æŸ¥è©¢æ¨™æº–è­‰å‹çŸ¥è­˜ï¼Œå…·å‚™å®Œæ•´è¡“èªæ˜ å°„èˆ‡ç—…ä½éæ¿¾ã€‚
        """
        if not self.se or not query_text:
            return None
            
        try:
            # --- 1. å¦å®šè©é è™•ç† (Negative Filter) ---
            # åƒ…ç§»é™¤æ˜ç¢ºçš„å¦å®šå¥ï¼Œä¿ç•™ "ä¸èˆ’æœ" ç­‰æè¿°
            import re
            negative_markers = ["æ²’æœ‰", "ç„¡", "æœªè¦‹", "é"] # ç§»é™¤ "ä¸"ï¼Œé¿å…èª¤æ®º
            must_not_terms = []
            
            clauses = re.split(r'[ï¼Œ,ã€‚.;ï¼›]', query_text)
            positive_clauses = []
            
            for clause in clauses:
                clause = clause.strip()
                if not clause: continue
                
                is_negative = False
                for m in negative_markers:
                    # åªæœ‰ç•¶å¦å®šè©ä½æ–¼å¥é¦–é™„è¿‘æ™‚æ‰è¦–ç‚ºå¦å®š (e.g. "ç„¡å£è‹¦")
                    if m in clause and clause.index(m) < 2:
                        is_negative = True
                        term = clause.split(m)[-1].strip()
                        if len(term) > 1: must_not_terms.append(term)
                        break
                
                if not is_negative:
                    positive_clauses.append(clause)
            
            clean_query = " ".join(positive_clauses) if positive_clauses else query_text

            # --- 2. å…¨æ–¹ä½è¡“èªæ˜ å°„ (Comprehensive Term Mapping) ---
            # å°‡å£èªè½‰è­¯ç‚º TCM æ¨™æº–åº« (scbr_syndromes_cleaned_verified.json) ä¸­çš„è©å½™
            term_mapping = {
                # [æ ¸å¿ƒéƒ¨ä½]
                "èƒƒ": "èƒƒè„˜ è„¾èƒƒ ä¸­ç„¦", "è‚šå­": "è…¹éƒ¨ å¤§è…¹ å°è…¹ è„˜è…¹",
                "èƒ¸": "èƒ¸è†ˆ å¿ƒèƒ¸", "è„…": "è„…è‚‹", "è…°": "è…°åºœ è…åºœ", "é ­": "å·”é ‚",
                "èƒŒ": "èƒŒä¿", "è‚‹": "è„…è‚‹", "å–‰": "å’½å–‰", "çœ¼": "ç›®",
                
                # [æ¶ˆåŒ–ç³»çµ±]
                "æ‹‰è‚šå­": "æ³„ç€‰ ä¸‹åˆ© ä¾¿æº", "å¤§ä¾¿ç¨€": "ä¾¿æº å®Œç©€ä¸åŒ–", "ä¾¿ç§˜": "å¤§ä¾¿ç§˜çµ å¤§ä¾¿ä¹¾çµ",
                "æƒ³å": "å˜”å å™å¿ƒ å˜”é€† ä¹¾å˜”", "åƒä¸ä¸‹": "ç´å‘† é£Ÿå°‘ ç´å·® å­é£Ÿ",
                "è„¹": "ç—æ»¿ è„¹æ»¿", "æ‰“å—": "å™¯æ°£ å‘ƒé€†", "å£è‹¦": "è†½ç«", "å£ä¹¾": "å£ç‡¥ å’½ä¹¾ æ´¥å‚·",
                "ç—›": "ç–¼ç—›", "åˆºç—›": "ç˜€è¡€", "è„¹ç—›": "æ°£æ»¯", "å†·ç—›": "å¯’å‡", "ç¼ç—›": "ç«ç†±",
                
                # [å…¨èº«èˆ‡ç²¾ç¥]
                "ç¡ä¸è‘—": "ä¸å¯ å¤±çœ  å…¥ç¡å›°é›£", "å¤šå¤¢": "å¤¢æ“¾",
                "å¾ˆç´¯": "ç¥ç–² ä¹åŠ› å€¦æ€  å°‘æ°£æ‡¶è¨€", "æ²’åŠ›æ°£": "è‚¢å€¦ ç„¡åŠ›",
                "ç…©": "å¿ƒç…© ç…©èº äº”å¿ƒç…©ç†±", "æ€•å†·": "ç•å¯’ æƒ¡é¢¨ è‚¢å†·", "æ€•ç†±": "æƒ¡ç†± å£¯ç†±",
                "å‡ºæ±—": "è‡ªæ±— ç›œæ±—", "é ­æšˆ": "çœ©æšˆ", "æ‰‹è…³å†°å†·": "æ‰‹è¶³å¥å†·",
                
                # [äº”å®˜èˆ‡å…¶ä»–]
                "å¿ƒè·³": "å¿ƒæ‚¸ æ€”å¿¡", "å–˜": "æ°£å–˜ çŸ­æ°£", "å’³": "å’³å—½ å’¯ç—°",
                "ç—°": "ç—°æ¿ ç—°é£²", "æœˆç¶“": "ç¶“è¡Œ ç¶“æœŸ", "ç™½å¸¶": "å¸¶ä¸‹"
            }
            
            expansion_terms = []
            for colloquial, formal in term_mapping.items():
                if colloquial in clean_query:
                    expansion_terms.append(formal)
            
            if expansion_terms:
                expanded_query = f"{clean_query} {' '.join(expansion_terms)}"
                logger.info(f"[L2Agentic] è¡“èªæ“´å±•: '{clean_query}' -> '{expanded_query}'")
                search_text = expanded_query
            else:
                search_text = clean_query

            # --- 3. ç”Ÿæˆå‘é‡èˆ‡æª¢ç´¢ ---
            vector = None
            if self.embed:
                try:
                    vector = await self.embed.embed(search_text)
                except Exception as e:
                    logger.warning(f"å‘é‡ç”Ÿæˆå¤±æ•—: {e}")

            # è¨­å®š Alpha=0.2 (é—œéµå­—å„ªå…ˆ)ï¼ŒLimit=10 (æ“´å¤§å¬å›)
            results = await self.se.hybrid_search(
                index="TCM",
                text=search_text,
                vector=vector,
                alpha=0.2, 
                limit=10, 
                search_fields=["name_zh", "definition", "clinical_manifestations", "vector_text"] 
            )
            
            # --- 4. ä¸­é†«ç—…ä½éæ¿¾ (Full Scope Guard) ---
            # ç¢ºä¿æœå°‹çµæœåŒ…å«ä¸»è¨´çš„æ ¸å¿ƒéƒ¨ä½
            key_locations = [
                "èƒƒ", "å¿ƒ", "è‚", "è„¾", "è‚º", "è…", "è†½", "è…¸", "è†€èƒ±", "ä¸‰ç„¦", 
                "é ­", "é¢", "ç›®", "çœ¼", "è€³", "é¼»", "å£", "é½’", "å’½", "å–‰", 
                "è…¹", "è‚š", "è‡", "èƒ¸", "è„…", "èƒŒ", "è…°", "è‚©", "é ¸", 
                "æ‰‹", "è¶³", "å››è‚¢", "è‚¢", "è…¿", "è†", "éª¨", "ç¯€", "ç­‹", "è„ˆ",
                "èƒå®®", "å­å®®", "å°‘è…¹", "é™°å™¨", "äºŒä¾¿", "çš®", "è†š", "è‚Œ"
            ]
            query_locations = [k for k in key_locations if k in query_text]
            
            valid_result = None
            
            if results:
                top3_names = [r.get('name_zh') for r in results[:3]]
                logger.info(f"[L2Agentic] å…§éƒ¨æª¢ç´¢å€™é¸: {top3_names}")

                for res in results:
                    score = res.get("score", 0)
                    name = res.get("name_zh", "")
                    content_str = str(res.get("definition", "")) + str(res.get("clinical_manifestations", ""))
                    
                    if score < 0.40: continue

                    # A. æ’é™¤å¦å®šè©è¡çª
                    if any(term in content_str for term in must_not_terms):
                         continue

                    # B. ç—…ä½æª¢æŸ¥ (Scope Guard)
                    if query_locations:
                        is_relevant = False
                        for loc in query_locations:
                            if loc in name or loc in content_str:
                                is_relevant = True
                                break
                            # æ™ºèƒ½æ˜ å°„ï¼šè…¹åŒ…å«èƒƒè…¸è„¾
                            if loc in ["è…¹", "è‚š"] and any(x in content_str for x in ["èƒƒ", "è…¸", "èƒå®®", "è„¾"]):
                                is_relevant = True
                                break
                            
                        if not is_relevant:
                            # logger.info(f"éæ¿¾: {name}") # æ¸›å°‘æ—¥èªŒé›œè¨Š
                            continue

                    valid_result = res
                    break
            
            if valid_result:
                logger.info(f"[L2Agentic] å…§éƒ¨çŸ¥è­˜åº«å‘½ä¸­: {valid_result.get('name_zh')} (Score: {valid_result.get('score', 0):.3f})")
                return valid_result
            
            return None
        except Exception as e:
            logger.warning(f"[L2Agentic] å…§éƒ¨çŸ¥è­˜åº«æŸ¥è©¢å¤±æ•—: {e}", exc_info=True)
            return None
    
    # ==================== é©é…æ–¹æ³•ï¼ˆç”¨æ–¼ four_layer_pipeline èª¿ç”¨ï¼‰====================
    
    async def enhance_diagnosis(
        self,
        l2_raw_result: Dict[str, Any],
        l1_decision: Dict[str, Any],
        retrieved_cases: List[Dict[str, Any]]
    ) -> L2AgenticOutput:
        """
        è¨ºæ–·å¢å¼·æ–¹æ³• - é©é… four_layer_pipeline.py çš„èª¿ç”¨ä»‹é¢
        """
        logger.info("[L2Agentic] ä½¿ç”¨ enhance_diagnosis é©é…æ–¹æ³•")
        
        # [MODIFIED] è™›æ“¬æ¡ˆä¾‹é˜²è­·ç¶²
        # è¬ä¸€çœŸçš„æ²’æœ‰æ¡ˆä¾‹ (retrieved_cases ç‚ºç©º)ï¼Œå‰µå»ºä¸€å€‹è™›æ“¬æ¡ˆä¾‹ä»¥é˜²å´©æ½°
        if not retrieved_cases:
            logger.warning("âš ï¸ L2 æ”¶åˆ° 0 å€‹æ¡ˆä¾‹ï¼Œä½¿ç”¨è™›æ“¬æ¡ˆä¾‹é€²è¡Œç´”ç†è«–è¨ºæ–·")
            
            # å˜—è©¦å¾ L1 æ±ºç­–ä¸­æ‰¾ä¸€å€‹ã€Œæš«å®šç—…åã€ï¼Œé¿å… "å¾…å®š" å°è‡´å·¥å…·ä¸å•Ÿå‹•
            kw = l1_decision.get("keyword_extraction", {})
            candidates = kw.get("syndrome_signals", []) + kw.get("symptom_terms", [])
            fallback_name = candidates[0] if candidates else "æœªåç—…ç—‡"
            
            virtual_case = {
                "case_id": "VIRTUAL_THEORY_CASE",
                "diagnosis": f"{fallback_name}(è™›æ“¬)", # çµ¦ä¸€å€‹å…·é«”åå­—
                "syndrome": fallback_name,
                "chief_complaint": "è³‡è¨Šä¸è¶³ï¼Œå•Ÿå‹•ç´”ç†è«–æ¨æ–·æ¨¡å¼",
                "treatment": "å»ºè­°è«®è©¢é†«å¸«",
                "score": 0.0,
                "pathogenesis": "", # ç•™ç™½ä»¥è§¸ç™¼ Knowledge Gap
            }
            retrieved_cases = [virtual_case]

        # æ­¥é©Ÿ 1ï¼šè©•ä¼°å‚³çµ± L2 è¨ºæ–·çš„å“è³ª
        case_completeness = self._evaluate_case_completeness_from_l2(l2_raw_result, retrieved_cases)
        diagnosis_confidence = self._evaluate_diagnosis_confidence_from_l2(
            l2_raw_result, l1_decision
        )
        
        logger.info(
            f"[L2Agentic] è©•ä¼°çµæœ\n"
            f"  æ¡ˆä¾‹å®Œæ•´åº¦: {case_completeness:.2f}\n"
            f"  è¨ºæ–·ç½®ä¿¡åº¦: {diagnosis_confidence:.2f}"
        )
        
        # æ­¥é©Ÿ 2ï¼šä½¿ç”¨éŒ¨å®šæ¡ˆä¾‹ï¼ˆç¾åœ¨ä¿è­‰è‡³å°‘æœ‰ä¸€å€‹ï¼Œå³ä½¿æ˜¯è™›æ“¬çš„ï¼‰
        anchored_case = retrieved_cases[0]
        
        # [ä¸­é†«æ€ç¶­ 0] å¼·åˆ¶é–å®šæœ€ä½³éŒ¨å®š (Force Top-1 Anchor)
        # è§£æ±º LLM åœ¨åˆ†æ•¸æ¥è¿‘æ™‚éš¨æ©Ÿé¸æ“‡å°è‡´çš„ä¸ç©©å®šå•é¡Œ
        # æˆ‘å€‘ç›´æ¥è¦†è“‹ prompt ä¸­çš„ implicitly chosen anchorï¼Œå¼·åˆ¶ä½¿ç”¨ Search Engine çš„ No.1
        best_anchor = None
        if retrieved_cases and len(retrieved_cases) > 0:
            best_anchor = retrieved_cases[0] # å–åˆ†æ•¸æœ€é«˜çš„
            logger.info(f"[L2Agentic] å¼·åˆ¶é–å®šæœ€ä½³éŒ¨å®šæ¡ˆä¾‹: {best_anchor.get('case_id')} (Score: {best_anchor.get('score')})")

        # æ­¥é©Ÿ 3ï¼šå¾ l2_raw_result æå–è¨ºæ–·è³‡è¨Š
        # é€™è£¡æˆ‘å€‘å‚³å…¥å¼·åˆ¶é–å®šçš„éŒ¨å®šï¼Œç¢ºä¿å¾ŒçºŒè™•ç†ä¸€è‡´
        initial_diagnosis = self._extract_diagnosis_from_l2_result(
            l2_raw_result,
            retrieved_cases=[best_anchor] if best_anchor else retrieved_cases
        )

        # ğŸš¨ [Step 3.5] å…§éƒ¨çŸ¥è­˜åº«å¢å¼· (Internal Knowledge Enrichment)
        user_query_text = ""
        # å˜—è©¦å¾ L1 æ±ºç­–ä¸­ç²å–åŸå§‹è¼¸å…¥
        if l1_decision and "input" in l1_decision:
            user_query_text = l1_decision["input"].get("user_query", "")
        
        # å¦‚æœ L1 æ²’å‚³ï¼Œå˜—è©¦å¾ L2 payload æ‰¾ (æœ‰äº›å¯¦ä½œæœƒæ”¾)
        if not user_query_text and "user_accumulated_query" in l2_raw_result:
             user_query_text = l2_raw_result.get("user_accumulated_query", "")

        internal_knowledge = None
        if user_query_text:
            # ä½¿ç”¨åŸå§‹ç—‡ç‹€é€²è¡Œæª¢ç´¢ (Vector Search)
            internal_knowledge = await self._query_internal_knowledge(user_query_text, vector_search_only=True)
        else:
            # ä¿åº•ï¼šå¦‚æœçœŸçš„æ‹¿ä¸åˆ°åŸå§‹è¼¸å…¥ï¼Œæ‰ç”¨ L2 çš„è¨ºæ–·åç¨±å»æŸ¥
            logger.warning("[L2Agentic] ç„¡æ³•ç²å–åŸå§‹è¼¸å…¥ï¼Œé™ç´šä½¿ç”¨ L2 è¨ºæ–·åç¨±æŸ¥è©¢")
            primary_syndrome = initial_diagnosis.get("primary_syndrome", "")
            # é€™è£¡éœ€è¦ç°¡å–®æ¸…æ´—ä¸€ä¸‹åç¨±
            import re
            clean_name = re.sub(r'[ï¼ˆ\(].*?[ï¼‰\)]', '', primary_syndrome).strip()
            internal_knowledge = await self._query_internal_knowledge(clean_name, vector_search_only=False)

        if internal_knowledge:
            tcm_name = internal_knowledge.get("name_zh", "")
            def_text = internal_knowledge.get("definition", "")
            manifest = internal_knowledge.get("clinical_manifestations", [])
            manifest_str = "ã€".join(manifest) if isinstance(manifest, list) else str(manifest)
            
            # [ä¸­é†«æ€ç¶­ 3] è¡çªæª¢æ¸¬ (Conflict Detection)
            # æ¯”è¼ƒã€ŒéŒ¨å®šæ¡ˆä¾‹è¨ºæ–·ã€èˆ‡ã€Œå…§éƒ¨çŸ¥è­˜åº«æª¢ç´¢çµæœã€
            l2_primary = initial_diagnosis.get("primary_syndrome", "æœªå®š")
            conflict_detected = False
            
            # æ¯”å°é‚è¼¯ï¼šå¦‚æœæ¨™æº–åº«çµæœä¸åœ¨ L2 åˆæ­¥è¨ºæ–·ä¸­ï¼Œä¸”æ¨™æº–åº«çµæœåˆ†æ•¸å¤ é«˜ (>0.75)
            # å‰‡è¦–ç‚ºé‡å¤§è¡çªï¼Œéœ€è¦å¼·åˆ¶å¼•å°
            internal_score = internal_knowledge.get("score", 0)
            
            if tcm_name not in l2_primary and l2_primary not in tcm_name:
                conflict_detected = True
                logger.warning(f"[L2Agentic] âš ï¸ ç™¼ç¾è¨ºæ–·è¡çª: éŒ¨å®šæ¨æ–·='{l2_primary}' vs æ¨™æº–åº«='{tcm_name}' (Score: {internal_score:.2f})")

            # æ³¨å…¥è£œå……è³‡è¨Šï¼Œä½¿ç”¨æ›´å¼·çƒˆçš„èªæ°£
            supplement_text = (
                f"ã€å…§éƒ¨æ¨™æº–çŸ¥è­˜åº«å°ç…§ã€‘\n"
                f"ç³»çµ±ä¾æ“šç—‡ç‹€æª¢ç´¢å‡ºçš„æœ€ä½³åŒ¹é…è­‰å‹ç‚ºï¼š{tcm_name} (åŒ¹é…åº¦: {internal_score:.2f})\n"
                f"å®šç¾©ï¼š{def_text}\n"
                f"å…¸å‹è¡¨ç¾ï¼š{manifest_str}\n"
            )
            
            if conflict_detected:
                # [FIX] å¦‚æœå…§éƒ¨çŸ¥è­˜åˆ†æ•¸å¾ˆé«˜ï¼Œå¼·åˆ¶è¦æ±‚ LLM è€ƒæ…®ä¿®æ­£æ–¹å‘
                if internal_score > 0.8:
                    priority_instruction = "è«‹å„ªå…ˆè€ƒæ…®æ¨™æº–åº«çš„å»ºè­°ï¼Œå› ç‚ºå…¶ç—‡ç‹€åŒ¹é…åº¦æ¥µé«˜ã€‚"
                else:
                    priority_instruction = "è«‹ä»”ç´°é‘‘åˆ¥å…©è€…å·®ç•°ã€‚"

                supplement_text += (
                    f"\nğŸš¨ **ç³»çµ±ç™¼ç¾é—œéµç–‘é»**ï¼š\n"
                    f"éŒ¨å®šæ¡ˆä¾‹æŒ‡å‘ã€Œ{l2_primary}ã€ï¼Œä½†ç—‡ç‹€ç‰¹å¾µèˆ‡æ¨™æº–åº«çš„ã€Œ{tcm_name}ã€æ›´ç‚ºå»åˆã€‚\n"
                    f"{priority_instruction}\n"
                    f"è«‹åœ¨ã€è¾¨è­‰åˆ†æã€‘ä¸­æ˜ç¢ºåŸ·è¡Œé‘‘åˆ¥ï¼šç‚ºä½•æ”¾æ£„ A è€Œé¸æ“‡ B (æˆ–å…¼è­‰)ï¼Ÿ"
                )
                
                # å¯«å…¥ reasoning æ¬„ä½ï¼Œå¼·è¿« LLM åœ¨æ€è€ƒéç¨‹ä¸­çœ‹åˆ°
                current_reasoning = initial_diagnosis.get("reasoning", "")
                initial_diagnosis["reasoning"] = f"ã€ç³»çµ±è­¦ç¤ºã€‘{l2_primary} èˆ‡ {tcm_name} å­˜åœ¨è¡çªï¼Œéœ€é€²è¡Œé‘‘åˆ¥ã€‚{current_reasoning}"
                
                initial_diagnosis["conflict_needs_resolution"] = True
            
            if "knowledge_supplements" not in initial_diagnosis:
                initial_diagnosis["knowledge_supplements"] = []
            initial_diagnosis["knowledge_supplements"].append(supplement_text)
            
            initial_diagnosis["internal_validated"] = True
            
            # è‹¥ L2 è¨ºæ–·åç¨±ä¸æ˜ç¢ºï¼Œç›´æ¥æ¡ç”¨å…§éƒ¨çµæœ
            if not l2_primary or "å¾…å®š" in l2_primary:
                initial_diagnosis["primary_syndrome"] = f"{tcm_name} (åŸºæ–¼ç—‡ç‹€æª¢ç´¢æ¨æ–·)"
                logger.info(f"[L2Agentic] å¡«è£œç©ºç™½è¨ºæ–·: {tcm_name}")
            

        # æ­¥é©Ÿ 4ï¼šæ±ºç­–æ˜¯å¦éœ€è¦å·¥å…·èª¿ç”¨
        tool_decision = self._decide_tool_calls(
            anchored_case=anchored_case,
            initial_diagnosis=initial_diagnosis, # é€™è£¡å·²ç¶“åŒ…å«å…§éƒ¨çŸ¥è­˜äº†
            case_completeness=case_completeness,
            diagnosis_confidence=diagnosis_confidence,
            l1_decision=l1_decision
        )
        
        # æ­¥é©Ÿ 5ï¼šåŸ·è¡Œå·¥å…·èª¿ç”¨ï¼ˆå¦‚æœ‰éœ€è¦ï¼‰
        tool_results = []
        if self._should_call_any_tool(tool_decision):
            num_tools = sum([
                tool_decision.should_call_tool_a,
                tool_decision.should_call_tool_b,
                tool_decision.should_call_tool_c
            ])
            logger.info(f"[L2Agentic] ä¸¦è¡ŒåŸ·è¡Œ {num_tools} å€‹å·¥å…·èª¿ç”¨")
            tool_results = await self._execute_tool_calls(
                tool_decision,
                initial_diagnosis.get("primary_syndrome", "")
            )
        else:
            logger.info("[L2Agentic] ç„¡éœ€èª¿ç”¨å·¥å…·ï¼Œæ¢ä»¶æœªè§¸ç™¼")
        
        # æ­¥é©Ÿ 6ï¼šæ•´åˆå·¥å…·çµæœ
        enhanced_diagnosis = self._integrate_tool_results(
            initial_diagnosis, tool_results
        )
        
        # æ­¥é©Ÿ 7ï¼šæ§‹å»ºè¼¸å‡º
        output = self._build_output(
            anchored_case=anchored_case,
            enhanced_diagnosis=enhanced_diagnosis,
            tool_decision=tool_decision,
            tool_results=tool_results,
            case_completeness=case_completeness
        )
        
        # ğŸ†• å‹•æ…‹æ·»åŠ å±¬æ€§ä¾› four_layer_pipeline ä½¿ç”¨
        output.diagnosis_confidence = diagnosis_confidence
        output.case_completeness = case_completeness
        
        logger.info(
            f"[L2Agentic] å¢å¼·å®Œæˆ\n"
            f"  é©—è­‰ç‹€æ…‹: {output.validation_status}\n"
            f"  å·¥å…·èª¿ç”¨æ•¸: {len(tool_results)}\n"
            f"  ç½®ä¿¡åº¦æå‡: +{output.confidence_boost:.2f}"
        )
        
        return output
    
    # ==================== [æ–°å¢] è¼”åŠ©æ–¹æ³• ====================

    def _extract_diagnosis_from_l2_result(
        self,
        l2_result: Dict[str, Any],
        retrieved_cases: List[Dict[str, Any]] = None  # [MODIFIED] æ–°å¢åƒæ•¸
    ) -> Dict[str, Any]:
        """
        å¾å‚³çµ± L2 è¨ºæ–·çµæœä¸­æå–è¨ºæ–·è³‡è¨Š (ä¿®æ­£åµŒå¥—çµæ§‹è®€å– + å¼·åˆ¶ä¿åº•)
        """
        # å„ªå…ˆå¾ tcm_inference æå–ï¼Œå¦‚æœæ²’æœ‰å‰‡å˜—è©¦å¾æ ¹ç›®éŒ„æå– (å…¼å®¹èˆŠç‰ˆ)
        inference = l2_result.get("tcm_inference", {})
        
        if not inference and "primary_pattern" in l2_result:
             inference = l2_result

        primary = (
            inference.get("primary_pattern") or 
            l2_result.get("primary_pattern") or 
            l2_result.get("primary_syndrome") or 
            ""
        ).strip()

        # [MODIFIED] å¼·åˆ¶ä¿åº•é‚è¼¯ï¼šæª¢æ¸¬ LLM æ˜¯å¦æ‹’çµ•è¨ºæ–·
        refusal_keywords = [
            "ç„¡æ³•å½¢æˆ", "ç„¡æ³•åˆ¤æ–·", "è³‡è¨Šä¸è¶³", "not be determined", 
            "no primary pattern", "n/a", "unknown", "none"
        ]
        
        if not primary or any(k in primary.lower() for k in refusal_keywords):
            # å˜—è©¦ä½¿ç”¨æª¢ç´¢åˆ°çš„ç¬¬ä¸€å€‹æ¡ˆä¾‹ä½œç‚ºä¿åº•
            if retrieved_cases and len(retrieved_cases) > 0:
                top_case = retrieved_cases[0]
                fallback_diag = (
                    top_case.get("diagnosis") or 
                    top_case.get("syndrome") or 
                    top_case.get("primary_pattern")
                )
                if fallback_diag:
                    primary = f"{fallback_diag} (ç³»çµ±å¼·åˆ¶éŒ¨å®š)"
                    logger.warning(f"âš ï¸ LLM æ‹’çµ•è¨ºæ–·ï¼Œå·²å¼·åˆ¶ä½¿ç”¨ Top-1 æ¡ˆä¾‹ä¿åº•: {primary}")
            
            # å¦‚æœé€£æ¡ˆä¾‹éƒ½æ²’æœ‰ï¼Œæ‰çµ¦æœ€çµ‚ä¿åº•
            if not primary or any(k in primary.lower() for k in refusal_keywords):
                primary = "å¾…å®š (è³‡è¨Šæ¥µåº¦ç¼ºä¹)"

        return {
            "primary_syndrome": primary,
            "secondary_syndromes": [], 
            "pathogenesis": inference.get("pathogenesis", "") or l2_result.get("pathogenesis", ""),
            "treatment_principle": inference.get("treatment_principle", "") or l2_result.get("treatment_principle", ""),
            "confidence": 0.9 if l2_result.get("status") == "ok" else 0.6, 
            "reasoning": inference.get("syndrome_analysis", "åŸºæ–¼æ¡ˆä¾‹ç›¸ä¼¼åº¦æ¨æ–·")
        }
    
    def _evaluate_case_completeness_from_l2(
        self,
        l2_result: Dict[str, Any],
        retrieved_cases: List[Dict[str, Any]] = None
    ) -> float:
        """
        å¾ L2 è¨ºæ–·çµæœè©•ä¼°æ¡ˆä¾‹å®Œæ•´åº¦ï¼ˆå¼•å…¥æª¢ç´¢å“è³ªæ‡²ç½°ï¼‰
        """
        # 1. è¨ˆç®—åŸºç¤å…§å®¹åˆ†æ•¸
        content_score = 0.0
        inference = l2_result.get("tcm_inference", {})
        
        field_mapping = {
            "primary_syndrome": "primary_pattern",
            "pathogenesis": "pathogenesis",
            "treatment_principle": "treatment_principle",
            "reasoning": "syndrome_analysis"
        }
        
        weights = {
            "primary_syndrome": 0.4,
            "pathogenesis": 0.3,
            "treatment_principle": 0.2,
            "reasoning": 0.1
        }
        
        for weight_key, weight in weights.items():
            json_key = field_mapping.get(weight_key, weight_key)
            value = inference.get(json_key) or l2_result.get(json_key)
            
            if value:
                if isinstance(value, str) and len(value) > 5 and "å¾…å®š" not in value:
                    content_score += weight
                elif isinstance(value, (list, dict)) and len(value) > 0:
                    content_score += weight
        
        # 2. è¨ˆç®—æª¢ç´¢æ‡²ç½°å› å­
        penalty_factor = 1.0
        if retrieved_cases:
            top_case = retrieved_cases[0]
            max_score = float(
                top_case.get("score") or 
                top_case.get("_additional", {}).get("score") or 
                top_case.get("_final_score") or 
                0.0
            )
            
            if max_score < 0.60:
                penalty_factor = 0.5
            elif max_score < 0.75:
                penalty_factor = 0.7
                
        final_score = content_score * penalty_factor
        return min(1.0, final_score)
    
    def _evaluate_diagnosis_confidence_from_l2(
        self,
        l2_result: Dict[str, Any],
        l1_decision: Dict[str, Any]
    ) -> float:
        """
        å¾ L2 è¨ºæ–·çµæœå’Œ L1 æ±ºç­–è©•ä¼°è¨ºæ–·ç½®ä¿¡åº¦
        """
        base_confidence = l2_result.get("confidence", 0.7)
        l1_confidence = l1_decision.get("overall_confidence", 0.7)
        
        # L2 è¨ºæ–·ç½®ä¿¡åº¦å  70%ï¼ŒL1 æª¢ç´¢ç½®ä¿¡åº¦å  30%
        combined_confidence = base_confidence * 0.7 + l1_confidence * 0.3
        
        if l2_result.get("reasoning") and len(str(l2_result["reasoning"])) > 50:
            combined_confidence += 0.05
        
        if l2_result.get("pathogenesis") and len(str(l2_result["pathogenesis"])) > 30:
            combined_confidence += 0.05
        
        return min(1.0, combined_confidence)
    
    # ==================== æ¡ˆä¾‹éŒ¨å®šèˆ‡åˆæ­¥è¨ºæ–· ====================
    
    async def _anchor_and_diagnose(
        self,
        user_symptoms: str,
        retrieved_cases: List[Dict[str, Any]],
        l1_decision: Dict[str, Any] = None  # ç¢ºä¿åƒæ•¸ç°½åå…¼å®¹
    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """
        åŸ·è¡Œæ¡ˆä¾‹éŒ¨å®šèˆ‡åˆæ­¥è¨ºæ–· (ä¿®å¾©æ¬„ä½è®€å–)
        """
        if not retrieved_cases:
            return {}, {"primary_syndrome": "å¾…åˆ†æ", "reasoning": "ç„¡å¯ç”¨æ¡ˆä¾‹"}
        
        anchored_case = retrieved_cases[0]
        
        # [FIX] éµåå…¼å®¹æ€§è™•ç† (Key Compatibility)
        # è³‡æ–™åº«ä¸­çš„ key å¯èƒ½æ˜¯ diagnosis, syndrome, æˆ– primary_pattern
        syndrome_name = (
            anchored_case.get("diagnosis") or 
            anchored_case.get("syndrome") or 
            anchored_case.get("primary_pattern") or 
            "å¾…åˆ†æ"
        )
        
        # ç°¡å–®çš„æ¨ç†æ–‡å­—ç”Ÿæˆ
        reasoning = f"åŸºæ–¼éŒ¨å®šæ¡ˆä¾‹ {anchored_case.get('case_id', 'Unknown')} ({syndrome_name}) é€²è¡Œæ¨æ–·ã€‚"
        
        initial_diagnosis = {
            "primary_syndrome": syndrome_name,
            "secondary_syndromes": [],
            "pathogenesis": anchored_case.get("pathogenesis", "") or anchored_case.get("mechanism", ""),
            "treatment_principle": anchored_case.get("treatment", "") or anchored_case.get("treatment_principle", ""),
            "confidence": 0.7,
            "reasoning": reasoning
        }
        
        return anchored_case, initial_diagnosis
    
    # ==================== è©•ä¼°å‡½æ•¸ ====================
    
    def _evaluate_case_completeness(self, case: Dict[str, Any]) -> float:
        """
        è©•ä¼°æ¡ˆä¾‹è³‡è¨Šå®Œæ•´åº¦
        """
        if not case:
            return 0.0
        
        required_fields = {
            "symptoms": 0.25,
            "tongue_pulse": 0.20,
            "pathogenesis": 0.20,
            "syndrome": 0.20,
            "treatment": 0.15
        }
        
        score = 0.0
        for field, weight in required_fields.items():
            if case.get(field):
                value = case[field]
                if isinstance(value, str) and len(value) > 5:
                    score += weight
                elif isinstance(value, (list, dict)) and len(value) > 0:
                    score += weight
        
        return score
    
    def _evaluate_diagnosis_confidence(
        self,
        diagnosis: Dict[str, Any],
        l1_decision: Dict[str, Any]
    ) -> float:
        """
        è©•ä¼°è¨ºæ–·çš„ç½®ä¿¡åº¦
        """
        base_confidence = diagnosis.get("confidence", 0.7)
        
        if diagnosis.get("primary_syndrome") and diagnosis["primary_syndrome"] not in ["å¾…åˆ†æ", ""]:
            base_confidence += 0.05
        
        if diagnosis.get("pathogenesis") and len(diagnosis["pathogenesis"]) > 20:
            base_confidence += 0.05
        
        l1_confidence = l1_decision.get("overall_confidence", 0.7)
        final_confidence = (base_confidence + l1_confidence) / 2
        
        return min(1.0, final_confidence)
    
    # ==================== å·¥å…·èª¿ç”¨æ±ºç­– ====================
    
    def _decide_tool_calls(self, anchored_case, initial_diagnosis, case_completeness, diagnosis_confidence, l1_decision):
        decision = ToolCallDecision()
        """
        è‡ªä¸»æ±ºç­–æ˜¯å¦éœ€è¦èª¿ç”¨å·¥å…·(æ·±åº¦æ•´åˆæ±ºç­–æ¨¹)
        """
        target_syndrome = initial_diagnosis.get("primary_syndrome", "")
        
        # [FIX] å¦‚æœæ˜¯è™›æ“¬æ¡ˆä¾‹ (case_id ç‚º VIRTUAL)ï¼Œå¼·åˆ¶è¨­å®šä¸€å€‹ç›®æ¨™è©ï¼Œä¸è®“å®ƒ return
        if anchored_case.get("case_id") == "VIRTUAL_THEORY_CASE":
            # å˜—è©¦ç”¨ L1 çš„è¼¸å…¥ç•¶ä½œæŸ¥è©¢è©
            target_syndrome = l1_decision.get("input", {}).get("user_query", "")[:20] 
            logger.info(f"[L2Agentic] è™›æ“¬æ¡ˆä¾‹æ¨¡å¼ï¼šå¼·åˆ¶è¨­å®šå·¥å…·æŸ¥è©¢è©ç‚º '{target_syndrome}'")

        # åŸºç¤æª¢æŸ¥ï¼šå¦‚æœæ˜¯ç©ºçš„ï¼Œä¸”ä¸æ˜¯è™›æ“¬æ¡ˆä¾‹ï¼Œæ‰è¿”å›
        if (not target_syndrome or "å¾…å®š" in target_syndrome) and anchored_case.get("case_id") != "VIRTUAL_THEORY_CASE":
            return decision

        # --- ç­–ç•¥ A: çŸ¥è­˜ç¼ºå£ (Knowledge Gap) -> Tool B (A+ç™¾ç§‘) ---
        has_pathogenesis = len(initial_diagnosis.get("pathogenesis", "")) > 20
        # [MODIFIED] æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰å…§éƒ¨çŸ¥è­˜é©—è­‰
        has_internal_knowledge = initial_diagnosis.get("internal_validated", False)
        
        # å¦‚æœå®Œæ•´åº¦ä½ï¼Œä¸”æ²’æœ‰å…§éƒ¨çŸ¥è­˜æ”¯æ’ï¼Œæ‰èª¿ç”¨å¤–éƒ¨ç™¾ç§‘
        if (case_completeness < self.tool_config["knowledge_gap_threshold"] or not has_pathogenesis) and not has_internal_knowledge:
            if self.tool_config["enable_tool_b"]:
                decision.should_call_tool_b = True
                decision.reasons.append(ToolCallReason.KNOWLEDGE_GAP)
                decision.target_terms.append(target_syndrome)
                logger.info(f"[L2Agentic] è§¸ç™¼ Tool B (ç—…æ©Ÿç¼ºå¤±ä¸”ç„¡å…§éƒ¨åº«å­˜: {case_completeness:.2f})")
        elif has_internal_knowledge:
            logger.info(f"[L2Agentic] å…§éƒ¨çŸ¥è­˜åº«å·²æ»¿è¶³çŸ¥è­˜ç¼ºå£ï¼Œè·³é Tool B")

        # --- ç­–ç•¥ B: å¹»è¦ºæ ¡é©— (Hallucination Check) -> Tool C (ETCM) ---
        if diagnosis_confidence < self.tool_config["validation_confidence_threshold"]:
            if self.tool_config["enable_tool_c"]:
                decision.should_call_tool_c = True
                decision.reasons.append(ToolCallReason.HALLUCINATION_CHECK)
                if target_syndrome not in decision.target_terms:
                    decision.target_terms.append(target_syndrome)
                logger.info(f"[L2Agentic] è§¸ç™¼ Tool C (ç½®ä¿¡åº¦ä¸è¶³: {diagnosis_confidence:.2f})")

        # --- ç­–ç•¥ C: æ¬Šå¨èƒŒæ›¸ (Authority Endorsement) -> Tool A (ICD-11) ---
        if target_syndrome and len(target_syndrome) < 10: 
            if self.tool_config["enable_tool_a"]:
                decision.should_call_tool_a = True
                decision.reasons.append(ToolCallReason.AUTHORITY_ENDORSEMENT)
                if target_syndrome not in decision.target_terms:
                    decision.target_terms.append(target_syndrome)
                logger.info("[L2Agentic] è§¸ç™¼ Tool A (å°‹æ±‚ ICD-11 æ¨™æº–åŒ–èƒŒæ›¸)")
        
        return decision
    
    def _should_call_any_tool(self, decision: ToolCallDecision) -> bool:
        """æª¢æŸ¥æ˜¯å¦éœ€è¦èª¿ç”¨ä»»ä½•å·¥å…·"""
        return (
            decision.should_call_tool_a or
            decision.should_call_tool_b or
            decision.should_call_tool_c
        )
    
    # ==================== å·¥å…·èª¿ç”¨åŸ·è¡Œ ====================
    
    async def _execute_tool_calls(
        self,
        decision: ToolCallDecision,
        primary_syndrome: str
    ) -> List[ToolCallResult]:
        """
        ä¸¦è¡ŒåŸ·è¡Œæ‰€æœ‰éœ€è¦çš„å·¥å…·èª¿ç”¨
        """
        tasks = []
        
        if decision.should_call_tool_a:
            tasks.append(self._call_tool_a(primary_syndrome))
        
        if decision.should_call_tool_b:
            tasks.append(self._call_tool_b(primary_syndrome))
        
        if decision.should_call_tool_c:
            tasks.append(self._call_tool_c(primary_syndrome))
        
        results = []
        if tasks:
            try:
                completed = await asyncio.wait_for(
                    asyncio.gather(*tasks, return_exceptions=True),
                    timeout=self.tool_config["tool_timeout"]
                )
                
                for result in completed:
                    if isinstance(result, Exception):
                        results.append(ToolCallResult(
                            tool_name="unknown",
                            success=False,
                            content="",
                            error=str(result)
                        ))
                    else:
                        results.append(result)
            except asyncio.TimeoutError:
                logger.error("[L2Agentic] å·¥å…·èª¿ç”¨ç¸½é«”è¶…æ™‚")
                results.append(ToolCallResult(
                    tool_name="batch",
                    success=False,
                    content="",
                    error="å·¥å…·èª¿ç”¨æ‰¹æ¬¡è¶…æ™‚"
                ))
        
        return results
    
    async def _call_tool_a(self, term: str) -> ToolCallResult:
        """èª¿ç”¨ Tool A - ICD-11 è¡“èªæ¨™æº–åŒ–"""
        try:
            loop = asyncio.get_event_loop()
            content = await asyncio.wait_for(
                loop.run_in_executor(None, self.tools.tool_a_standardize_term, term),
                timeout=self.tool_config["tool_timeout"]
            )
            return ToolCallResult(
                tool_name="Tool A (ICD-11)",
                success=True,
                content=content
            )
        except asyncio.TimeoutError:
            return ToolCallResult(
                tool_name="Tool A (ICD-11)",
                success=False,
                content="",
                error="å·¥å…·èª¿ç”¨è¶…æ™‚"
            )
        except Exception as e:
            return ToolCallResult(
                tool_name="Tool A (ICD-11)",
                success=False,
                content="",
                error=str(e)
            )
    
    async def _call_tool_b(self, syndrome_name: str) -> ToolCallResult:
        """èª¿ç”¨ Tool B - A+ç™¾ç§‘è¾¨è­‰é‚è¼¯"""
        try:
            loop = asyncio.get_event_loop()
            content = await asyncio.wait_for(
                loop.run_in_executor(None, self.tools.tool_b_syndrome_logic, syndrome_name),
                timeout=self.tool_config["tool_timeout"]
            )
            return ToolCallResult(
                tool_name="Tool B (A+ç™¾ç§‘)",
                success=True,
                content=content
            )
        except asyncio.TimeoutError:
            return ToolCallResult(
                tool_name="Tool B (A+ç™¾ç§‘)",
                success=False,
                content="",
                error="å·¥å…·èª¿ç”¨è¶…æ™‚"
            )
        except Exception as e:
            return ToolCallResult(
                tool_name="Tool B (A+ç™¾ç§‘)",
                success=False,
                content="",
                error=str(e)
            )
    
    async def _call_tool_c(self, syndrome_name: str) -> ToolCallResult:
        """èª¿ç”¨ Tool C - ETCM ç¾ä»£å°ç…§"""
        try:
            loop = asyncio.get_event_loop()
            content = await asyncio.wait_for(
                loop.run_in_executor(None, self.tools.tool_c_modern_evidence, syndrome_name),
                timeout=self.tool_config["tool_timeout"]
            )
            return ToolCallResult(
                tool_name="Tool C (ETCM)",
                success=True,
                content=content
            )
        except asyncio.TimeoutError:
            return ToolCallResult(
                tool_name="Tool C (ETCM)",
                success=False,
                content="",
                error="å·¥å…·èª¿ç”¨è¶…æ™‚"
            )
        except Exception as e:
            return ToolCallResult(
                tool_name="Tool C (ETCM)",
                success=False,
                content="",
                error=str(e)
            )
    
    # ==================== çµæœæ•´åˆ ====================
    
    def _integrate_tool_results(
        self,
        initial_diagnosis: Dict[str, Any],
        tool_results: List[ToolCallResult]
    ) -> Dict[str, Any]:
        """
        æ•´åˆå·¥å…·çµæœåˆ°è¨ºæ–·ä¸­(è³‡è¨Šèåˆ)
        """
        enhanced = initial_diagnosis.copy()
        for field in ["authority_references", "knowledge_supplements", "modern_evidence", "validation_notes"]:
            if field not in enhanced: enhanced[field] = []
        
        for result in tool_results:
            if not result.success:
                enhanced["validation_notes"].append(f"{result.tool_name} èª¿ç”¨å¤±æ•—: {result.error}")
                continue

            target_term = initial_diagnosis.get("primary_syndrome", "")
            if target_term and len(target_term) > 1 and "å¾…å®š" not in target_term:
                if hasattr(self, 'term_manager'):
                    self.term_manager.add_term(target_term)
            
            if "Tool A" in result.tool_name:
                if "ICD-11" in result.content and "æœªæ‰¾åˆ°" not in result.content:
                    enhanced["authority_references"].append(result.content)
                    enhanced["validation_notes"].insert(0, "â˜… è­‰å‹åç¨±å·²ç² WHO ICD-11 æ¨™æº–é©—è­‰")
            
            elif "Tool B" in result.tool_name:
                if "è‡¨åºŠè¡¨ç¾" in result.content or "è¾¨è­‰" in result.content:
                    enhanced["knowledge_supplements"].append(result.content)
                    enhanced["validation_notes"].append("âœ“ å·²è£œå……è¾¨è­‰é‚è¼¯")
                    
                    if not enhanced.get("pathogenesis") or len(enhanced.get("pathogenesis", "")) < 10:
                        enhanced["pathogenesis"] = f"(ç”±å¤–éƒ¨çŸ¥è­˜åº«è£œå……) åƒè€ƒ A+ç™¾ç§‘ï¼š{result.content[:100]}..."
            
            elif "Tool C" in result.tool_name:
                if "ETCM" in result.content and "æœªæ‰¾åˆ°" not in result.content:
                    enhanced["modern_evidence"].append(result.content)
                    enhanced["validation_notes"].append("âœ“ å·²ç²å–ç¾ä»£ç§‘å­¸è­‰æ“š")
        
        return enhanced
    
    # ==================== è¼¸å‡ºæ§‹å»º-ä½¿ç”¨å‹•æ…‹æ¨¡å‹ ====================
    
    def _build_output(
        self,
        anchored_case: Dict[str, Any],
        enhanced_diagnosis: Dict[str, Any],
        tool_decision: ToolCallDecision,
        tool_results: List[ToolCallResult],
        case_completeness: float
    ) -> L2AgenticOutput:
        """
        æ§‹å»ºæœ€çµ‚çš„ L2 è¼¸å‡º
        """
        successful_tools = sum(1 for r in tool_results if r.success)
        total_tools = len(tool_results)
        
        if total_tools == 0:
            validation_status = "unvalidated"
        elif successful_tools == total_tools:
            validation_status = "validated"
        else:
            validation_status = "partially_validated"
        
        confidence_boost = self._calculate_confidence_boost(enhanced_diagnosis)
        
        follow_up_questions = []
        if case_completeness < 0.7:
            follow_up_questions = self._generate_follow_up_questions(
                anchored_case, enhanced_diagnosis
            )
        
        return L2AgenticOutput(
            anchored_case=anchored_case,
            syndrome_analysis=enhanced_diagnosis.get("primary_syndrome", ""),
            diagnosis_reasoning=self._format_diagnosis_reasoning(enhanced_diagnosis),
            tool_decisions=tool_decision,
            tool_results=tool_results,
            validation_status=validation_status,
            authority_references=enhanced_diagnosis.get("authority_references", []),
            knowledge_supplements=enhanced_diagnosis.get("knowledge_supplements", []),
            modern_evidence=enhanced_diagnosis.get("modern_evidence", []),
            coverage_score=case_completeness,
            confidence_boost=confidence_boost,
            follow_up_questions=follow_up_questions
        )
    
    def _format_diagnosis_reasoning(self, diagnosis: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è¨ºæ–·æ¨ç†èªªæ˜"""
        parts = []
        
        if diagnosis.get("reasoning"):
            parts.append(f"æ¨ç†ä¾æ“šï¼š{diagnosis['reasoning']}")
        
        if diagnosis.get("pathogenesis"):
            parts.append(f"ç—…å› ç—…æ©Ÿï¼š{diagnosis['pathogenesis']}")
        
        if diagnosis.get("validation_notes"):
            parts.append("é©—è­‰ç‹€æ…‹ï¼š" + " | ".join(diagnosis["validation_notes"]))
        
        return "\n".join(parts) if parts else "åŸºæ–¼æ¡ˆä¾‹ç›¸ä¼¼åº¦æ¨æ–·"
    
    def _generate_follow_up_questions(
        self,
        case: Dict[str, Any],
        diagnosis: Dict[str, Any]
    ) -> List[str]:
        """ç”Ÿæˆè¿½å•å•é¡Œ"""
        questions = []
        
        if not case.get("tongue_pulse"):
            questions.append("è«‹å•æ‚¨çš„èˆŒè±¡å¦‚ä½•ï¼ŸèˆŒè³ªé¡è‰²ã€èˆŒè‹”åšè–„ï¼Ÿ")
            questions.append("æ‚¨çš„è„ˆè±¡æœ‰ä»€éº¼ç‰¹é»ï¼Ÿæ˜¯å¦æœ‰é†«å¸«æŠŠéè„ˆï¼Ÿ")
        
        if not case.get("duration"):
            questions.append("é€™äº›ç—‡ç‹€æŒçºŒå¤šé•·æ™‚é–“äº†ï¼Ÿ")
        
        if not case.get("triggers"):
            questions.append("æœ‰ä»€éº¼æƒ…æ³æœƒåŠ é‡æˆ–ç·©è§£é€™äº›ç—‡ç‹€ï¼Ÿ")
        
        return questions[:3]
    
    def _calculate_confidence_boost(self, enhanced_diagnosis: Dict[str, Any]) -> float:
        """
        è¨ˆç®—è¨ºæ–·ç½®ä¿¡åº¦å¢ç›Š (Confidence Gain Model)
        """
        boost = 0.0
        
        if enhanced_diagnosis.get("authority_references"):
            boost += 0.15
            
        supplements = enhanced_diagnosis.get("knowledge_supplements", [])
        if supplements:
            content_len = sum(len(s) for s in supplements)
            if content_len > 100:
                boost += 0.10
            elif content_len > 0:
                boost += 0.05
                
        if enhanced_diagnosis.get("modern_evidence"):
            boost += 0.05
            
        return min(0.3, boost)