import json
import yaml
import os

def generate_spiral_benchmark_yaml():
    input_file = 'tcm_cases_dump.json'
    output_file = 'benchmark_cases_spiral.yaml'
    
    if not os.path.exists(input_file):
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æª”æ¡ˆ: {input_file}")
        return

    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            cases = json.load(f)
    except Exception as e:
        print(f"âŒ JSON è§£æå¤±æ•—: {e}")
        return

    benchmark_list = []

    for case in cases:
        # è§£æ raw_data ä»¥ç²å–çµæ§‹åŒ–æ¬„ä½
        try:
            raw_data = json.loads(case.get('raw_data', '{}'))
            complaint_data = raw_data.get('complaint', {})
            inspection_data = raw_data.get('inspection', {})
            pulse_data = raw_data.get('pulse', {})
        except:
            continue # è·³éè³‡æ–™ä¸å®Œæ•´çš„

        # --- æ§‹å»ºèºæ—‹æ¸¬è©¦ (Spiral Rounds) ---
        
        # Round 1: åƒ…æä¾›ä¸»è¨´ (æ¨¡æ“¬åˆè¨º)
        # é€™æœƒæ¸¬è©¦ L1 æ˜¯å¦èƒ½è™•ç†çŸ­æ–‡æœ¬ï¼Œä»¥åŠ L2 æ˜¯å¦æœƒæ¨™è¨˜ need_more_info
        r1_query = complaint_data.get('chiefComplaint', '')
        if not r1_query: r1_query = case.get('chief_complaint', 'ä¸é©')

        # Round 2: è£œå……ç¾ç—…å² (æ¨¡æ“¬æ‚£è€…è©³è¿°)
        r2_query = complaint_data.get('presentIllness', '')

        # Round 3: è£œå……èˆŒè„ˆ (æ¨¡æ“¬é†«ç”Ÿæœ›è¨º/åˆ‡è¨ºå¾Œè¼¸å…¥)
        # é€™æ˜¯ç¢ºè¨ºçš„é—œéµ
        tongue = inspection_data.get('tongueBody', []) + inspection_data.get('tongueCoating', [])
        pulse_str = ", ".join([f"{k}:{v[0]}" for k,v in pulse_data.items() if v])
        r3_query = f"èˆŒè±¡ï¼š{' '.join(tongue)}ã€‚è„ˆè±¡ï¼š{pulse_str}"

        # å»ºç«‹å¤šè¼ªæ¸¬è©¦æ¡ˆä¾‹
        benchmark_item = {
            "id": case.get('case_id'),
            "name": f"èºæ—‹æ¸¬è©¦ - {case.get('diagnosis', 'æœªçŸ¥')}",
            "type": "benchmark_spiral",
            "expected_diagnosis": case.get('diagnosis'),
            "rounds": []
        }

        # ä¾åºåŠ å…¥è¼ªæ¬¡ (è‹¥è³‡æ–™å­˜åœ¨)
        if r1_query:
            benchmark_item['rounds'].append({"question": r1_query})
        if r2_query:
            benchmark_item['rounds'].append({"question": r2_query})
        if len(tongue) > 0 or len(pulse_str) > 0:
            benchmark_item['rounds'].append({"question": r3_query})

        benchmark_list.append(benchmark_item)

    # å¯«å…¥ YAML
    final_yaml = {"test_cases": benchmark_list}
    with open(output_file, 'w', encoding='utf-8') as f:
        yaml.dump(final_yaml, f, allow_unicode=True, sort_keys=False, indent=2)

    print(f"âœ… å·²ç”Ÿæˆèºæ—‹æ¸¬è©¦é›†: {len(benchmark_list)} å€‹æ¡ˆä¾‹")
    print(f"   æ¯å€‹æ¡ˆä¾‹å¹³å‡ {sum(len(c['rounds']) for c in benchmark_list)/len(benchmark_list):.1f} è¼ª")
    print(f"ğŸ’¾ æª”æ¡ˆä½ç½®: {output_file}")

if __name__ == "__main__":
    generate_spiral_benchmark_yaml()